<!DOCTYPE HTML>
<html lang="zh" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Mojo 爬蟲完整指南 - Jason Notes</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "rust";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Jason Notes</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/shihyu/jason_note" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="mojo-爬蟲完整指南"><a class="header" href="#mojo-爬蟲完整指南">Mojo 爬蟲完整指南</a></h1>
<h2 id="-目錄"><a class="header" href="#-目錄">📚 目錄</a></h2>
<ul>
<li><a href="#mojo-%E5%AE%89%E8%A3%9D">Mojo 安裝</a></li>
<li><a href="#%E7%92%B0%E5%A2%83%E6%BA%96%E5%82%99">環境準備</a></li>
<li><a href="#%E5%9F%BA%E7%A4%8E%E7%88%AC%E8%9F%B2%E7%AF%84%E4%BE%8B">基礎爬蟲範例</a></li>
<li><a href="#%E9%80%B2%E9%9A%8E%E7%88%AC%E8%9F%B2%E7%AF%84%E4%BE%8B">進階爬蟲範例</a></li>
<li><a href="#%E5%AF%A6%E7%94%A8%E5%B7%A5%E5%85%B7%E5%87%BD%E6%95%B8">實用工具函數</a></li>
<li><a href="#%E6%9C%80%E4%BD%B3%E5%AF%A6%E8%B8%90">最佳實踐</a></li>
<li><a href="#%E5%B8%B8%E8%A6%8B%E5%95%8F%E9%A1%8C">常見問題</a></li>
</ul>
<h2 id="-mojo-安裝"><a class="header" href="#-mojo-安裝">🚀 Mojo 安裝</a></h2>
<h3 id="系統需求"><a class="header" href="#系統需求">系統需求</a></h3>
<ul>
<li><strong>作業系統</strong>: Ubuntu 20.04+ 或 macOS 12+</li>
<li><strong>硬體</strong>: x86-64 或 ARM64 架構</li>
<li><strong>記憶體</strong>: 至少 4GB RAM</li>
</ul>
<h3 id="安裝步驟"><a class="header" href="#安裝步驟">安裝步驟</a></h3>
<h4 id="方法-1-官方安裝器推薦"><a class="header" href="#方法-1-官方安裝器推薦">方法 1: 官方安裝器（推薦）</a></h4>
<pre><code class="language-bash"># 1. 訪問 Modular 官網
curl -s https://get.modular.com | sh -

# 2. 安裝 Mojo
modular install mojo

# 3. 設定環境變數
echo 'export MODULAR_HOME="$HOME/.modular"' &gt;&gt; ~/.bashrc
echo 'export PATH="$MODULAR_HOME/pkg/packages.modular.com_mojo/bin:$PATH"' &gt;&gt; ~/.bashrc
source ~/.bashrc

# 4. 驗證安裝
mojo --version
</code></pre>
<h4 id="方法-2-max-platform"><a class="header" href="#方法-2-max-platform">方法 2: MAX Platform</a></h4>
<pre><code class="language-bash"># 1. 註冊並下載 MAX Platform
# 2. 安裝 MAX
sudo dpkg -i max-*.deb

# 3. 啟動 MAX
max auth login

# 4. 安裝 Mojo
max install mojo

# 5. 驗證
mojo --version
</code></pre>
<h3 id="開發環境設定"><a class="header" href="#開發環境設定">開發環境設定</a></h3>
<h4 id="vs-code-擴展"><a class="header" href="#vs-code-擴展">VS Code 擴展</a></h4>
<pre><code class="language-bash"># 安裝 Mojo 語言支援
code --install-extension modular-mojotools.mojo
</code></pre>
<h4 id="jupyter-notebook-支援"><a class="header" href="#jupyter-notebook-支援">Jupyter Notebook 支援</a></h4>
<pre><code class="language-bash"># 安裝 Jupyter
pip install jupyter

# 註冊 Mojo 核心
max install jupyter

# 啟動 Jupyter
jupyter notebook
</code></pre>
<h2 id="-環境準備"><a class="header" href="#-環境準備">🛠️ 環境準備</a></h2>
<h3 id="python-依賴安裝"><a class="header" href="#python-依賴安裝">Python 依賴安裝</a></h3>
<pre><code class="language-bash"># 安裝爬蟲必要套件
pip install requests beautifulsoup4 lxml html5lib aiohttp

# 可選套件
pip install selenium pandas numpy
</code></pre>
<h3 id="項目結構"><a class="header" href="#項目結構">項目結構</a></h3>
<pre><code>mojo-crawler/
├── crawler.mojo          # 主爬蟲檔案
├── utils.mojo           # 工具函數
├── config.mojo          # 配置檔案
├── requirements.txt     # Python 依賴
└── README.md           # 說明文件
</code></pre>
<h2 id="-基礎爬蟲範例"><a class="header" href="#-基礎爬蟲範例">🕷️ 基礎爬蟲範例</a></h2>
<h3 id="1-簡單的網頁爬蟲"><a class="header" href="#1-簡單的網頁爬蟲">1. 簡單的網頁爬蟲</a></h3>
<pre><code class="language-mojo"># crawler.mojo
from python import Python

def main():
    """基礎爬蟲範例"""
    
    # 導入 Python 模組
    let requests = Python.import_module("requests")
    let bs4 = Python.import_module("bs4")
    
    # 設定請求標頭
    let headers = Python.dict()
    headers["User-Agent"] = "Mozilla/5.0 (compatible; MojoCrawler/1.0)"
    
    try:
        # 發送 HTTP 請求
        let url = "https://example.com"
        let response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            print("✅ 請求成功")
            
            # 解析 HTML
            let soup = bs4.BeautifulSoup(response.content, "html.parser")
            
            # 提取標題
            let title = soup.find("title")
            if title:
                print("標題:", title.get_text())
            
            # 提取所有連結
            let links = soup.find_all("a", href=True)
            print(f"找到 {len(links)} 個連結")
            
            for i in range(min(5, len(links))):  # 只顯示前5個
                let link = links[i]
                print(f"  {i+1}. {link.get_text()}: {link['href']}")
                
        else:
            print("❌ 請求失敗, 狀態碼:", response.status_code)
            
    except Exception as e:
        print("錯誤:", e)
</code></pre>
<h3 id="2-json-api-爬蟲"><a class="header" href="#2-json-api-爬蟲">2. JSON API 爬蟲</a></h3>
<pre><code class="language-mojo">def crawl_json_api():
    """爬取 JSON API 數據"""
    
    let requests = Python.import_module("requests")
    let json = Python.import_module("json")
    
    let headers = Python.dict()
    headers["Accept"] = "application/json"
    headers["User-Agent"] = "MojoCrawler/1.0"
    
    try:
        # 爬取 API 數據
        let api_url = "https://jsonplaceholder.typicode.com/posts"
        let response = requests.get(api_url, headers=headers)
        
        if response.status_code == 200:
            let data = response.json()
            print(f"📊 獲取到 {len(data)} 筆數據")
            
            # 處理前3筆數據
            for i in range(min(3, len(data))):
                let post = data[i]
                print(f"\n📝 貼文 {i+1}:")
                print(f"  標題: {post['title']}")
                print(f"  用戶ID: {post['userId']}")
                print(f"  內容: {post['body'][:50]}...")
                
        else:
            print("❌ API 請求失敗")
            
    except Exception as e:
        print("錯誤:", e)
</code></pre>
<h2 id="-進階爬蟲範例"><a class="header" href="#-進階爬蟲範例">🚀 進階爬蟲範例</a></h2>
<h3 id="1-面向對象的爬蟲類"><a class="header" href="#1-面向對象的爬蟲類">1. 面向對象的爬蟲類</a></h3>
<pre><code class="language-mojo">from python import Python
from memory import Reference

struct WebCrawler:
    """高性能網頁爬蟲"""
    var session: PythonObject
    var headers: PythonObject
    var delay: Float64
    var max_retries: Int
    
    fn __init__(inout self):
        """初始化爬蟲"""
        let requests = Python.import_module("requests")
        self.session = requests.Session()
        
        # 設定標頭
        self.headers = Python.dict()
        self.headers["User-Agent"] = "Mozilla/5.0 (compatible; MojoCrawler/2.0)"
        self.headers["Accept"] = "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"
        self.headers["Accept-Language"] = "zh-TW,zh;q=0.9,en;q=0.8"
        self.headers["Accept-Encoding"] = "gzip, deflate, br"
        self.headers["Connection"] = "keep-alive"
        
        self.delay = 1.0
        self.max_retries = 3
    
    fn fetch_url(self, url: String) raises -&gt; PythonObject:
        """獲取 URL 內容（帶重試機制）"""
        let time = Python.import_module("time")
        
        for retry in range(self.max_retries):
            try:
                let response = self.session.get(
                    url, 
                    headers=self.headers, 
                    timeout=10,
                    allow_redirects=True
                )
                
                if response.status_code == 200:
                    return response
                elif response.status_code == 429:  # Too Many Requests
                    print(f"⚠️ 請求過於頻繁，等待 {(retry + 1) * 2} 秒...")
                    time.sleep((retry + 1) * 2)
                else:
                    print(f"❌ HTTP {response.status_code}")
                    
            except Exception as e:
                print(f"🔄 重試 {retry + 1}/{self.max_retries}: {e}")
                if retry &lt; self.max_retries - 1:
                    time.sleep(self.delay * (retry + 1))
        
        raise Error("所有重試都失敗了")
    
    fn parse_html(self, html_content: PythonObject) -&gt; PythonObject:
        """解析 HTML 內容"""
        let bs4 = Python.import_module("bs4")
        return bs4.BeautifulSoup(html_content, "html.parser")
    
    fn extract_data(self, soup: PythonObject) -&gt; PythonObject:
        """提取結構化數據"""
        let data = Python.dict()
        
        # 提取標題
        let title = soup.find("title")
        data["title"] = title.get_text().strip() if title else "無標題"
        
        # 提取 meta 描述
        let meta_desc = soup.find("meta", attrs={"name": "description"})
        data["description"] = meta_desc.get("content", "") if meta_desc else ""
        
        # 提取所有標題
        let headings = Python.list()
        for level in range(1, 7):  # h1-h6
            let tags = soup.find_all(f"h{level}")
            for i in range(len(tags)):
                let heading = tags[i]
                headings.append({
                    "level": level,
                    "text": heading.get_text().strip()
                })
        data["headings"] = headings
        
        # 提取連結
        let links = Python.list()
        let link_tags = soup.find_all("a", href=True)
        for i in range(len(link_tags)):
            let link = link_tags[i]
            links.append({
                "text": link.get_text().strip(),
                "url": link["href"]
            })
        data["links"] = links
        
        # 提取圖片
        let images = Python.list()
        let img_tags = soup.find_all("img", src=True)
        for i in range(len(img_tags)):
            let img = img_tags[i]
            images.append({
                "src": img["src"],
                "alt": img.get("alt", "")
            })
        data["images"] = images
        
        return data
</code></pre>
<h3 id="2-批量爬蟲範例"><a class="header" href="#2-批量爬蟲範例">2. 批量爬蟲範例</a></h3>
<pre><code class="language-mojo">def batch_crawl_demo():
    """批量爬蟲示例"""
    
    let time = Python.import_module("time")
    let json = Python.import_module("json")
    
    var crawler = WebCrawler()
    
    # 要爬取的 URL 列表
    let urls = [
        "https://example.com",
        "https://httpbin.org/html",
        "https://httpbin.org/json"
    ]
    
    let results = Python.list()
    
    print("🚀 開始批量爬取...")
    
    for i in range(len(urls)):
        let url = urls[i]
        print(f"\n📄 正在處理第 {i+1}/{len(urls)} 個: {url}")
        
        try:
            # 獲取頁面
            let response = crawler.fetch_url(url)
            
            # 解析內容
            if "application/json" in str(response.headers.get("content-type", "")):
                # JSON 數據
                let data = response.json()
                results.append({
                    "url": url,
                    "type": "json",
                    "data": data
                })
            else:
                # HTML 數據
                let soup = crawler.parse_html(response.content)
                let extracted_data = crawler.extract_data(soup)
                results.append({
                    "url": url,
                    "type": "html",
                    "data": extracted_data
                })
            
            print("✅ 處理完成")
            
        except Exception as e:
            print(f"❌ 處理失敗: {e}")
            results.append({
                "url": url,
                "type": "error",
                "error": str(e)
            })
        
        # 請求間隔
        if i &lt; len(urls) - 1:
            time.sleep(crawler.delay)
    
    # 保存結果
    try:
        with open("crawl_results.json", "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print("\n💾 結果已保存到 crawl_results.json")
    except Exception as e:
        print(f"💥 保存失敗: {e}")
    
    print(f"\n🎉 批量爬取完成! 共處理 {len(urls)} 個 URL")
</code></pre>
<h2 id="-實用工具函數"><a class="header" href="#-實用工具函數">🛠️ 實用工具函數</a></h2>
<h3 id="1-url-工具"><a class="header" href="#1-url-工具">1. URL 工具</a></h3>
<pre><code class="language-mojo">def normalize_url(base_url: String, relative_url: String) -&gt; String:
    """規範化 URL"""
    let urllib = Python.import_module("urllib.parse")
    return str(urllib.urljoin(base_url, relative_url))

def is_valid_url(url: String) -&gt; Bool:
    """檢查 URL 是否有效"""
    let urllib = Python.import_module("urllib.parse")
    let parsed = urllib.urlparse(url)
    return bool(parsed.netloc and parsed.scheme)
</code></pre>
<h3 id="2-數據處理工具"><a class="header" href="#2-數據處理工具">2. 數據處理工具</a></h3>
<pre><code class="language-mojo">def clean_text(text: PythonObject) -&gt; String:
    """清理文本數據"""
    let re = Python.import_module("re")
    
    # 移除多餘空白
    cleaned = re.sub(r'\s+', ' ', str(text))
    
    # 移除特殊字符
    cleaned = re.sub(r'[^\w\s\u4e00-\u9fff]', '', cleaned)
    
    return str(cleaned).strip()

def extract_emails(text: String) -&gt; PythonObject:
    """提取電子郵件地址"""
    let re = Python.import_module("re")
    let pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    return re.findall(pattern, text)

def extract_phone_numbers(text: String) -&gt; PythonObject:
    """提取電話號碼（台灣格式）"""
    let re = Python.import_module("re")
    let patterns = [
        r'09\d{8}',           # 手機號碼
        r'0\d{1,2}-\d{7,8}',  # 市話
        r'\(\d{2,3}\)\d{7,8}' # 括號格式
    ]
    
    let results = Python.list()
    for pattern in patterns:
        let matches = re.findall(pattern, text)
        results.extend(matches)
    
    return results
</code></pre>
<h3 id="3-數據存儲工具"><a class="header" href="#3-數據存儲工具">3. 數據存儲工具</a></h3>
<pre><code class="language-mojo">def save_to_csv(data: PythonObject, filename: String):
    """保存數據到 CSV"""
    let pandas = Python.import_module("pandas")
    
    try:
        let df = pandas.DataFrame(data)
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"💾 數據已保存到 {filename}")
    except Exception as e:
        print(f"💥 CSV 保存失敗: {e}")

def save_to_json(data: PythonObject, filename: String):
    """保存數據到 JSON"""
    let json = Python.import_module("json")
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"💾 數據已保存到 {filename}")
    except Exception as e:
        print(f"💥 JSON 保存失敗: {e}")
</code></pre>
<h2 id="-最佳實踐"><a class="header" href="#-最佳實踐">📋 最佳實踐</a></h2>
<h3 id="1-尊重-robotstxt"><a class="header" href="#1-尊重-robotstxt">1. 尊重 robots.txt</a></h3>
<pre><code class="language-mojo">def check_robots_txt(base_url: String) -&gt; Bool:
    """檢查 robots.txt"""
    let urllib = Python.import_module("urllib.robotparser")
    
    let robots_url = base_url.rstrip('/') + '/robots.txt'
    let rp = urllib.RobotFileParser()
    rp.set_url(robots_url)
    
    try:
        rp.read()
        return rp.can_fetch('*', base_url)
    except:
        return True  # 如果無法讀取，假設允許
</code></pre>
<h3 id="2-請求限制"><a class="header" href="#2-請求限制">2. 請求限制</a></h3>
<pre><code class="language-mojo">struct RateLimiter:
    """請求速率限制器"""
    var last_request_time: Float64
    var min_interval: Float64
    
    fn __init__(inout self, requests_per_second: Float64):
        self.last_request_time = 0.0
        self.min_interval = 1.0 / requests_per_second
    
    fn wait_if_needed(inout self):
        """如有需要則等待"""
        let time = Python.import_module("time")
        let current_time = float(time.time())
        
        let time_since_last = current_time - self.last_request_time
        if time_since_last &lt; self.min_interval:
            let wait_time = self.min_interval - time_since_last
            time.sleep(wait_time)
        
        self.last_request_time = float(time.time())
</code></pre>
<h3 id="3-錯誤處理"><a class="header" href="#3-錯誤處理">3. 錯誤處理</a></h3>
<pre><code class="language-mojo">def robust_crawl(url: String) -&gt; PythonObject:
    """具有強健錯誤處理的爬蟲函數"""
    let requests = Python.import_module("requests")
    let time = Python.import_module("time")
    
    let max_retries = 3
    let backoff_factor = 2
    
    for attempt in range(max_retries):
        try:
            let response = requests.get(
                url,
                timeout=10,
                headers={"User-Agent": "MojoCrawler/1.0"}
            )
            
            if response.status_code == 200:
                return response
            elif response.status_code == 429:
                let wait_time = backoff_factor ** attempt
                print(f"⏳ 請求限制，等待 {wait_time} 秒...")
                time.sleep(wait_time)
            else:
                print(f"❌ HTTP {response.status_code}")
                
        except Exception as e:
            print(f"🔄 嘗試 {attempt + 1}: {e}")
            if attempt &lt; max_retries - 1:
                time.sleep(backoff_factor ** attempt)
    
    raise Error("所有嘗試都失敗了")
</code></pre>
<h2 id="-常見問題"><a class="header" href="#-常見問題">💡 常見問題</a></h2>
<h3 id="q-mojo-相比-python-有什麼優勢"><a class="header" href="#q-mojo-相比-python-有什麼優勢">Q: Mojo 相比 Python 有什麼優勢？</a></h3>
<p><strong>A:</strong> Mojo 在爬蟲方面的優勢：</p>
<ul>
<li><strong>性能</strong>: 比 Python 快 10-100 倍</li>
<li><strong>記憶體效率</strong>: 更好的記憶體管理</li>
<li><strong>並行處理</strong>: 原生支援並行計算</li>
<li><strong>兼容性</strong>: 可以直接使用 Python 套件</li>
</ul>
<h3 id="q-如何處理反爬蟲機制"><a class="header" href="#q-如何處理反爬蟲機制">Q: 如何處理反爬蟲機制？</a></h3>
<p><strong>A:</strong> 常見策略：</p>
<pre><code class="language-mojo"># 1. 隨機 User-Agent
let user_agents = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36"
]

# 2. 使用代理
let proxies = {
    "http": "http://proxy:port",
    "https": "https://proxy:port"
}

# 3. 模擬真實行為
time.sleep(random.uniform(1, 3))
</code></pre>
<h3 id="q-如何處理-javascript-渲染的頁面"><a class="header" href="#q-如何處理-javascript-渲染的頁面">Q: 如何處理 JavaScript 渲染的頁面？</a></h3>
<p><strong>A:</strong> 使用 Selenium：</p>
<pre><code class="language-mojo">def crawl_js_page(url: String) -&gt; PythonObject:
    let selenium = Python.import_module("selenium")
    let webdriver = selenium.webdriver
    
    let driver = webdriver.Chrome()
    driver.get(url)
    
    # 等待頁面載入
    let time = Python.import_module("time")
    time.sleep(3)
    
    let content = driver.page_source
    driver.quit()
    
    return content
</code></pre>
<h3 id="q-如何進行分散式爬蟲"><a class="header" href="#q-如何進行分散式爬蟲">Q: 如何進行分散式爬蟲？</a></h3>
<p><strong>A:</strong> 可以結合 Celery 或 RQ：</p>
<pre><code class="language-mojo"># 任務分發
def distribute_urls(urls: PythonObject, num_workers: Int) -&gt; PythonObject:
    let chunks = Python.list()
    let chunk_size = len(urls) // num_workers
    
    for i in range(num_workers):
        let start = i * chunk_size
        let end = start + chunk_size if i &lt; num_workers - 1 else len(urls)
        chunks.append(urls[start:end])
    
    return chunks
</code></pre>
<h2 id="-完整範例運行"><a class="header" href="#-完整範例運行">🎯 完整範例運行</a></h2>
<pre><code class="language-bash"># 1. 創建項目目錄
mkdir mojo-crawler &amp;&amp; cd mojo-crawler

# 2. 創建並運行爬蟲
echo '# 上面的完整代碼' &gt; crawler.mojo
mojo crawler.mojo

# 3. 查看結果
cat crawl_results.json
</code></pre>
<h2 id="-進階學習資源"><a class="header" href="#-進階學習資源">📚 進階學習資源</a></h2>
<ul>
<li><a href="https://docs.modular.com/mojo/">Mojo 官方文檔</a></li>
<li><a href="https://discord.gg/modular">Modular 開發者社群</a></li>
<li><a href="https://github.com/modularml/mojo">Mojo GitHub 範例</a></li>
</ul>
<hr />
<p><strong>注意</strong>: 請務必遵守目標網站的使用條款和 robots.txt 規則，進行合理合法的數據收集。</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../mojo/mojo.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../zig/zig.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../mojo/mojo.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../zig/zig.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>



        <script>
            window.playground_line_numbers = true;
        </script>

        <script>
            window.playground_copyable = true;
        </script>

        <script src="../ace.js"></script>
        <script src="../mode-rust.js"></script>
        <script src="../editor.js"></script>
        <script src="../theme-dawn.js"></script>
        <script src="../theme-tomorrow_night.js"></script>

        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../mermaid.min.js"></script>
        <script src="../mermaid-init.js"></script>



    </div>
    </body>
</html>
