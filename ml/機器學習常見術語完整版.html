<!DOCTYPE HTML>
<html lang="zh" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>機器學習常見術語完整版 - Jason&#x27;s Notes</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "rust";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Jason&#x27;s Notes</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/shihyu/jason_note" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="機器學習常見術語白話解釋-"><a class="header" href="#機器學習常見術語白話解釋-">機器學習常見術語白話解釋 🎓</a></h1>
<h2 id="完整版功能--解決的問題"><a class="header" href="#完整版功能--解決的問題">完整版：功能 + 解決的問題</a></h2>
<hr />
<h2 id="-1-資料相關"><a class="header" href="#-1-資料相關">📊 1. 資料相關</a></h2>
<h3 id="應變數dependent-variable"><a class="header" href="#應變數dependent-variable">應變數（Dependent Variable）</a></h3>
<p><strong>是什麼：</strong> 你想要預測的目標</p>
<p><strong>白話：</strong> 就是「答案」</p>
<p><strong>功能：</strong></p>
<ul>
<li>定義機器學習任務的目標</li>
<li>模型訓練的依據</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 沒有明確目標 → 不知道要預測什麼</li>
<li>✅ 定義應變數 → 清楚知道模型要學什麼</li>
</ul>
<p><strong>例子：</strong></p>
<ul>
<li>預測房價 → 應變數是「房價」</li>
<li>預測會不會下雨 → 應變數是「下雨/不下雨」</li>
<li>預測花的品種 → 應變數是「品種（A/B/C）」</li>
<li>預測學生成績 → 應變數是「考試分數」</li>
</ul>
<p><strong>程式碼：</strong></p>
<pre><code class="language-python">y = df['房價']  # 這是應變數（目標）
</code></pre>
<hr />
<h3 id="自變數independent-variable"><a class="header" href="#自變數independent-variable">自變數（Independent Variable）</a></h3>
<p><strong>是什麼：</strong> 用來預測答案的線索</p>
<p><strong>白話：</strong> 就是「參考資料」</p>
<p><strong>功能：</strong></p>
<ul>
<li>提供預測所需的資訊</li>
<li>影響應變數的因素</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 沒有自變數 → 無法預測</li>
<li>✅ 選對自變數 → 預測更準確</li>
<li>⚠️ 自變數太少 → 資訊不足，預測不準</li>
<li>⚠️ 自變數太多 → 雜訊干擾，反而變差</li>
</ul>
<p><strong>例子：</strong></p>
<ul>
<li>預測房價 → 自變數是「坪數、房間數、地段、屋齡」</li>
<li>預測會不會下雨 → 自變數是「溫度、濕度、氣壓、風速」</li>
<li>預測花的品種 → 自變數是「花瓣長度、花瓣寬度、花萼長度」</li>
<li>預測學生成績 → 自變數是「讀書時間、出席率、作業完成度」</li>
</ul>
<p><strong>程式碼：</strong></p>
<pre><code class="language-python">X = df[['坪數', '房間數', '屋齡']]  # 這些是自變數（特徵）
</code></pre>
<p><strong>關係圖：</strong></p>
<pre><code>自變數（線索）          應變數（答案）
坪數 = 30 坪
房間數 = 3 房      →    房價 = 1500 萬
屋齡 = 5 年
地段 = 市中心
</code></pre>
<hr />
<h2 id="-2-模型架構相關"><a class="header" href="#-2-模型架構相關">🧠 2. 模型架構相關</a></h2>
<h3 id="激活函數activation-function"><a class="header" href="#激活函數activation-function">激活函數（Activation Function）</a></h3>
<p><strong>是什麼：</strong> 決定神經元要不要「興奮」的開關</p>
<p><strong>白話：</strong> 就像是「判斷規則」，決定訊號要不要傳下去</p>
<p><strong>功能：</strong></p>
<ol>
<li>引入非線性（讓神經網絡能學習複雜模式）</li>
<li>控制訊號傳遞</li>
<li>影響梯度傳播</li>
</ol>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 沒有激活函數 → 多層網絡等於單層（無法學複雜規律）</li>
<li>✅ 使用激活函數 → 可以學習非線性關係（如曲線、複雜分類邊界）</li>
<li>✅ 選對激活函數 → 避免梯度消失，深層網絡才能訓練</li>
</ul>
<hr />
<h4 id="relu隱藏層最常用"><a class="header" href="#relu隱藏層最常用">ReLU（隱藏層最常用）⭐⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">activation='relu'
</code></pre>
<p><strong>規則：</strong> 負數變 0，正數不變</p>
<ul>
<li><code>ReLU(5) = 5</code></li>
<li><code>ReLU(-3) = 0</code></li>
</ul>
<p><strong>比喻：</strong> 像考試「不及格的通通算 0 分」</p>
<p><strong>功能：</strong></p>
<ul>
<li>加速訓練（計算簡單）</li>
<li>避免梯度消失</li>
<li>產生稀疏性（有些神經元輸出 0）</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ Sigmoid/Tanh 梯度消失 → 深層網絡訓練困難</li>
<li>✅ ReLU 梯度不衰減 → 可以訓練 50+ 層的深度網絡</li>
<li>✅ 計算速度快 → 訓練時間大幅縮短</li>
</ul>
<p><strong>缺點（Dying ReLU）：</strong></p>
<ul>
<li>神經元輸出變負數後，梯度永遠是 0，神經元「死掉」</li>
</ul>
<p><strong>用在：</strong> 隱藏層（無論分類或回歸）</p>
<hr />
<h4 id="leaky-relu改良版-relu"><a class="header" href="#leaky-relu改良版-relu">Leaky ReLU（改良版 ReLU）⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">from keras.layers import LeakyReLU
model.add(Dense(64))
model.add(LeakyReLU(alpha=0.01))
</code></pre>
<p><strong>規則：</strong></p>
<ul>
<li><code>x &gt; 0: y = x</code> （梯度 = 1）</li>
<li><code>x &lt; 0: y = 0.01x</code> （梯度 = 0.01）</li>
</ul>
<p><strong>功能：</strong></p>
<ul>
<li>解決 Dying ReLU 問題</li>
<li>負數區域仍有小梯度</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ ReLU 神經元會死掉 → 浪費模型容量</li>
<li>✅ Leaky ReLU 永遠有梯度 → 所有神經元都能學習</li>
</ul>
<p><strong>用在：</strong> 隱藏層（比 ReLU 更穩定）</p>
<hr />
<h4 id="eluexponential-linear-unit"><a class="header" href="#eluexponential-linear-unit">ELU（Exponential Linear Unit）⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">activation='elu'
</code></pre>
<p><strong>功能：</strong></p>
<ul>
<li>負數區域平滑曲線</li>
<li>輸出均值接近 0</li>
<li>訓練更穩定</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ ReLU 輸出均值 &gt; 0 → 訓練不穩定</li>
<li>✅ ELU 均值接近 0 → 加速收斂</li>
</ul>
<p><strong>缺點：</strong> 計算比 ReLU 慢</p>
<p><strong>用在：</strong> 隱藏層（要求高穩定性時）</p>
<hr />
<h4 id="sigmoid二分類輸出層用"><a class="header" href="#sigmoid二分類輸出層用">Sigmoid（二分類輸出層用）⭐⭐</a></h4>
<pre><code class="language-python">activation='sigmoid'
</code></pre>
<p><strong>規則：</strong> 把任何數字壓縮到 0~1 之間</p>
<p><strong>比喻：</strong> 像「信心程度」，0 = 完全沒信心，1 = 100% 確定</p>
<p><strong>功能：</strong></p>
<ul>
<li>輸出機率值（0 到 1）</li>
<li>適合二分類問題</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 輸出是任意數字 → 無法解釋為機率</li>
<li>✅ Sigmoid 輸出 0~1 → 可解釋為「是」的機率</li>
</ul>
<p><strong>缺點（梯度消失）：</strong></p>
<ul>
<li>梯度最大只有 0.25</li>
<li>多層相乘：0.25 × 0.25 × 0.25 × ... → 接近 0</li>
<li>深層網絡（&gt;5 層）訓練困難</li>
</ul>
<p><strong>比喻：</strong></p>
<pre><code>每層都打 7 折：
100 → 70 → 49 → 34 → 24 → 17 → 12 → 8 → 6 → 4 → 3
傳到第 10 層只剩 3%！
</code></pre>
<p><strong>用在：</strong> 二分類問題的輸出層（例：垃圾郵件判斷）</p>
<p><strong>輸出例子：</strong> 0.8 表示「80% 機率是垃圾郵件」</p>
<hr />
<h4 id="tanh"><a class="header" href="#tanh">Tanh⭐⭐</a></h4>
<pre><code class="language-python">activation='tanh'
</code></pre>
<p><strong>規則：</strong> 把數字壓縮到 -1~1 之間</p>
<p><strong>功能：</strong></p>
<ul>
<li>輸出零中心（比 Sigmoid 好）</li>
<li>適合 RNN</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ Sigmoid 輸出 0~1，不是零中心 → 訓練較慢</li>
<li>✅ Tanh 輸出 -1~1，零中心 → 訓練稍快</li>
</ul>
<p><strong>缺點：</strong> 仍有梯度消失問題（但比 Sigmoid 輕微）</p>
<p><strong>用在：</strong> RNN（循環神經網絡）的隱藏層</p>
<hr />
<h4 id="softmax多分類輸出層用"><a class="header" href="#softmax多分類輸出層用">Softmax（多分類輸出層用）⭐⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">activation='softmax'
</code></pre>
<p><strong>規則：</strong> 把數字變成機率，加起來 = 1</p>
<p><strong>比喻：</strong> 像「投票結果」，每個選項都有機率</p>
<p><strong>功能：</strong></p>
<ul>
<li>輸出多個類別的機率分佈</li>
<li>所有機率總和 = 1</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 輸出任意數字 → 無法比較類別</li>
<li>✅ Softmax 輸出機率 → 可以看出「最可能的類別」</li>
</ul>
<p><strong>用在：</strong> 多分類問題的輸出層（例：Iris 花種類）</p>
<p><strong>輸出例子：</strong> [0.7, 0.2, 0.1] 表示「70% 是 A、20% 是 B、10% 是 C」</p>
<hr />
<h4 id="linear--none回歸輸出層用"><a class="header" href="#linear--none回歸輸出層用">Linear / None（回歸輸出層用）⭐⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">activation=None  # 或 'linear'
</code></pre>
<p><strong>規則：</strong> 數字直接輸出，不做轉換</p>
<p><strong>比喻：</strong> 像「實際測量值」</p>
<p><strong>功能：</strong></p>
<ul>
<li>輸出任意實數</li>
<li>不限制範圍</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 用 Sigmoid/Softmax → 輸出被限制範圍</li>
<li>✅ 不用激活函數 → 可以預測任意數值（如房價 1523.5 萬）</li>
</ul>
<p><strong>用在：</strong> 回歸問題的輸出層</p>
<p><strong>輸出例子：</strong> 1523.5（房價 1523.5 萬）</p>
<hr />
<h3 id="-激活函數快速選擇表"><a class="header" href="#-激活函數快速選擇表">📋 激活函數快速選擇表</a></h3>
<div class="table-wrapper"><table><thead><tr><th>問題類型</th><th>輸出層激活函數</th><th>隱藏層激活函數</th><th>解決的核心問題</th></tr></thead><tbody>
<tr><td>回歸（預測數值）</td><td>None / linear</td><td>ReLU</td><td>預測連續數值</td></tr>
<tr><td>二分類（是/否）</td><td>sigmoid</td><td>ReLU</td><td>輸出機率（0~1）</td></tr>
<tr><td>多分類（選一個）</td><td>softmax</td><td>ReLU</td><td>輸出機率分佈</td></tr>
</tbody></table>
</div><div class="table-wrapper"><table><thead><tr><th>激活函數</th><th>梯度消失問題</th><th>適用場景</th><th>推薦度</th></tr></thead><tbody>
<tr><td><strong>Sigmoid</strong></td><td>❌ 嚴重</td><td>輸出層（二分類）</td><td>⭐⭐</td></tr>
<tr><td><strong>Tanh</strong></td><td>❌ 中等</td><td>RNN</td><td>⭐⭐</td></tr>
<tr><td><strong>ReLU</strong></td><td>✅ 解決</td><td>隱藏層（最常用）</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>Leaky ReLU</strong></td><td>✅ 解決</td><td>隱藏層（更穩定）</td><td>⭐⭐⭐⭐</td></tr>
<tr><td><strong>ELU</strong></td><td>✅ 解決</td><td>隱藏層（計算較慢）</td><td>⭐⭐⭐⭐</td></tr>
<tr><td><strong>Softmax</strong></td><td>N/A</td><td>輸出層（多分類）</td><td>⭐⭐⭐⭐⭐</td></tr>
</tbody></table>
</div>
<hr />
<h3 id="-深入理解梯度消失問題"><a class="header" href="#-深入理解梯度消失問題">🔍 深入理解：梯度消失問題</a></h3>
<p><strong>什麼是梯度消失？</strong></p>
<p><strong>白話：</strong> 深層神經網絡訓練時，越前面的層「學不到東西」</p>
<p><strong>比喻：</strong></p>
<pre><code>傳話遊戲（10 個人排成一列）：
第 1 個人說：「今天天氣很好」
傳到第 10 個人：「...什麼？聽不清楚」

→ 訊息越傳越弱，最後消失了
→ 這就是梯度消失！
</code></pre>
<p><strong>技術原因：</strong>
反向傳播時，梯度（調整幅度）會一層層相乘，如果每層都乘以 &lt; 1 的數字，最後會變得超級小，接近 0。</p>
<p><strong>為什麼 Sigmoid/Tanh 容易梯度消失：</strong></p>
<pre><code>Sigmoid 梯度最大 = 0.25
10 層網絡：0.25¹⁰ = 0.00000095（幾乎是 0！）

前面的層收到的梯度 ≈ 0
→ 權重幾乎不更新
→ 學不到東西
</code></pre>
<p><strong>為什麼 ReLU 能解決：</strong></p>
<pre><code>ReLU 正數區域梯度 = 1
10 層網絡：1¹⁰ = 1（不衰減！）

前面的層仍能收到有效梯度
→ 權重正常更新
→ 可以學習
</code></pre>
<hr />
<h3 id="損失函數loss-function"><a class="header" href="#損失函數loss-function">損失函數（Loss Function）</a></h3>
<p><strong>是什麼：</strong> 衡量模型預測有多爛的分數</p>
<p><strong>白話：</strong> 就是「錯誤程度」，越小越好（0 分最好）</p>
<p><strong>功能：</strong></p>
<ul>
<li>量化模型的預測誤差</li>
<li>提供優化方向</li>
<li>引導模型改進</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 不知道模型好不好 → 無法改進</li>
<li>✅ 有損失函數 → 知道哪裡錯了，怎麼改</li>
<li>✅ 選對損失函數 → 模型學習更有效</li>
</ul>
<p><strong>常見類型：</strong></p>
<hr />
<h4 id="mse均方誤差--回歸用-"><a class="header" href="#mse均方誤差--回歸用-">MSE（均方誤差）- 回歸用 ⭐⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">loss='mse'
</code></pre>
<p><strong>算法：</strong> (預測值 - 真實值)² 的平均</p>
<p><strong>功能：</strong></p>
<ul>
<li>懲罰大錯誤（誤差會被平方放大）</li>
<li>數學性質好，容易優化</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 大小錯誤同等對待 → 不合理</li>
<li>✅ MSE 懲罰大錯誤 → 模型更重視離群值</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code>預測 3 間房價：
- 房 1：真實 1500 萬，預測 1600 萬 → (100)² = 10,000
- 房 2：真實 2000 萬，預測 1950 萬 → (50)² = 2,500
- 房 3：真實 1800 萬，預測 1800 萬 → (0)² = 0
MSE = (10,000 + 2,500 + 0) ÷ 3 = 4,166.67
</code></pre>
<p><strong>特點：</strong> 對異常值敏感（差很多會被放大懲罰）</p>
<hr />
<h4 id="mae平均絕對誤差--回歸用-"><a class="header" href="#mae平均絕對誤差--回歸用-">MAE（平均絕對誤差）- 回歸用 ⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">loss='mae'
</code></pre>
<p><strong>算法：</strong> |預測值 - 真實值| 的平均</p>
<p><strong>功能：</strong></p>
<ul>
<li>平等對待所有誤差</li>
<li>對異常值不敏感</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ MSE 對異常值太敏感 → 可能被極端值主導</li>
<li>✅ MAE 穩健 → 不會被少數極端值影響太多</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code>預測 3 間房價：
- 房 1：真實 1500 萬，預測 1600 萬 → |100| = 100
- 房 2：真實 2000 萬，預測 1950 萬 → |50| = 50
- 房 3：真實 1800 萬，預測 1800 萬 → |0| = 0
MAE = (100 + 50 + 0) ÷ 3 = 50 萬
</code></pre>
<p><strong>白話：</strong> 「平均錯了 50 萬」</p>
<p><strong>選擇建議：</strong></p>
<ul>
<li>資料有離群值 → 用 MAE</li>
<li>希望懲罰大錯誤 → 用 MSE</li>
</ul>
<hr />
<h4 id="binary-crossentropy二分類用"><a class="header" href="#binary-crossentropy二分類用">Binary Crossentropy（二分類用）⭐⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">loss='binary_crossentropy'
</code></pre>
<p><strong>功能：</strong></p>
<ul>
<li>衡量機率預測的準確度</li>
<li>懲罰「很有信心但猜錯」</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 用 MSE 做分類 → 不適合機率預測</li>
<li>✅ 用 Crossentropy → 針對機率分佈優化</li>
</ul>
<p><strong>用在：</strong> 是/否問題</p>
<p><strong>例子：</strong> 判斷郵件是不是垃圾郵件</p>
<p><strong>懲罰機制：</strong></p>
<pre><code>真實：垃圾郵件（1）
預測：0.9（90% 信心） → 損失小 ✓
預測：0.1（10% 信心） → 損失大 ✗（很有信心但錯了！）
</code></pre>
<hr />
<h4 id="categorical-crossentropy多分類用"><a class="header" href="#categorical-crossentropy多分類用">Categorical Crossentropy（多分類用）⭐⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">loss='categorical_crossentropy'
</code></pre>
<p><strong>功能：</strong></p>
<ul>
<li>衡量多類別機率預測的準確度</li>
<li>引導模型輸出正確類別的高機率</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 二分類損失無法處理多類別</li>
<li>✅ Categorical Crossentropy 處理 N 個類別</li>
</ul>
<p><strong>用在：</strong> 多個類別選一個</p>
<p><strong>例子：</strong> 判斷 Iris 花是 A、B、C 哪一種</p>
<p><strong>懲罰機制：</strong></p>
<pre><code>真實：類別 A
預測：[0.8, 0.1, 0.1] → 損失小 ✓（正確類別機率高）
預測：[0.2, 0.5, 0.3] → 損失大 ✗（正確類別機率低）
</code></pre>
<hr />
<h3 id="-損失函數快速選擇表"><a class="header" href="#-損失函數快速選擇表">📋 損失函數快速選擇表</a></h3>
<div class="table-wrapper"><table><thead><tr><th>問題類型</th><th>損失函數</th><th>何時用</th></tr></thead><tbody>
<tr><td>回歸（預測數值）</td><td>MSE</td><td>標準選擇，懲罰大錯誤</td></tr>
<tr><td>回歸（有離群值）</td><td>MAE</td><td>對異常值穩健</td></tr>
<tr><td>二分類（是/否）</td><td>binary_crossentropy</td><td>機率預測</td></tr>
<tr><td>多分類（選一個）</td><td>categorical_crossentropy</td><td>機率分佈預測</td></tr>
</tbody></table>
</div>
<p><strong>生活比喻：</strong></p>
<pre><code>考試考 100 題：
- 錯 5 題 → 損失函數 = 5（越小越好）
- 錯 50 題 → 損失函數 = 50（很糟）
- 全對 → 損失函數 = 0（完美！）
</code></pre>
<hr />
<h2 id="-3-訓練過程相關"><a class="header" href="#-3-訓練過程相關">🎯 3. 訓練過程相關</a></h2>
<h3 id="優化器optimizer"><a class="header" href="#優化器optimizer">優化器（Optimizer）</a></h3>
<p><strong>是什麼：</strong> 決定模型如何學習、改進</p>
<p><strong>白話：</strong> 就是「學習方法」</p>
<p><strong>功能：</strong></p>
<ul>
<li>根據損失函數更新權重</li>
<li>決定學習的路徑和速度</li>
<li>影響訓練穩定性和速度</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 不知道怎麼更新權重 → 模型無法學習</li>
<li>✅ 使用優化器 → 自動找到最佳參數</li>
<li>✅ 選對優化器 → 更快收斂、更穩定</li>
</ul>
<p><strong>常見類型：</strong></p>
<hr />
<h4 id="adam最常用"><a class="header" href="#adam最常用">Adam（最常用）⭐⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">optimizer='adam'
</code></pre>
<p><strong>功能：</strong></p>
<ul>
<li>自動調整每個參數的學習率</li>
<li>結合動量（Momentum）和 RMSprop 的優點</li>
<li>適應性強</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ SGD 需要手動調參 → 費時費力</li>
<li>✅ Adam 自動適應 → 開箱即用</li>
<li>✅ 對學習率不敏感 → 容錯率高</li>
</ul>
<p><strong>比喻：</strong> 像「聰明的學生」，知道哪裡該多花時間，哪裡可以快速通過</p>
<p><strong>為什麼最常用：</strong></p>
<ul>
<li>效果好</li>
<li>不需要太多調參</li>
<li>適用於大部分問題</li>
</ul>
<hr />
<h4 id="sgd隨機梯度下降"><a class="header" href="#sgd隨機梯度下降">SGD（隨機梯度下降）⭐⭐⭐</a></h4>
<pre><code class="language-python">optimizer='sgd'
optimizer=SGD(learning_rate=0.01, momentum=0.9)
</code></pre>
<p><strong>功能：</strong></p>
<ul>
<li>最基礎的優化方法</li>
<li>每次隨機選一批資料更新權重</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 全部資料一起算 → 記憶體不夠、速度慢</li>
<li>✅ SGD 分批計算 → 速度快、記憶體省</li>
</ul>
<p><strong>缺點：</strong></p>
<ul>
<li>需要手動調整學習率</li>
<li>可能卡在局部最優解</li>
<li>訓練不穩定</li>
</ul>
<p><strong>比喻：</strong> 像「按部就班的學生」，一步一步來，但可能走錯路</p>
<p><strong>改進版：SGD + Momentum</strong></p>
<pre><code class="language-python">optimizer=SGD(learning_rate=0.01, momentum=0.9)
</code></pre>
<ul>
<li>加入「慣性」，減少震盪</li>
<li>更容易跳出局部最優解</li>
</ul>
<hr />
<h4 id="rmsprop-"><a class="header" href="#rmsprop-">RMSprop ⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">optimizer='rmsprop'
</code></pre>
<p><strong>功能：</strong></p>
<ul>
<li>自適應學習率</li>
<li>適合處理 RNN（循環神經網絡）</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 固定學習率 → 不同參數需要不同速度</li>
<li>✅ RMSprop 自適應 → 每個參數有自己的學習率</li>
</ul>
<p><strong>比喻：</strong> 專門處理序列資料的學習方式</p>
<hr />
<h3 id="-優化器選擇建議"><a class="header" href="#-優化器選擇建議">📋 優化器選擇建議</a></h3>
<div class="table-wrapper"><table><thead><tr><th>優化器</th><th>特點</th><th>適用場景</th><th>推薦度</th></tr></thead><tbody>
<tr><td><strong>Adam</strong></td><td>自適應、容錯高</td><td>大部分問題（首選）</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>SGD</strong></td><td>簡單、需調參</td><td>經典模型、研究</td><td>⭐⭐⭐</td></tr>
<tr><td><strong>SGD + Momentum</strong></td><td>穩定、較快</td><td>圖像分類</td><td>⭐⭐⭐⭐</td></tr>
<tr><td><strong>RMSprop</strong></td><td>適合 RNN</td><td>時間序列、NLP</td><td>⭐⭐⭐⭐</td></tr>
</tbody></table>
</div>
<p><strong>新手建議：</strong> 先用 <code>Adam</code>，99% 的情況都夠用</p>
<hr />
<h3 id="學習率learning-rate"><a class="header" href="#學習率learning-rate">學習率（Learning Rate）</a></h3>
<p><strong>是什麼：</strong> 每次學習時調整的幅度</p>
<p><strong>白話：</strong> 就是「每次改進的步伐大小」</p>
<p><strong>功能：</strong></p>
<ul>
<li>控制參數更新的大小</li>
<li>影響訓練速度和穩定性</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 學習率太大 → 震盪不收斂，找不到最佳解</li>
<li>❌ 學習率太小 → 訓練超級慢，可能卡住</li>
<li>✅ 學習率適中 → 穩定且快速收斂</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code class="language-python">optimizer=Adam(learning_rate=0.001)  # 常用值
</code></pre>
<p><strong>比喻：</strong></p>
<pre><code>想像你在找山谷最低點（最佳解）：

學習率太大（0.5）：
→ 步伐太大，一直跨過最低點
→ 像「走太快會摔倒」
  ╱╲     ╱╲     ╱╲
 ↓  ↑   ↓  ↑   ↓  ↑  （來回震盪）

學習率太小（0.00001）：
→ 步伐太小，要走很久
→ 像「龜速前進」
  ╱         ╲
 ↓→→→→→→→→→↓  （太慢了）

學習率剛好（0.001 ~ 0.01）：
→ 穩定前進，順利找到最低點 ✓
  ╱    ╲
 ↓→→→↓  （穩定下降）
</code></pre>
<p><strong>常用值：</strong></p>
<ul>
<li>Adam：0.001（預設）</li>
<li>SGD：0.01 到 0.1</li>
<li>微調預訓練模型：0.0001（更小更穩）</li>
</ul>
<p><strong>進階技巧：學習率衰減</strong></p>
<pre><code class="language-python"># 訓練過程中逐漸降低學習率
from keras.callbacks import ReduceLROnPlateau
</code></pre>
<hr />
<h3 id="epoch訓練輪數"><a class="header" href="#epoch訓練輪數">Epoch（訓練輪數）</a></h3>
<p><strong>是什麼：</strong> 整個資料集訓練幾次</p>
<p><strong>白話：</strong> 就是「複習次數」</p>
<p><strong>功能：</strong></p>
<ul>
<li>讓模型多次看過所有資料</li>
<li>提高學習充分性</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ Epoch 太少 → 學習不充分（欠擬合）</li>
<li>❌ Epoch 太多 → 背答案（過擬合）</li>
<li>✅ Epoch 適中 → 學得剛好</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code class="language-python">model.fit(X, y, epochs=100)
</code></pre>
<p><strong>比喻：</strong></p>
<pre><code>準備考試有 100 題練習題：

epochs=1：
→ 每題只做 1 次
→ 可能記不熟

epochs=10：
→ 每題做 10 次
→ 開始有印象 ✓

epochs=100：
→ 每題做 100 次
→ 滾瓜爛熟 ✓

epochs=1000：
→ 每題做 1000 次
→ 過度背答案，不會舉一反三 ✗
</code></pre>
<p><strong>如何選擇：</strong></p>
<ol>
<li>觀察訓練曲線</li>
<li>使用 Early Stopping（表現不再提升就停止）</li>
<li>一般從 50-200 開始嘗試</li>
</ol>
<hr />
<h3 id="batch-size批次大小"><a class="header" href="#batch-size批次大小">Batch Size（批次大小）</a></h3>
<p><strong>是什麼：</strong> 一次餵多少筆資料給模型</p>
<p><strong>白話：</strong> 就是「一次看幾題」</p>
<p><strong>功能：</strong></p>
<ul>
<li>平衡計算效率和學習品質</li>
<li>影響梯度估計的準確性</li>
<li>影響記憶體使用</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 每次只看 1 筆 → 梯度不穩定、超級慢</li>
<li>❌ 一次看全部 → 記憶體爆炸、梯度不準</li>
<li>✅ 適中批次 → 速度和效果平衡</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code class="language-python">model.fit(X, y, batch_size=32)
</code></pre>
<p><strong>比喻：</strong></p>
<pre><code>有 1000 題練習題：

batch_size=1（逐筆學習）：
→ 做 1 題，馬上檢討 1 題
→ 優點：學習精細
→ 缺點：超級慢（檢討 1000 次）

batch_size=32（小批次）：
→ 做 32 題，檢討一次
→ 優點：速度適中，效果好 ✓
→ 檢討 1000÷32 ≈ 31 次

batch_size=1000（全部一起）：
→ 做完 1000 題，檢討一次
→ 優點：速度快（只檢討 1 次）
→ 缺點：可能學不好、記憶體爆炸
</code></pre>
<p><strong>常用值：</strong> 16、32、64、128</p>
<p><strong>如何選擇：</strong></p>
<ul>
<li>資料少 → 較小 batch (16, 32)</li>
<li>資料多 → 較大 batch (64, 128)</li>
<li>GPU 記憶體限制 → 調小直到不爆記憶體</li>
</ul>
<p><strong>記憶體關係：</strong></p>
<pre><code>Batch Size 越大 → GPU 記憶體用越多
如果出現 OOM（Out of Memory）→ 調小 batch size
</code></pre>
<hr />
<h2 id="-4-評估指標相關"><a class="header" href="#-4-評估指標相關">📈 4. 評估指標相關</a></h2>
<h3 id="分類問題指標"><a class="header" href="#分類問題指標">分類問題指標</a></h3>
<h4 id="accuracy準確率"><a class="header" href="#accuracy準確率">Accuracy（準確率）⭐⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">metrics=['accuracy']
</code></pre>
<p><strong>算法：</strong> 預測對的數量 ÷ 總數量</p>
<p><strong>功能：</strong></p>
<ul>
<li>最直觀的分類指標</li>
<li>快速了解整體表現</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 不知道模型好不好 → 無法評估</li>
<li>✅ 看準確率 → 立刻知道對錯比例</li>
</ul>
<p><strong>例子：</strong> 100 封郵件，判對 95 封 → 準確率 = 95%</p>
<p><strong>白話：</strong> 「答對率」</p>
<p><strong>缺點（類別不平衡時）：</strong></p>
<pre><code>100 封郵件：95 封正常、5 封垃圾
模型全猜「正常」→ 準確率 = 95%
但垃圾郵件完全沒抓到！
</code></pre>
<p><strong>何時不適用：</strong></p>
<ul>
<li>類別不平衡（如癌症檢測：99% 正常、1% 有癌）</li>
<li>此時應看 Precision、Recall、F1-score</li>
</ul>
<hr />
<h4 id="precision精確率"><a class="header" href="#precision精確率">Precision（精確率）⭐⭐⭐⭐</a></h4>
<p><strong>算法：</strong> 預測是垃圾郵件的，真的是垃圾郵件的比例</p>
<p><strong>功能：</strong></p>
<ul>
<li>衡量「誤判」的程度</li>
<li>重視「不要冤枉好人」</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 準確率高但誤判多 → Accuracy 無法反映</li>
<li>✅ Precision 低 → 知道誤判嚴重</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code>判斷 100 封是垃圾郵件，其中 90 封真的是
→ Precision = 90/100 = 90%
</code></pre>
<p><strong>白話：</strong> 「不要誤判好人」</p>
<p><strong>適用場景：</strong></p>
<ul>
<li>垃圾郵件過濾（不希望誤判正常郵件）</li>
<li>推薦系統（推薦的商品最好都是使用者想要的）</li>
</ul>
<hr />
<h4 id="recall召回率"><a class="header" href="#recall召回率">Recall（召回率）⭐⭐⭐⭐</a></h4>
<p><strong>算法：</strong> 真的是垃圾郵件的，被抓出來的比例</p>
<p><strong>功能：</strong></p>
<ul>
<li>衡量「漏掉」的程度</li>
<li>重視「不要漏掉壞人」</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 準確率高但漏掉很多 → Accuracy 無法反映</li>
<li>✅ Recall 低 → 知道漏掉太多</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code>有 100 封垃圾郵件，抓到 80 封
→ Recall = 80/100 = 80%
</code></pre>
<p><strong>白話：</strong> 「不要漏掉壞人」</p>
<p><strong>適用場景：</strong></p>
<ul>
<li>疾病檢測（不希望漏掉病人）</li>
<li>欺詐檢測（不希望漏掉詐騙案件）</li>
</ul>
<hr />
<h4 id="f1-score-"><a class="header" href="#f1-score-">F1-Score ⭐⭐⭐⭐⭐</a></h4>
<p><strong>算法：</strong> Precision 和 Recall 的調和平均</p>
<p><strong>功能：</strong></p>
<ul>
<li>平衡 Precision 和 Recall</li>
<li>單一指標綜合評估</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ Precision 和 Recall 互相矛盾 → 難以取捨</li>
<li>✅ F1-Score 綜合考量 → 一個數字看整體</li>
</ul>
<p><strong>公式：</strong></p>
<pre><code>F1 = 2 × (Precision × Recall) / (Precision + Recall)
</code></pre>
<p><strong>適用場景：</strong></p>
<ul>
<li>類別不平衡問題</li>
<li>需要同時兼顧「不誤判」和「不漏掉」</li>
</ul>
<hr />
<h3 id="-分類指標生活比喻抓小偷"><a class="header" href="#-分類指標生活比喻抓小偷">🎯 分類指標生活比喻（抓小偷）</a></h3>
<pre><code>街上有 10 個小偷，100 個路人：

模型 A：抓了 8 個人，全是小偷
→ Precision = 100%（抓到的都是小偷）✓
→ Recall = 80%（10 個小偷只抓到 8 個）
→ 適合：不想冤枉好人（如法律判決）

模型 B：抓了 50 個人，包含 10 個小偷和 40 個路人
→ Precision = 20%（抓錯很多路人）
→ Recall = 100%（小偷全抓到了）✓
→ 適合：不想漏掉壞人（如疾病篩檢）

模型 C：抓了 9 個人，9 個都是小偷
→ Precision = 100%（完美！）
→ Recall = 90%（很好！）
→ F1-Score = 94.7%（綜合最佳）✓
</code></pre>
<hr />
<h3 id="回歸問題指標"><a class="header" href="#回歸問題指標">回歸問題指標</a></h3>
<h4 id="mse均方誤差"><a class="header" href="#mse均方誤差">MSE（均方誤差）⭐⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">metrics=['mse']
</code></pre>
<p><strong>算法：</strong> (預測值 - 真實值)² 的平均</p>
<p><strong>功能：</strong></p>
<ul>
<li>衡量預測誤差</li>
<li>懲罰大錯誤</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 不知道預測有多準 → 無法評估</li>
<li>✅ MSE 量化誤差 → 知道平均錯多少</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code>預測 3 間房價：
- 房 1：真實 1500 萬，預測 1600 萬 → (100)² = 10,000
- 房 2：真實 2000 萬，預測 1950 萬 → (50)² = 2,500
- 房 3：真實 1800 萬，預測 1800 萬 → (0)² = 0
MSE = (10,000 + 2,500 + 0) ÷ 3 = 4,166.67
</code></pre>
<p><strong>特點：</strong> 對異常值非常敏感（誤差會被平方放大）</p>
<hr />
<h4 id="rmse均方根誤差"><a class="header" href="#rmse均方根誤差">RMSE（均方根誤差）⭐⭐⭐⭐⭐</a></h4>
<p><strong>算法：</strong> MSE 開根號</p>
<p><strong>功能：</strong></p>
<ul>
<li>和原始資料同單位</li>
<li>更容易解釋</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ MSE 單位是「平方」→ 不直觀（房價平方？）</li>
<li>✅ RMSE 單位和原始資料一樣 → 容易理解</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code>MSE = 4,166.67
RMSE = √4,166.67 ≈ 64.5 萬

白話：「平均誤差約 64.5 萬」
</code></pre>
<hr />
<h4 id="mae平均絕對誤差"><a class="header" href="#mae平均絕對誤差">MAE（平均絕對誤差）⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">metrics=['mae']
</code></pre>
<p><strong>算法：</strong> |預測值 - 真實值| 的平均</p>
<p><strong>功能：</strong></p>
<ul>
<li>平等對待所有誤差</li>
<li>直觀易懂</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ MSE 對異常值太敏感 → 被極端值主導</li>
<li>✅ MAE 穩健 → 反映整體誤差</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code>預測 3 間房價：
- 房 1：真實 1500 萬，預測 1600 萬 → |100| = 100
- 房 2：真實 2000 萬，預測 1950 萬 → |50| = 50
- 房 3：真實 1800 萬，預測 1800 萬 → |0| = 0
MAE = (100 + 50 + 0) ÷ 3 = 50 萬
</code></pre>
<p><strong>白話：</strong> 「平均錯了 50 萬」</p>
<hr />
<h4 id="r²決定係數"><a class="header" href="#r²決定係數">R²（決定係數）⭐⭐⭐⭐⭐</a></h4>
<p><strong>範圍：</strong> 0 到 1（越接近 1 越好）</p>
<p><strong>功能：</strong></p>
<ul>
<li>衡量模型解釋能力</li>
<li>和基準模型（預測平均值）比較</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ MSE/MAE 無法比較不同問題 → 不知道算好還是壞</li>
<li>✅ R² 標準化 → 容易比較</li>
</ul>
<p><strong>意義：</strong> 模型能解釋多少變異</p>
<p><strong>例子：</strong></p>
<pre><code>R² = 0.9 → 模型能解釋 90% 的變化，很好！
R² = 0.3 → 模型只能解釋 30% 的變化，不太好
R² = 0.0 → 模型和瞎猜一樣差
R² &lt; 0.0 → 模型比瞎猜還差（這很糟）
</code></pre>
<p><strong>白話：</strong> 「模型有多準」</p>
<hr />
<h3 id="-評估指標選擇建議"><a class="header" href="#-評估指標選擇建議">📋 評估指標選擇建議</a></h3>
<p><strong>分類問題：</strong></p>
<div class="table-wrapper"><table><thead><tr><th>情境</th><th>推薦指標</th><th>原因</th></tr></thead><tbody>
<tr><td>類別平衡</td><td>Accuracy</td><td>最直觀</td></tr>
<tr><td>類別不平衡</td><td>F1-Score</td><td>綜合考量</td></tr>
<tr><td>不想誤判（如法律）</td><td>Precision</td><td>寧可漏掉，不要冤枉</td></tr>
<tr><td>不想漏掉（如醫療）</td><td>Recall</td><td>寧可誤判，不要漏掉</td></tr>
</tbody></table>
</div>
<p><strong>回歸問題：</strong></p>
<div class="table-wrapper"><table><thead><tr><th>情境</th><th>推薦指標</th><th>原因</th></tr></thead><tbody>
<tr><td>標準回歸</td><td>RMSE</td><td>易解釋，懲罰大錯</td></tr>
<tr><td>有離群值</td><td>MAE</td><td>穩健</td></tr>
<tr><td>比較模型</td><td>R²</td><td>標準化，易比較</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="-5-資料處理相關"><a class="header" href="#-5-資料處理相關">🔧 5. 資料處理相關</a></h2>
<h3 id="標準化standardization"><a class="header" href="#標準化standardization">標準化（Standardization）⭐⭐⭐⭐⭐</a></h3>
<pre><code class="language-python">from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
</code></pre>
<p><strong>是什麼：</strong> 把數據變成「平均 0、標準差 1」</p>
<p><strong>功能：</strong></p>
<ul>
<li>統一不同特徵的量級</li>
<li>加速模型收斂</li>
<li>避免某些特徵主導模型</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 不同特徵範圍差很大 → 模型學習不平衡</li>
<li>❌ 坪數 (10-100) vs 距離 (0-5000) → 距離主導一切</li>
<li>✅ 標準化後範圍相近 → 模型公平對待所有特徵</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code>原始資料：
- 坪數：30（範圍 10~100，平均 50）
- 屋齡：5（範圍 0~50，平均 10）
- 距捷運：500 公尺（範圍 0~5000，平均 1000）

標準化後（平均 0，標準差 1）：
- 坪數：-0.5
- 屋齡：-0.3
- 距捷運：-0.4

→ 大家都在類似的範圍，模型學習更平衡
</code></pre>
<p><strong>何時用：</strong></p>
<ul>
<li>神經網絡（必用！）</li>
<li>SVM、邏輯迴歸</li>
<li>梯度下降算法</li>
</ul>
<hr />
<h3 id="正規化normalization"><a class="header" href="#正規化normalization">正規化（Normalization）⭐⭐⭐⭐</a></h3>
<pre><code class="language-python">from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)
</code></pre>
<p><strong>是什麼：</strong> 把數據壓縮到 0~1 之間</p>
<p><strong>功能：</strong></p>
<ul>
<li>統一數據範圍</li>
<li>保持原始分佈形狀</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 數據範圍不一致 → 影響某些算法</li>
<li>✅ 壓縮到 0~1 → 統一處理</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code>原始資料：
- 溫度：[10, 20, 30, 40]

正規化後：
- 溫度：[0, 0.33, 0.67, 1.0]

公式：(x - 最小值) ÷ (最大值 - 最小值)
</code></pre>
<p><strong>何時用：</strong></p>
<ul>
<li>圖像處理（像素 0-255 → 0-1）</li>
<li>神經網絡輸入</li>
<li>KNN、K-means</li>
</ul>
<p><strong>標準化 vs 正規化：</strong></p>
<div class="table-wrapper"><table><thead><tr><th>特性</th><th>標準化</th><th>正規化</th></tr></thead><tbody>
<tr><td>範圍</td><td>不固定（多在 -3~3）</td><td>0~1</td></tr>
<tr><td>平均</td><td>0</td><td>不一定</td></tr>
<tr><td>適用</td><td>神經網絡、SVM</td><td>圖像、距離算法</td></tr>
</tbody></table>
</div>
<hr />
<h3 id="one-hot-encoding獨熱編碼"><a class="header" href="#one-hot-encoding獨熱編碼">One-Hot Encoding（獨熱編碼）⭐⭐⭐⭐⭐</a></h3>
<pre><code class="language-python">from keras.utils import to_categorical
y_encoded = to_categorical(y, num_classes=3)
</code></pre>
<p><strong>是什麼：</strong> 把類別變成 0 和 1 的組合</p>
<p><strong>功能：</strong></p>
<ul>
<li>將類別資料轉成數字</li>
<li>避免類別間的「順序」誤解</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 直接用數字編碼 → 模型誤以為有大小關係</li>
</ul>
<pre><code>顏色：紅(1) &lt; 綠(2) &lt; 藍(3)
→ 模型會認為「藍色比紅色大」（錯誤！）
</code></pre>
<ul>
<li>✅ One-Hot 編碼 → 類別平等，無大小關係</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code>原始類別：
['紅色', '綠色', '藍色', '紅色']

錯誤做法（Label Encoding）：
[1, 2, 3, 1]
→ 模型認為：3 &gt; 2 &gt; 1（錯！）

正確做法（One-Hot Encoding）：
[[1, 0, 0],   ← 紅色
 [0, 1, 0],   ← 綠色
 [0, 0, 1],   ← 藍色
 [1, 0, 0]]   ← 紅色
→ 模型知道：這些是不同類別，沒有大小關係 ✓
</code></pre>
<p><strong>比喻：</strong> 像「複選題」，每個選項只能勾一個</p>
<p><strong>何時用：</strong></p>
<ul>
<li>分類問題的標籤（必用！）</li>
<li>類別型特徵（如：城市、顏色、品牌）</li>
</ul>
<hr />
<h3 id="label-encoding-"><a class="header" href="#label-encoding-">Label Encoding ⭐⭐⭐</a></h3>
<pre><code class="language-python">from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)
</code></pre>
<p><strong>是什麼：</strong> 把類別轉成數字</p>
<p><strong>功能：</strong></p>
<ul>
<li>簡單快速</li>
<li>節省記憶體</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 模型不能處理文字 → 轉成數字</li>
<li>✅ Label Encoding → 快速轉換</li>
</ul>
<p><strong>例子：</strong></p>
<pre><code>['紅', '綠', '藍'] → [0, 1, 2]
</code></pre>
<p><strong>何時用：</strong></p>
<ul>
<li>決策樹、隨機森林（可以用，不會誤解）</li>
<li>目標變數（y）</li>
</ul>
<p><strong>何時不用：</strong></p>
<ul>
<li>神經網絡、線性模型（會誤解大小關係）</li>
<li>類別特徵（應該用 One-Hot）</li>
</ul>
<hr />
<h2 id="-6-常見問題"><a class="header" href="#-6-常見問題">⚠️ 6. 常見問題</a></h2>
<h3 id="過擬合overfitting"><a class="header" href="#過擬合overfitting">過擬合（Overfitting）</a></h3>
<p><strong>是什麼：</strong> 模型「背答案」，只記住訓練資料</p>
<p><strong>功能：</strong> 提醒你模型太複雜了</p>
<p><strong>解決什麼問題的反面：</strong></p>
<ul>
<li>❌ 模型太複雜 → 過擬合</li>
<li>✅ 適當複雜度 → 泛化良好</li>
</ul>
<p><strong>症狀：</strong></p>
<pre><code>訓練集準確率：99% ✓
測試集準確率：60% ✗

→ 這就是過擬合！
</code></pre>
<p><strong>比喻：</strong></p>
<pre><code>學生只背考古題的答案：
- 考古題：100 分（因為背過）
- 新的題目：30 分（沒背過就不會）

→ 這就是過擬合！
</code></pre>
<p><strong>原因：</strong></p>
<ol>
<li>模型太複雜（層數太多、神經元太多）</li>
<li>訓練資料太少</li>
<li>訓練太久（epochs 太多）</li>
<li>沒有正規化</li>
</ol>
<p><strong>解決方法：</strong></p>
<h4 id="1-dropout-"><a class="header" href="#1-dropout-">1. Dropout ⭐⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">model.add(Dropout(0.5))
</code></pre>
<ul>
<li>隨機關閉 50% 神經元</li>
<li>防止過度依賴特定神經元</li>
</ul>
<h4 id="2-early-stopping-"><a class="header" href="#2-early-stopping-">2. Early Stopping ⭐⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">from keras.callbacks import EarlyStopping
early_stop = EarlyStopping(monitor='val_loss', patience=10)
model.fit(X, y, callbacks=[early_stop])
</code></pre>
<ul>
<li>驗證集表現不再提升就停止</li>
<li>避免過度訓練</li>
</ul>
<h4 id="3-增加訓練資料-"><a class="header" href="#3-增加訓練資料-">3. 增加訓練資料 ⭐⭐⭐⭐⭐</a></h4>
<ul>
<li>更多資料 → 更難背答案</li>
<li>Data Augmentation（資料增強）</li>
</ul>
<h4 id="4-正規化l1l2"><a class="header" href="#4-正規化l1l2">4. 正規化（L1/L2）⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">from keras.regularizers import l2
model.add(Dense(64, kernel_regularizer=l2(0.01)))
</code></pre>
<ul>
<li>懲罰過大的權重</li>
<li>強迫模型簡化</li>
</ul>
<h4 id="5-減少模型複雜度-"><a class="header" href="#5-減少模型複雜度-">5. 減少模型複雜度 ⭐⭐⭐</a></h4>
<pre><code class="language-python"># 原本：5 層，每層 128 神經元
# 改成：3 層，每層 64 神經元
</code></pre>
<hr />
<h3 id="欠擬合underfitting"><a class="header" href="#欠擬合underfitting">欠擬合（Underfitting）</a></h3>
<p><strong>是什麼：</strong> 模型太笨，學不到規律</p>
<p><strong>功能：</strong> 提醒你模型太簡單了</p>
<p><strong>解決什麼問題的反面：</strong></p>
<ul>
<li>❌ 模型太簡單 → 欠擬合</li>
<li>✅ 適當複雜度 → 學得好</li>
</ul>
<p><strong>症狀：</strong></p>
<pre><code>訓練集準確率：60% ✗
測試集準確率：58% ✗

→ 都很爛，這就是欠擬合！
</code></pre>
<p><strong>比喻：</strong></p>
<pre><code>學生完全不讀書：
- 考古題：30 分
- 新的題目：32 分

→ 都很爛，這就是欠擬合！
</code></pre>
<p><strong>原因：</strong></p>
<ol>
<li>模型太簡單（層數太少、神經元太少）</li>
<li>訓練不夠（epochs 太少）</li>
<li>正規化太強</li>
<li>學習率太小</li>
</ol>
<p><strong>解決方法：</strong></p>
<h4 id="1-增加模型複雜度-"><a class="header" href="#1-增加模型複雜度-">1. 增加模型複雜度 ⭐⭐⭐⭐⭐</a></h4>
<pre><code class="language-python"># 加更多層、更多神經元
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
</code></pre>
<h4 id="2-訓練更久-"><a class="header" href="#2-訓練更久-">2. 訓練更久 ⭐⭐⭐⭐</a></h4>
<pre><code class="language-python">model.fit(X, y, epochs=200)  # 增加 epochs
</code></pre>
<h4 id="3-減少正規化-"><a class="header" href="#3-減少正規化-">3. 減少正規化 ⭐⭐⭐</a></h4>
<pre><code class="language-python">model.add(Dropout(0.2))  # 從 0.5 降到 0.2
</code></pre>
<h4 id="4-增加特徵-"><a class="header" href="#4-增加特徵-">4. 增加特徵 ⭐⭐⭐⭐</a></h4>
<ul>
<li>加入更多有用的自變數</li>
<li>特徵工程</li>
</ul>
<hr />
<h3 id="dropout隨機丟棄"><a class="header" href="#dropout隨機丟棄">Dropout（隨機丟棄）⭐⭐⭐⭐⭐</a></h3>
<pre><code class="language-python">model.add(Dropout(0.5))
</code></pre>
<p><strong>是什麼：</strong> 訓練時隨機「關閉」一些神經元</p>
<p><strong>功能：</strong></p>
<ul>
<li>防止過擬合</li>
<li>增強泛化能力</li>
<li>模擬集成學習</li>
</ul>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 神經元過度依賴彼此 → 過擬合</li>
<li>✅ Dropout 強迫獨立學習 → 泛化更好</li>
</ul>
<p><strong>比喻：</strong></p>
<pre><code>考試練習時：
- 正常：100 個神經元一起工作
- Dropout(0.5)：隨機關掉 50 個，只用 50 個工作

→ 強迫模型不能依賴特定神經元
→ 就像「蒙眼練習」，增強適應能力
</code></pre>
<p><strong>數字意義：</strong></p>
<ul>
<li>Dropout(0.5)：關掉 50%</li>
<li>Dropout(0.3)：關掉 30%</li>
<li>Dropout(0.2)：關掉 20%</li>
<li>常用範圍：0.2 ~ 0.5</li>
</ul>
<p><strong>何時用：</strong></p>
<ul>
<li>隱藏層之後（防止過擬合）</li>
<li>模型出現過擬合時</li>
</ul>
<p><strong>注意：</strong></p>
<ul>
<li>測試時自動關閉 Dropout（用全部神經元）</li>
<li>輸出層不要用 Dropout</li>
</ul>
<hr />
<h2 id="-7-資料分割"><a class="header" href="#-7-資料分割">📋 7. 資料分割</a></h2>
<h3 id="訓練集training-set"><a class="header" href="#訓練集training-set">訓練集（Training Set）⭐⭐⭐⭐⭐</a></h3>
<p><strong>功能：</strong> 讓模型學習</p>
<p><strong>比例：</strong> 通常 60~80%</p>
<p><strong>比喻：</strong> 「練習題」</p>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 沒有訓練資料 → 模型無法學習</li>
<li>✅ 足夠訓練資料 → 模型學到規律</li>
</ul>
<hr />
<h3 id="驗證集validation-set"><a class="header" href="#驗證集validation-set">驗證集（Validation Set）⭐⭐⭐⭐⭐</a></h3>
<p><strong>功能：</strong></p>
<ul>
<li>調整超參數</li>
<li>監控過擬合</li>
<li>決定何時停止訓練</li>
</ul>
<p><strong>比例：</strong> 通常 10~20%</p>
<p><strong>比喻：</strong> 「模擬考」</p>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 沒有驗證集 → 不知道何時停止，可能過擬合</li>
<li>✅ 有驗證集 → 即時監控，適時停止</li>
</ul>
<hr />
<h3 id="測試集test-set"><a class="header" href="#測試集test-set">測試集（Test Set）⭐⭐⭐⭐⭐</a></h3>
<p><strong>功能：</strong> 最終評估模型</p>
<p><strong>比例：</strong> 通常 10~20%</p>
<p><strong>比喻：</strong> 「正式考試」</p>
<p><strong>解決什麼問題：</strong></p>
<ul>
<li>❌ 沒有測試集 → 不知道真實表現</li>
<li>✅ 有測試集 → 客觀評估泛化能力</li>
</ul>
<hr />
<h3 id="為什麼要分三份"><a class="header" href="#為什麼要分三份">為什麼要分三份？</a></h3>
<pre><code>只有訓練集和測試集：
→ 問題：不知道什麼時候該停止訓練
→ 風險：可能過擬合

有訓練集、驗證集、測試集：
→ 訓練集：學習 📚
→ 驗證集：調整、監控（邊學邊檢查）🔍
→ 測試集：最終評分（完全沒看過的題目）✅

完美！
</code></pre>
<p><strong>程式碼：</strong></p>
<pre><code class="language-python">from sklearn.model_selection import train_test_split

# 先分出訓練集和測試集（80% vs 20%）
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 從訓練集再分出驗證集（訓練 75% vs 驗證 25%）
X_train, X_val, y_train, y_val = train_test_split(
    X_train, y_train, test_size=0.25, random_state=42
)

# 最終比例：訓練集 60%、驗證集 20%、測試集 20%
</code></pre>
<hr />
<h2 id="-8-完整範例預測房價"><a class="header" href="#-8-完整範例預測房價">🎓 8. 完整範例：預測房價</a></h2>
<pre><code class="language-python"># ========== 1. 載入套件 ==========
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.callbacks import EarlyStopping
from keras.optimizers import Adam
import matplotlib.pyplot as plt

# ========== 2. 載入資料 ==========
# 假設有房屋資料
df = pd.DataFrame({
    '坪數': [30, 25, 40, 35, 28, 45, 32, 38, 27, 33],
    '房間數': [3, 2, 4, 3, 2, 4, 3, 4, 2, 3],
    '屋齡': [5, 10, 3, 8, 12, 2, 7, 4, 15, 6],
    '距捷運': [500, 1000, 300, 800, 1500, 200, 600, 400, 2000, 700],
    '房價': [1500, 1200, 2000, 1700, 1100, 2200, 1600, 1900, 1000, 1550]
})

# ========== 3. 定義自變數和應變數 ==========
X = df[['坪數', '房間數', '屋齡', '距捷運']]  # 自變數（特徵）
y = df['房價']                                # 應變數（目標）

# ========== 4. 資料分割 ==========
# 先分出訓練+驗證 vs 測試（80% vs 20%）
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 再分出訓練 vs 驗證（75% vs 25%）
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=42
)

# ========== 5. 標準化 ==========
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)  # 訓練集：fit + transform
X_val = scaler.transform(X_val)          # 驗證集：只 transform
X_test = scaler.transform(X_test)        # 測試集：只 transform

# ========== 6. 建立模型（回歸問題）==========
model = Sequential([
    # 輸入層 + 第一隱藏層
    Dense(64, input_dim=4, activation='relu'),
    Dropout(0.3),                    # 防止過擬合
    
    # 第二隱藏層
    Dense(32, activation='relu'),
    Dropout(0.2),
    
    # 輸出層（回歸不需激活函數）
    Dense(1)
])

# ========== 7. 編譯模型 ==========
model.compile(
    loss='mse',                      # 損失函數：均方誤差
    optimizer=Adam(learning_rate=0.001),  # 優化器：Adam
    metrics=['mae', 'mse']           # 評估指標
)

# ========== 8. 設定 Early Stopping ==========
early_stop = EarlyStopping(
    monitor='val_loss',      # 監控驗證集損失
    patience=20,             # 20 輪沒改善就停止
    restore_best_weights=True  # 恢復最佳權重
)

# ========== 9. 訓練模型 ==========
history = model.fit(
    X_train, y_train,
    epochs=200,                      # 最多訓練 200 輪
    batch_size=4,                    # 每次 4 筆資料
    validation_data=(X_val, y_val),  # 驗證集
    callbacks=[early_stop],          # 使用 Early Stopping
    verbose=1                        # 顯示訓練過程
)

# ========== 10. 評估模型 ==========
# 測試集評估
test_loss, test_mae, test_mse = model.evaluate(X_test, y_test)
print(f'\n測試集結果：')
print(f'MAE: {test_mae:.2f} 萬（平均誤差）')
print(f'RMSE: {np.sqrt(test_mse):.2f} 萬（均方根誤差）')

# ========== 11. 預測新房子的價格 ==========
new_house = [[35, 3, 6, 500]]  # 35坪、3房、屋齡6年、距捷運500m
new_house_scaled = scaler.transform(new_house)
predicted_price = model.predict(new_house_scaled, verbose=0)
print(f'\n新房子預測房價: {predicted_price[0][0]:.2f} 萬')

# ========== 12. 視覺化訓練過程 ==========
plt.figure(figsize=(12, 4))

# 損失曲線
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='訓練集損失')
plt.plot(history.history['val_loss'], label='驗證集損失')
plt.xlabel('Epoch')
plt.ylabel('Loss (MSE)')
plt.legend()
plt.title('訓練過程 - 損失函數')

# MAE 曲線
plt.subplot(1, 2, 2)
plt.plot(history.history['mae'], label='訓練集 MAE')
plt.plot(history.history['val_mae'], label='驗證集 MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.title('訓練過程 - 平均絕對誤差')

plt.tight_layout()
plt.show()
</code></pre>
<p><strong>這段代碼示範了：</strong>
✅ 完整的資料處理流程<br />
✅ 三份資料分割（訓練/驗證/測試）<br />
✅ 標準化處理<br />
✅ 模型建立與編譯<br />
✅ 使用 Dropout 防止過擬合<br />
✅ Early Stopping 自動停止<br />
✅ 模型評估與預測<br />
✅ 訓練過程視覺化</p>
<hr />
<h2 id="-完整術語快速查詢表"><a class="header" href="#-完整術語快速查詢表">🗂️ 完整術語快速查詢表</a></h2>
<div class="table-wrapper"><table><thead><tr><th>類別</th><th>術語</th><th>白話</th><th>解決的問題</th><th>推薦度</th></tr></thead><tbody>
<tr><td><strong>資料</strong></td><td>應變數</td><td>答案</td><td>定義預測目標</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>資料</strong></td><td>自變數</td><td>線索</td><td>提供預測資訊</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>激活</strong></td><td>ReLU</td><td>負數變0</td><td>解決梯度消失</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>激活</strong></td><td>Sigmoid</td><td>輸出0~1</td><td>二分類機率</td><td>⭐⭐⭐⭐</td></tr>
<tr><td><strong>激活</strong></td><td>Softmax</td><td>機率分佈</td><td>多分類機率</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>損失</strong></td><td>MSE</td><td>均方誤差</td><td>量化回歸誤差</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>損失</strong></td><td>MAE</td><td>絕對誤差</td><td>穩健誤差估計</td><td>⭐⭐⭐⭐</td></tr>
<tr><td><strong>損失</strong></td><td>Crossentropy</td><td>分類誤差</td><td>量化分類錯誤</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>優化</strong></td><td>Adam</td><td>自適應學習</td><td>自動調整速度</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>訓練</strong></td><td>Learning Rate</td><td>步伐大小</td><td>控制更新幅度</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>訓練</strong></td><td>Epoch</td><td>複習次數</td><td>充分學習</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>訓練</strong></td><td>Batch Size</td><td>一次幾題</td><td>平衡效率品質</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>評估</strong></td><td>Accuracy</td><td>答對率</td><td>整體表現</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>評估</strong></td><td>Precision</td><td>不誤判</td><td>減少誤報</td><td>⭐⭐⭐⭐</td></tr>
<tr><td><strong>評估</strong></td><td>Recall</td><td>不漏掉</td><td>減少漏報</td><td>⭐⭐⭐⭐</td></tr>
<tr><td><strong>評估</strong></td><td>R²</td><td>解釋力</td><td>評估回歸品質</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>處理</strong></td><td>標準化</td><td>統一量級</td><td>平衡特徵</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>處理</strong></td><td>One-Hot</td><td>類別編碼</td><td>避免順序誤解</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>問題</strong></td><td>過擬合</td><td>背答案</td><td>泛化不良</td><td>⭐⭐⭐⭐⭐</td></tr>
<tr><td><strong>問題</strong></td><td>欠擬合</td><td>學不會</td><td>模型太簡單</td><td>⭐⭐⭐⭐</td></tr>
<tr><td><strong>技巧</strong></td><td>Dropout</td><td>隨機丟棄</td><td>防止過擬合</td><td>⭐⭐⭐⭐⭐</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="-新手建議"><a class="header" href="#-新手建議">💡 新手建議</a></h2>
<h3 id="學習順序"><a class="header" href="#學習順序">學習順序</a></h3>
<ol>
<li>✅ <strong>先搞懂應變數和自變數</strong>（這是基礎）</li>
<li>✅ <strong>記住激活函數和損失函數的搭配</strong></li>
<li>✅ <strong>優化器用 Adam，學習率用 0.001</strong></li>
<li>✅ <strong>注意過擬合問題</strong>（訓練久 ≠ 好）</li>
<li>✅ <strong>多實作，多看別人的 code</strong></li>
</ol>
<h3 id="常用組合直接套用"><a class="header" href="#常用組合直接套用">常用組合（直接套用）</a></h3>
<p><strong>分類問題（如：Iris 花分類）</strong></p>
<pre><code class="language-python">model = Sequential([
    Dense(64, activation='relu'),    # 隱藏層
    Dropout(0.3),
    Dense(3, activation='softmax')   # 輸出層（3類）
])

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)
</code></pre>
<p><strong>回歸問題（如：房價預測）</strong></p>
<pre><code class="language-python">model = Sequential([
    Dense(64, activation='relu'),    # 隱藏層
    Dropout(0.3),
    Dense(1)                         # 輸出層（回歸）
])

model.compile(
    loss='mse',
    optimizer='adam',
    metrics=['mae']
)
</code></pre>
<h3 id="除錯清單"><a class="header" href="#除錯清單">除錯清單</a></h3>
<ul>
<li>❌ 訓練集 99%，測試集 60% → <strong>過擬合</strong>，加 Dropout</li>
<li>❌ 訓練集 60%，測試集 58% → <strong>欠擬合</strong>，增加複雜度</li>
<li>❌ 損失不下降 → 檢查學習率、檢查資料標準化</li>
<li>❌ 損失是 NaN → 學習率太大，調小 10 倍</li>
</ul>
<hr />
<h2 id="-總結"><a class="header" href="#-總結">🎉 總結</a></h2>
<p>機器學習雖然術語多，但核心概念不複雜：</p>
<ol>
<li><strong>資料</strong>：定義問題（應變數、自變數）</li>
<li><strong>模型</strong>：學習規律（激活函數、層數）</li>
<li><strong>訓練</strong>：優化參數（損失函數、優化器）</li>
<li><strong>評估</strong>：檢驗效果（各種指標）</li>
<li><strong>改進</strong>：解決問題（過擬合、欠擬合）</li>
</ol>
<p><strong>記住：多動手實作，比看一百遍理論有用！</strong> 💪</p>
<p>希望這份筆記對你有幫助！🚀</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../ml/01_機器學習基礎.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../ml/src/2021-13th-ironman/index.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../ml/01_機器學習基礎.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../ml/src/2021-13th-ironman/index.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>



        <script>
            window.playground_line_numbers = true;
        </script>

        <script>
            window.playground_copyable = true;
        </script>

        <script src="../ace.js"></script>
        <script src="../mode-rust.js"></script>
        <script src="../editor.js"></script>
        <script src="../theme-dawn.js"></script>
        <script src="../theme-tomorrow_night.js"></script>

        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../mermaid.min.js"></script>
        <script src="../mermaid-init.js"></script>



    </div>
    </body>
</html>
