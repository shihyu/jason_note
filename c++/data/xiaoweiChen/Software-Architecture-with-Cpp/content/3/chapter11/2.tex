

为了有效地改进代码的性能，必须从测量其性能开始。如果不知道真正的瓶颈在哪里，将最终优化错误的地方，损失时间，并对努力工作几乎没有收获感到惊讶和沮丧。本节中，将展示如何正确地使用基准测试来度量性能，如何成功地分析代码，以及深入了解分布式系统中的性能。

\subsubsubsection{11.2.1\hspace{0.2cm}进行准确且有意义的测量}

为了进行精确和可重复的测量，可能还希望将机器设置为性能模式，而不是通常的默认省电模式。如果需要较低的系统延迟，可能需要在进行基准测试的机器和生产环境中永久禁用节能功能。很多时候，这可能意味着进入BIOS并正确配置服务器。注意，如果使用公共云提供商，这样的操作是不可能的。如果有root/admin权限，操作系统通常也可以控制一些设置。例如，在Linux系统上，可以通过执行以下命令强制CPU以其最高频率运行:

\begin{tcblisting}{commandshell={}}
sudo cpupower frequency-set --governor performance
\end{tcblisting}

此外，为了获得有意义的结果，可能希望在与生产环境尽可能接近的系统上执行测量。除了配置之外，RAM的不同速度、CPU缓存的数量和CPU的微架构等方面也会影响结果，导致错误的结论。对于硬盘设置，甚至网络拓扑结构和使用的硬件也是如此。构建的软件也扮演着至关重要的角色:从使用的固件，通过操作系统和内核，一路向上的软件堆会栈到依赖。最好有第二个与生产环境相同的环境，并使用相同的工具和脚本进行治理。

现在有了测量的环境，看看能测试到什么。

\subsubsubsection{11.2.2\hspace{0.2cm}利用不同类型的测量工具}

有几种方法可以测量性能，每种方法关注不同的范围。

基准测试可以用于在制作的测试中计时系统的速度。通常，会测试完成时间或另一个性能指标(如每秒处理的订单)。有几种基准:

\begin{itemize}
\item 
微基准测试，可以测量小代码片段的执行。将在下一节中介绍。

\item 
用人工数据模拟在更大范围内进行的合成测试。如果无法访问目标数据或目标硬件，这种方式就可能很有用。例如，当计划检查正在工作的硬件的性能，但它还不存在，或者当计划处理传入的通信流，但只能假设通信流的外观。

\item 
回放，这是在现实工作负载下测量性能的一种非常准确的方法。其思想是记录进入生产系统的所有请求或工作负载，通常带有时间戳。然后可以在基准测试系统中“重播”这些转储，并考虑到它们之间的时间差异，检查它的执行情况。这样的基准测试可以很好地了解代码或环境的变化对系统延迟和吞吐量的影响。

\item 
行业标准，这是一个很好的方式来了解自己的产品如何与其竞争对手的相比。这类基准测试包括用于CPU的SuperPi，用于显卡的3D Mark，以及用于人工智能处理器的ResNet-50。
\end{itemize}

除了基准测试之外，另一种用于测量性能的工具是分析器。分析器不只提供总体性能指标，并允许检查代码正在做什么并寻找瓶颈。对于捕获使系统变慢的意外事件非常有用。

掌握系统性能的最后一种方法是跟踪，其本质是记录执行期间系统行为的一种方法。通过监视请求完成各种处理步骤所需的时间(例如不同类型的微服务处理)，可以了解系统的哪些部分需要提高性能，或者系统处理不同类型请求的情况:要么是不同的类型，要么是接受或拒绝的类型。

现在来看看微基准测试。

\subsubsubsection{11.2.3\hspace{0.2cm}微基准测试}

微基准测试用于测量“微”代码片段的执行速度。如果想知道如何实现给定的功能，或者不同的第三方库处理相同任务的速度有多快，它们是完成这项工作的最佳工具。虽然它们不能代表现实环境，但非常适合进行这样的小实验。

接下来，展示如何使用C++中最常用的创建微基准测试的框架:Google基准测试来执行这样的实验。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{设置Google基准测试}

通过使用Conan将这个库引入代码中，并在conanfile.txt中添加以下内容:

\begin{tcblisting}{commandshell={}}
[requires]
benchmark/1.5.2

[generators]
CMakeDeps	
\end{tcblisting}

将使用CMakeDeps生成器，因为它是Conan2.0中推荐的CMake生成器。它依赖于CMake的\texttt{find\_package}特性来使用野蛮依赖管理器安装包。要在发布版本中安装依赖关系，请执行以下命令:

\begin{tcblisting}{commandshell={}}
cd <build_directory>
conan install <source_directory> --build=missing -s build_type=Release
\end{tcblisting}

如果使用的是自定义的Conan配置，记得在这里也添加。

以CMakeLists.txt的方式使用也非常简单:

\begin{lstlisting}[style=styleCMake]
list(APPEND CMAKE_PREFIX_PATH "${CMAKE_BINARY_DIR}")
find_package(benchmark REQUIRED)
\end{lstlisting}

首先，将构建目录添加到\texttt{CMAKE\_PREFIX\_PATH}中，这样CMake就可以找到Conan生成的配置和/或目标文件。接下来，只需使用它们来找到依赖即可。

当要创建几个微基准测试时，可以使用CMake函数进行定义:

\begin{lstlisting}[style=styleCMake]
function(add_benchmark NAME SOURCE)
	add_executable(${NAME} ${SOURCE})
	target_compile_features(${NAME} PRIVATE cxx_std_20)
	target_link_libraries(${NAME} PRIVATE benchmark::benchmark)
endfunction()
\end{lstlisting}

该函数将能够创建单转译单元微基准测试，每一个都使用C++20并链接到Google基准测试库。现在使用它来创建第一个微基准可执行文件:

\begin{lstlisting}[style=styleCMake]
add_benchmark(microbenchmark_1 microbenchmarking/main_1.cpp)
\end{lstlisting}

现在准备在源文件中放入一些代码。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{第一个微基准测试}

我们将测试在排序后的数组中使用二分法进行查找的速度比线性查找快多少。先从创建排序数组的代码开始:

\begin{lstlisting}[style=styleCXX]
using namespace std::ranges;

template <typename T>
auto make_sorted_vector(std::size_t size) {
	auto sorted = std::vector<T>{};
	sorted.reserve(size);
	
	auto sorted_view = views::iota(T{0}) | views::take(size);
	std::ranges::copy(sorted_view, std::back_inserter(sorted));
	return sorted;
}
\end{lstlisting}

数组将包含size个元素，所有的数字从0到size - 1按升序排列。现在指定要查找的元素和容器大小:

\begin{lstlisting}[style=styleCXX]
constexpr auto MAX_HAYSTACK_SIZE = std::size_t{10'000'000};
constexpr auto NEEDLE = 2137;
\end{lstlisting}

我们会测量查找需要多长时间。简单的线性搜索可以这样实现:

\begin{lstlisting}[style=styleCXX]
void linear_search_in_sorted_vector(benchmark::State &state) {
	auto haystack = make_sorted_vector<int>(MAX_HAYSTACK_SIZE);
	for (auto _ : state) {
		benchmark::DoNotOptimize(find(haystack, NEEDLE));
	}
}
\end{lstlisting}

这里，可以看到Google基准测试的首次使用。每个微基准测试都应该接受State作为参数。这种特殊类型的功能如下:

\begin{itemize}
\item 
包含有关执行的迭代和测试在计算上花费时间的信息

\item 
如果需要，计算处理的字节数

\item 
返回其他状态信息，比如需要进一步运行(通过\texttt{keepprunning()}成员函数)

\item 
可用于暂停和恢复迭代的计时(分别通过\texttt{PauseTiming()}和\texttt{ResumeTiming()}成员函数)
\end{itemize}

测量循环中的代码，根据运行这个特定基准测试的总允许时间进行所需的多次迭代。我们的数组在循环之外创建，创建耗时不会计入测量。 

循环内部，有一个接收器助手，名为\texttt{DoNotOptimize}，目的是确保编译器不会优化掉计算。例子中，将把\texttt{std::find}的结果标记为必要的，因此查找指针的实际代码没有优化掉。使用objdump等工具或Godbolt和QuickBench等网站可以查看想运行的代码是否优化掉。QuickBench还有一个优势，就是在云端运行基准测试，并在线分享测试结果。

回到手头上的任务，现在有一个线性搜索的微基准，现在让我们在另一个微基准中计算二分搜索的时间:

\begin{lstlisting}[style=styleCXX]
void binary_search_in_sorted_vector(benchmark::State &state) {
	auto haystack = make_sorted_vector<int>(MAX_HAYSTACK_SIZE);
	for (auto _ : state) {
		benchmark::DoNotOptimize(lower_bound(haystack, NEEDLE));
	}
}
\end{lstlisting}

新基准非常类似，只在使用的函数上有所不同:\texttt{lower\_bound}将执行二进制搜索。注意，与基础示例类似，不检查迭代器返回的是\texttt{vector}中的有效元素，还是\texttt{vector}的末尾。在\texttt{lower\_bound}的情况下，可以检查迭代器指向的元素是否就是要找的元素。

现在有了微基准函数，可以通过添加以下代码来创建实际的基准:

\begin{lstlisting}[style=styleCXX]
BENCHMARK(binary_search_in_sorted_vector);
BENCHMARK(linear_search_in_sorted_vector);
\end{lstlisting}

如果接受默认基准设置，那么只需通过这些设置即可。作为最后一步，添加\texttt{main()}函数:

\begin{lstlisting}[style=styleCXX]
BENCHMARK_MAIN();
\end{lstlisting}

就这么简单!或者，也可以使用\texttt{benchmark\_main}来链接应用。使用Google Benchmark的\texttt{main()}函数的好处是提供了一些默认选项。如果编译基准测试，并将\texttt{-\,-help}作为参数运行它，将看到以下内容:

\begin{tcblisting}{commandshell={}}
benchmark [--benchmark_list_tests={true|false}]
          [--benchmark_filter=<regex>]
          [--benchmark_min_time=<min_time>]
          [--benchmark_repetitions=<num_repetitions>]
          [--benchmark_report_aggregates_only={true|false}]
          [--benchmark_display_aggregates_only={true|false}]
          [--benchmark_format=<console|json|csv>]
          [--benchmark_out=<filename>]
          [--benchmark_out_format=<json|console|csv>]
          [--benchmark_color={auto|true|false}]
          [--benchmark_counters_tabular={true|false}]
          [--v=<verbosity>]
\end{tcblisting}

这是一组很好的特性。例如，在设计实验时，可以使用\texttt{benchmark\_format}开关来获得CSV输出，以便在图表上绘图。

现在通过运行编译后的不带命令行参数的可执行文件，来看看基准测试的实际效果。运行\texttt{./microbenchmark\_1}可能的输出如下:

\begin{tcblisting}{commandshell={}}
2021-02-28T16:19:28+01:00
Running ./microbenchmark_1
Run on (8 X 2601 MHz CPU s)
Load Average: 0.52, 0.58, 0.59
-------------------------------------------------------------------------
Benchmark Time CPU Iterations
-------------------------------------------------------------------------
linear_search_in_sorted_vector 984 ns 984 ns 746667
binary_search_in_sorted_vector 18.9 ns 18.6 ns 34461538
\end{tcblisting}

从一些关于运行环境的数据(基准测试的时间、可执行名称、服务器的CPU和当前负载)开始，得到定义的每个基准测试的结果。对于每个基准测试，可以得到每个迭代的平均挂钟时间、每个迭代的平均CPU时间，以及基准测试运行的迭代次数。默认情况下，单个迭代越长，所经过的迭代就越少。运行更多的迭代可以获得更稳定的结果。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{向微基准测试传递参数}

如果要测试更多处理手头问题的方法，可以寻找重用基准测试代码的方法，只要将其传递给用于执行查找的函数，就可以使用Google基准测试的一个特性。通过将参数作为附加参数添加到函数签名中，该框架实际上可以将任何想要的参数传递给基准测试。

有了这个特性，基准测试的统一签名会是什么样子:

\begin{lstlisting}[style=styleCXX]
void search_in_sorted_vector(benchmark::State &state, auto finder) {
	auto haystack = make_sorted_vector<int>(MAX_HAYSTACK_SIZE);
	for (auto _ : state) {
		benchmark::DoNotOptimize(finder(haystack, NEEDLE));
	}
}
\end{lstlisting}

可以注意到函数的新finder参数，它用于之前调用\texttt{find}或\texttt{lower\_bound}的位置。现在，可以使用与上次不同的宏来进行两个微基准测试:

\begin{lstlisting}[style=styleCXX]
BENCHMARK_CAPTURE(search_in_sorted_vector, binary, lower_bound);
BENCHMARK_CAPTURE(search_in_sorted_vector, linear, find);
\end{lstlisting}

\texttt{BENCHMARK\_CAPTURE}宏接受函数、名称后缀和任意数量的参数。如果想要更多，可以把它们传到这里。基准函数可以是常规函数或模板——两者都支持。现在来看看当运行代码时得到了什么:

\begin{tcblisting}{commandshell={}}
-------------------------------------------------------------------------
Benchmark Time CPU Iterations
-------------------------------------------------------------------------
search_in_sorted_vector/binary 19.0 ns 18.5 ns 28000000
search_in_sorted_vector/linear 959 ns 952 ns 640000
\end{tcblisting}

传递给函数的参数不是函数名的一部分，而是函数名和后缀的一部分。

现在，看看如何进一步定制基准测试。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{向微基准传递数值参数}

设计像这样的实验时，常见的需求是在不同大小的参数上进行检验。在Google基准测试中，可以通过多种方式解决此类需求。最简单的方法是在\texttt{BENCHMARK}宏返回的对象上添加对\texttt{Args()}的调用。这样，就可以传递一组值给相应的微基准中使用。要使用传递的值，需要对基准函数进行如下修改:

\begin{lstlisting}[style=styleCXX]
void search_in_sorted_vector(benchmark::State &state, auto finder) {
	const auto haystack = make_sorted_vector<int>(state.range(0));
	const auto needle = 2137;
	for (auto _ : state) {
		benchmark::DoNotOptimize(finder(haystack, needle));
	}
}
\end{lstlisting}

对\texttt{state.range(0)}的调用将读取传递的第0个参数，其支持任意数量参数的传递。例子中，用于参数化干数组的大小。如果想传递一个范围的值集呢？这样，就可以更容易地看到更改大小如何影响性能。可以在基准测试中调用\texttt{Range}，而非\texttt{Args}:

\begin{lstlisting}[style=styleCXX]
constexpr auto MIN_HAYSTACK_SIZE = std::size_t{1'000};
constexpr auto MAX_HAYSTACK_SIZE = std::size_t{10'000'000};
BENCHMARK_CAPTURE(search_in_sorted_vector, binary, lower_bound)
	->RangeMultiplier(10)
	->Range(MIN_HAYSTACK_SIZE, MAX_HAYSTACK_SIZE);
BENCHMARK_CAPTURE(search_in_sorted_vector, linear, find)
	->RangeMultiplier(10)
	->Range(MIN_HAYSTACK_SIZE, MAX_HAYSTACK_SIZE);
\end{lstlisting}

使用预定义的最小值和最大值来指定范围边界。然后，告诉基准测试工具通过乘以10而不是默认值来创建范围。当运行这样的基准时，可以得到如下的结果:

\begin{tcblisting}{commandshell={}}
-------------------------------------------------------------------------
Benchmark Time CPU Iterations
-------------------------------------------------------------------------
search_in_sorted_vector/binary/1000 0.2 ns 19.9 ns 34461538
search_in_sorted_vector/binary/10000 24.8 ns 24.9 ns 26352941
search_in_sorted_vector/binary/100000 26.1 ns 26.1 ns 26352941
search_in_sorted_vector/binary/1000000 29.6 ns 29.5 ns 24888889
search_in_sorted_vector/binary/10000000 25.9 ns 25.7 ns 24888889
search_in_sorted_vector/linear/1000 482 ns 474 ns 1120000
search_in_sorted_vector/linear/10000 997 ns 1001 ns 640000
search_in_sorted_vector/linear/100000 1005 ns 1001 ns 640000
search_in_sorted_vector/linear/1000000 1013 ns 1004 ns 746667
search_in_sorted_vector/linear/10000000 990 ns 1004 ns 746667
\end{tcblisting}

分析这些结果时，可能想知道为什么线性搜索没有显示出线性增长。那是因为我们寻找的是一个定值，可以在固定的位置发现。如果数组中包含了指针，那么需要相同数量的操作来找到它，而不管数组的大小，所以执行时间停止增长(仍然可能受到小波动的影响)。

为什么不试试尝试换换查找的位置呢？

\hspace*{\fill} \\ %插入空行
\noindent
\textit{以编程方式生成传递参数}

在简单的函数中生成数组大小和对应值的位置可能很容易。Google基准可以进行这样的操作，所以来展示下在实践这种方式是如何工作的。

首先重写基准函数，在每次迭代中使用两个参数:

\begin{lstlisting}[style=styleCXX]
void search_in_sorted_vector(benchmark::State &state, auto finder) {
	const auto needle = state.range(0);
	const auto haystack = make_sorted_vector<int>(state.range(1));
	for (auto _ : state) {
		benchmark::DoNotOptimize(finder(haystack, needle));
	}
}
\end{lstlisting}

\texttt{state.range(0)}将标记寻找值的位置，而\texttt{state.range(1)}将是数组的大小，这意味着每次需要传递两个值。创建一个生成函数:

\begin{lstlisting}[style=styleCXX]
void generate_sizes(benchmark::internal::Benchmark *b) {
	for (long haystack = MIN_HAYSTACK_SIZE; haystack <= MAX_HAYSTACK_SIZE;
	haystack *= 100) {
		for (auto needle :
		{haystack / 8, haystack / 2, haystack - 1, haystack + 1}) {
			b->Args({needle, haystack});
		}
	}
}
\end{lstlisting}

没有使用\texttt{Range}和\texttt{rangemulplier}，而是写了一个循环来生成数组，这次每次增加100。说到查找值，在数组的相应位置使用三个位置，还有一个在外面。在每次循环迭代中调用\texttt{Args}，传递两个生成的值。

现在，将生成器函数应用于基准测试:

\begin{lstlisting}[style=styleCXX]
BENCHMARK_CAPTURE(search_in_sorted_vector, binary,
lower_bound)->Apply(generate_sizes);
BENCHMARK_CAPTURE(search_in_sorted_vector, linear,
find)->Apply(generate_sizes);
\end{lstlisting}

使用这样的函数，可以很容易地将相同的生成器传递给许多基准测试。这些基准的结果如下:

\begin{tcblisting}{commandshell={}}
-------------------------------------------------------------------------
Benchmark Time CPU Iterations
-------------------------------------------------------------------------
search_in_sorted_vector/binary/125/1000 20.0 ns 20.1 ns 37333333
search_in_sorted_vector/binary/500/1000 19.3 ns 19.0 ns 34461538
search_in_sorted_vector/binary/999/1000 20.1 ns 19.9 ns 34461538
search_in_sorted_vector/binary/1001/1000 18.1 ns 18.0 ns 40727273
search_in_sorted_vector/binary/12500/100000 35.0 ns 34.5 ns 20363636
search_in_sorted_vector/binary/50000/100000 28.9 ns 28.9 ns 24888889
search_in_sorted_vector/binary/99999/100000 31.0 ns 31.1 ns 23578947
search_in_sorted_vector/binary/100001/100000 29.1 ns 29.2 ns 23578947
// et cetera
\end{tcblisting}

现在有一个非常明确的实验来执行搜索。作为练习，请在自己的机器上运行这个实验，以查看完整的结果，并尝试从结果中得出一些结论。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{选择微基准测试和优化}

进行这样的实验可能具有意义，甚至会让人上瘾。但请记住，微基准测试不应该是项目中唯一的性能测试类型。Donald Knuth有句名言:

\begin{center}
\textit{We should forget about small efficiencies, say about 97\% of the time: premature optimization is the root of all evil}

\textit{(不成熟的优化是罪恶之源)}
\end{center}

应该只对重要的代码进行微基准测试，特别是热路径上的代码。可以使用较大的基准测试，以及跟踪和分析来查看何时何地进行优化，而不是过早地猜测和优化。首先，了解软件是如何执行的。

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black, title=Note]
\hspace*{0.7cm}关于上面的引用，还有一点想说明，但不要过早的悲观。糟糕的数据结构或算法选择，甚至分散的所有低效代码，有时会影响系统的整体性能。例如，执行不必要的动态分配，虽然一开始看起来没有那么糟糕，但随着时间的推移，可能会导致堆碎片，如果应用程序要运行很长一段时间，会带来严重的麻烦。过度使用基于节点的容器也会导致更多的缓存失败。长话短说，如果编写高效的代码更容易，那就去写吧。
\end{tcolorbox}

现在，若项目有一些地方需要随着时间的推移保持良好的性能，该做些什么呢？

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{创建基准性能测试}

与使用单元测试进行精确测试和使用功能测试进行大规模的代码正确性测试类似，可以使用微基准测试和大型基准测试来测试代码的性能。

如果对某些代码路径的执行时间有严格的限制，进行测试以确保满足限制是非常有用的。即使没有这样特定的约束，也可能对监视代码变更时性能的变化感兴趣。如果在更改之后，代码运行速度比以前慢了一个数量级，那么测试可能标记为失败。

尽管这也是一种有用的工具，但请记住，这样的测试很容易产生沸腾青蛙效应:随着时间的推移缓慢降低性能可能不会注意到，所以一定要偶尔监控执行时间。向CI引入性能测试时，请确保在相同的环境中运行，以获得稳定的结果。

现在，讨论下一种性能工具。

\subsubsubsection{11.2.4\hspace{0.2cm}分析}

虽然基准测试和跟踪可以提供一个概述和给定范围的特定数字，但分析器可以分析这些数字的来源。如果需要观察自己的表现并改进它，那它们是必不可少的工具。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{选择分析器}

有两种类型的分析器:仪表分析器和采样分析器。其中一个较为知名的仪器分析器是Valgrind中的Callgrind。采样分析器的开销很大，需要插装代码，以查看调用了哪些函数，以及每个函数占用了多少开销。这样，生成的结果甚至包含最小的函数，但是执行时间可能会因这种开销而扭曲。它还有一个缺点是不能总是捕捉输入/输出(I/O)低速和抖动。它们会降低执行速度，因此虽然可以告知调用某个函数的频率，但不会说明，慢是因为要等待磁盘读取完成。

由于仪表分析器的缺陷，通常更好的方法是使用采样分析器。值得一提的是Linux系统上的开源性能分析和Intel的专有工具VTune(开源项目免费使用)。尽管由于抽样的性质，有时会错过关键事件，但通常可以更好地了解代码花费时间的地方。

如果决定使用perf，应该知道可以通过\texttt{perf stat}来使用它，它可以提供像CPU缓存使用情况这样的统计信息的快速概览，或者通过调用\texttt{perf record -g}和\texttt{perf report -g}来捕获和分析分析结果。

如果想对perf有一个全面的了解，请观看Chandler Carruth的视频，视频中展示了该工具的各种可能性以及如何使用它，或者看一看它的教程。两者在扩展阅读部分都有链接。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{分析器和处理结果}

分析分析结果时，可能经常想要执行一些准备、清理和处理。若代码大部分时间都在空转，那么可能需要将其过滤掉。启动分析器之前，一定要编译或保留尽可能多的调试符号，包括代码、依赖项、甚至OS库和内核的调试符号。另外，禁用帧指针优化也是必要的。在GCC和Clang上，可以通过\texttt{-fno-omit-frame-pointer}标志来实现这一点。它不会对性能造成太大的影响，但会提供更多关于代码执行的数据。当涉及到结果的后期处理时，使用perf时，根据结果创建火焰图通常是一个好主意。Brendan Gregg在扩展阅读部分的工具就不错。火焰图是一种简单而有效的工具，可以查看执行在哪里花费了太多的时间，因为图上每个项目的宽度对应于资源使用情况。可以有CPU使用情况的火焰图，以及内存使用情况、分配和页面故障等资源的火焰图，或者代码不执行时所花费的时间，例如在系统调用期间保持阻塞、互斥锁、I/O操作等。也有方法在生成的火焰图上执行的差异。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{分析结果}

记住，并不是所有的性能问题都会显示在这样的图上，也不是所有的问题都可以使用分析器找到。虽然有一定经验的开发者可以看到，可以通过设置线程的亲和性或更改在特定NUMA节点上执行的线程而获益，但是忘记禁用省电特性或启用或禁用超线程可能并不总是那么明显，关于正在运行的硬件的信息也很有用。有时可能会看到正在使用CPU的SIMD寄存器，但代码仍然不能全速运行:可能使用SSE指令，而不是AVX指令，使用AVX而不是AVX2，或使用AVX2而不是AVX512。在分析分析结果时，了解CPU能够运行哪些特定指令也非常重要。

解决性能问题也需要一些经验。另一方面，有时经验会产生错误的假设。例如，使用动态多态性会损害性能。某些情况下，它不会降低代码的速度。在得出结论之前，有必要对代码进行分析，了解编译器优化代码的各种方法以及这些技术的局限性。具体地说到虚拟化，当不想让其他类型分别继承和覆盖虚成员函数的类时，标记为\texttt{final}通常是有益的。这在很多情况下对编译器都有帮助。

如果编译器可以“看到”对象的类型，就可以更好地优化:如果在作用域中创建一个类型并调用它的虚成员函数，编译器应该能够推断应该调用哪个函数。GCC倾向于比其他编译器更好地进行反虚拟化。关于这方面的更多信息，可以参考Arthur O’dwyer在扩展阅读部分的博客文章。

与本节介绍的其他类型的工具一样，不要只依赖于分析器。分析结果的改进并不能保证系统变得更快。再好看的测试报告，也不能说明事情的全部。而且一个部件的性能提高，并不意味着整个系统的性能提高。

接下来，是最后一种工具。

\subsubsubsection{11.2.5\hspace{0.2cm}跟踪}

本节中我们将讨论的最后一种技术适用于分布式系统。当查看整个系统(通常部署在云中)时，在一台机器上分析软件并不能说明全部情况。在这样的范围内，最好的方法是跟踪流经系统的请求和响应。

跟踪是记录代码执行情况的一种方法。当请求(有时是它的响应)必须流经系统的许多部分时，通常使用它。消息是沿着路线跟踪的，可以在感兴趣的执行点添加时间戳。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{相关ID}

对时间戳的一个常见添加是相关ID。基本上，是分配给每个跟踪消息的惟一标识符。目的是关联系统中不同组件(如不同的微服务)在处理相同的传入请求期间产生的日志，有时也关联它导致的事件。这样的ID应该随消息传递到任何地方，例如通过附加到其HTTP头。即使原始请求已经消失，也可以将其关联ID添加到生成的每个响应中。

通过使用相关ID，可以跟踪给定请求的消息如何在系统中传播，以及系统的不同部分处理它所花费的时间。通常，需要在整个过程中收集额外的数据，比如用于执行计算的线程、为给定请求产生的响应的类型和数量，或者所经过的机器的名称。

像Jaeger和Zipkin(或其他OpenTracing替代工具)这样的工具可以快速地向系统添加跟踪支持。

下面，让我们讨论另一个话题，从而对生成代码进行讨论。





