<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [第六章：存儲器層次結構](#%E7%AC%AC%E5%85%AD%E7%AB%A0%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84)
  - [6.1 存儲技術](#61-%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF)
    - [隨機訪問存儲器](#%E9%9A%8F%E6%9C%BA%E8%AE%BF%E9%97%AE%E5%AD%98%E5%82%A8%E5%99%A8)
    - [磁盤存儲](#%E7%A3%81%E7%9B%98%E5%AD%98%E5%82%A8)
    - [固態硬盤](#%E5%9B%BA%E6%80%81%E7%A1%AC%E7%9B%98)
    - [存儲技術趨勢](#%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E8%B6%8B%E5%8A%BF)
  - [6.2 局部性](#62-%E5%B1%80%E9%83%A8%E6%80%A7)
  - [6.3 存儲器層次結構](#63-%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84)
    - [存儲器層次結構中的緩存](#%E5%AD%98%E5%82%A8%E5%99%A8%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%E4%B8%AD%E7%9A%84%E7%BC%93%E5%AD%98)
  - [6.4 高速緩存存儲器](#64-%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E5%AD%98%E5%82%A8%E5%99%A8)
  - [6.5 編寫緩存友好的程序](#65-%E7%BC%96%E5%86%99%E7%BC%93%E5%AD%98%E5%8F%8B%E5%A5%BD%E7%9A%84%E7%A8%8B%E5%BA%8F)
  - [6.6 綜合：高速緩存對程序的影響](#66-%E7%BB%BC%E5%90%88%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E5%AF%B9%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%BD%B1%E5%93%8D)
  - [6.7 小節](#67-%E5%B0%8F%E8%8A%82)
  - [補充](#%E8%A1%A5%E5%85%85)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# 第六章：存儲器層次結構

前面的討論中，都依賴與一個簡單的內存模型，即存儲器系統是一個一維的線性字節數組。CPU能夠在常數時間內訪問每個存儲器位置。這種簡化是有效的，但是並不能反映現代系統的工作方式。

實際上的存儲器系統是一個具有不同容量、成本和訪問時間的存儲設計的層次結構：
- 靠近CPU的是小的、快速的高速緩存系統（cache）。
- 緩存中的存儲是相對較慢和大容量的主存中的一部分。
- 主存緩存更大更慢的磁盤上內容的一部分。
- 這些磁盤也可以作為網絡連接中其他機器的緩衝區域。

存儲器層次結構是可行、有效、合理的：
- 一個編寫良好的程序傾向於更頻繁訪問某一層次的存儲設備。
- 因此下一層的設備可以更慢、更大、更便宜一些。
- 最終實現整體是一個大存儲池，其成本與最底層最便宜的設備相當，但卻可以以接近最頂層設備的速率向程序提供數據。

## 6.1 存儲技術

### 隨機訪問存儲器

隨機訪問存儲器（Random-Access memory）分為兩類：靜態（SRAM）和動態（DRAM）。
- SRAM更快也更貴，一般L1、L2、L2緩存都是用的SRAM。
- DRAM更慢也更便宜，主要用於內存。

SRAM；
- 每一位存儲在一個雙穩態（bitstable）的存儲器單元裡。
- 每個單元用一個六晶體管電路實現。可以無限期保存兩個不同狀態（電壓）之一，其他任何狀態都是不穩定的，電路會迅速轉移到兩個穩定狀態中的一個。
- 因為是雙穩態的，所以只要有電，就會永遠保持它的值。

動態DRAM：
- 每個位存儲為電容的電壓，充滿電則為1，放完電則為0。
- 每個位有一個電容和一個訪問晶體管組成，集成度可以很高。
- 電容對很多因素都很敏感，會快速漏電，DRAM單元大概會在10~100毫秒內失去電荷，因為計算機運行的時間週期是以納秒來衡量的（比如2GHz那麼時鐘週期就是0.5ns），相比較而言這個保持時間還是比較長的。
- 因為電容漏電，所以必須週期性讀取，然後重寫來刷新內存每一位，並且有些電路還有糾錯碼，只要錯誤在限度內都能夠糾正回來。

SRAM和DRAM比較：
- SRAM使用6晶體管搭建，DRAM使用1晶體管加1電容。
- SRAM比DRAM快至少十倍。
- SRAM只要加電就能持續，DRAM則需要刷新。
- SRAM的每位花費大概是DRAM的一千倍。
- 這以上的特性決定了SRAM只能用於小容量的緩存，用於主存價格會非常高昂，普通消費者無法承受，也沒有必要。
- 而DRAM價格低廉，雖然慢一點，耗電量大。

內存模塊：
- 在64位模塊中，內存以64位單位傳送數據。

非易失性存儲：
- SRAM和DRAM都是易失性（volatile）的，他們都是加電才能維持。
- 在掉電後依然能夠維持信息的存儲器被稱為非易失性存儲器（nonvolatile memory）。
- 由於歷史原因，他們被稱為ROM（Read-Only Memory），即是現在他們都是可以寫的。
- PROM：可編程ROM，只能寫入一次。
- EPROM：可擦寫可編程ROM，需要特殊設備通過紫外線寫入，可以擦寫數千次。還有EEPROM：電子可擦寫可編程ROM，直接印製在電路板上，可擦寫次數達到10萬次。
- 閃存（flash memory）：基於EEPROM，現已是非常重要的存儲技術，為大量電子設備提供快速持久的非易失性存儲。基於閃存的硬盤成為固態硬盤（SSD）。是一種電介質存儲器，使用電信號存儲單元，長時間掉電還是會有數據丟失風險（一年左右），但是隻要經常通電就能夠保持。
- 更傳統的基於磁介質的設備：比如磁帶、機械硬盤相對來說存儲時間則更長。
- 存儲在ROM的程序通常稱為固件（fireware），當計算機運行後會運行存儲在ROM中固件。

訪問主存：
- 數據流通過總線（bus）在CPU和內存之間流通。
- 每次CPU和主存之間的數據通信都通過一系列步驟完成，這些步驟稱為總線事務（bus transaction）。
- 讀事務（read transaction）從主存傳送數據到CPU，寫事務（write transaction）從CPU傳送數據到主存。
- 總線是一系列並行的導線，能夠攜帶地址、數據、控制信號。取決於設計，數據和地址可能共享一組導線，也可能不。
- 多個設備可以共享同一總線。

總線：

![](BUS.JPG)

- CPU通過內存總線連接到I/O橋，I/O橋通過系統總線連接到CPU中的總線接口。
- 其他設備也通過I/O總線連接到I/O橋。
- 在過去的真實系統中，I/O橋並不是一個統一的整體，一般會分為南橋和北橋，南橋負責通過I/O總線連接低速設備，比如鼠標、鍵盤等，北橋負責連接CPU、內存、顯卡等，同時也連接到南橋。
- Intel從SandyBridge開始，CPU整合內存控制器和PCI-E控制器、DMI通道，相當於是把原來北橋的功能集成在CPU內部了，北橋則消失了。

### 磁盤存儲

磁盤（機械硬盤）現在依然是保存大量數據的首選，雖然一定程度被SSD取代了，但是HDD單位容量價格便宜，在大型系統中依然不可或缺。
- 從磁盤上讀取數據需要毫秒級時間。
- 磁盤的細節：構造、容量、操作等內容略。
- 磁盤通過I/O總線（比如PCI總線）連接到系統中，
- I/O總線雖然比系統總線和內存總線慢，但是可以容納種類繁多的第三方I/O設備：
    - USB（Universal Serial Bus，通用串行總線）控制器：是連接到USB總線的設備的中轉機構，是廣泛使用標準，可以連接各種外圍設備。USB總線的最大帶寬在數百到上千MB/S量級（USB3.0 625MB/s, USB3.1 1250MB/s）。
    - 顯卡（顯示適配器）：包含硬件和軟件邏輯，負責代表CPU在顯示器上繪製像素。
    - 主機總線適配器：將一個或者多個磁盤連接到I/O總線，最常用的磁盤接口是SCSI和SATA（現在最常用的其實是M.2）。
- 其他設備，比如網絡適配器（網卡）可以通過將適配器插入主板上空的擴展槽中，從而連接到I/O總線。
- 這裡的I/O總線是一個簡單的抽象，現實中它是基於PCIE總線的。
- 磁盤的典型訪問速度在數百MB/s左右（一般不超過500MB/s）。

訪問磁盤：
- CPU使用一種稱為**內存映射**（memory-mapped I/O）的技術來向I/O設備發送命令。
- 在使用內存映射I/O的系統中，地址空間中有一塊地址是為I/O設備通信保留的，每個這樣的地址稱為I/O端口（I/O port）。
- 當一個設備連接到總線時，它被分配（映射/關聯）到一個或者多個I/O端口。
- 舉個例子：
    - 當需要讀取磁盤內容，CPU可能通過對端口地址的存儲指令發起磁盤讀取操作，通過一系列操作發送磁盤讀取操作後，磁盤受到命令，通過DMA（Direct Memory Access，直接內存訪問）將數據通過I/O總線和內存總線傳送到內存中，而CPU在這段時間則可以執行其他操作。
    - DMA傳送完成後，磁盤扇區的內容被安全存儲到主存後，磁盤控制器通過給CPU發送一箇中斷信號來通知CPU。基本思想是中斷信號會發送到CPU芯片的一個外部引腳，CPU收到後會暫停工作，跳轉到一個操作系統例程，這個程序會記錄下I/O已經完成，然後將控制返回到CPU被中斷的地方。

### 固態硬盤

- SSD是基於閃存的存儲設備，是磁盤的替代品，速度更塊，價格也更貴。
- 一個SSD封裝一個或者多個閃存芯片（顆粒）和閃存翻譯層（主控與固件），翻譯層扮演磁盤控制器相同的角色，將對邏輯塊的請求翻譯為對底層物理設備的訪問。
- 讀SSD比寫更快，隨機讀寫性能低於順序讀寫。
- 現在的SSD設備速度的數百MB/S到數GB/s左右（高可至3GB/s，最低也可達數百MB/s），相比機械硬盤速度有非常大的提升。

### 存儲技術趨勢

- 不同的存儲技術有不同的價格和性能折中。
    - 速度：SRAM > DRAM > SSD > HDD。
    - 每單位價格：SRAM > DRAM > SSD > HDD。
    - 容量則通常相反。
- 不同存儲技術的價格和性能屬性以不同的速率在發展：總體趨勢是容量增加很快，但是訪問時間降低並沒有那麼快。
- DRAM和磁盤性能滯後於CPU的性能：總體來說DRAM和磁盤的速度和容量的發展速度趕不上CPU性能提升的速度。
    - 特別是CPU和DRAM之間的性能差距實際上是在加大的，這主要是因為CPU發展太快了，而DRAM則沒有那麼快。
    - 為了彌補這一點，現代CPU中普通使用SRAM作用高速緩存，也讓緩存未命中的相對代價變得越來越大。
- 不過現代CPU的提升已經沒有那麼顯著了，CPU的發展撞上了功耗牆，時鐘頻率在多年前就已經增加不動了。現在CPU都是憑靠更高的指令級數據級並行度、更多的核心、更先進的製程工藝在前進。

## 6.2 局部性

一個編寫良好的程序常常具有良好的局部性（locality），也就是他們傾向於引用臨近與最近引用的數據項的數據項，或者最近引用過的數據項本身。
- 這種傾向性成為局部性原則，對硬件和軟件系統的設計和性能都有很大影響。
- 局部性有兩種形式：時間局部性（temporal locality）和空間局部性（spatial locality）。
    - 時間局部性：被引用過一次的內存位置可能在不遠的將來被再次引用。
    - 空間局部性：一個內存位置被引用了一次，那麼程序很可能在不遠的將來引用附近的內存位置。
- 一般而言，具有良好局部性的程序比局部性差的程序運行得更快。

**對程序數據引用的局部性**：
- 看例子：
```C
int sumvec(int* v, int N)
{
    int i, sum = 0;
    for (i = 0; i < N; ++i)
    {
        sum += v[i];
    }
    return sum;
}
```
- 對於變量`sum`來說，具有良好的時間局部性，但沒有空間局部性。
- 對於變量`v`來說，具有良好的空間局部性，但沒有時間局部性。
- 這個函數中的變量要麼具有好的時間局部性，要麼具有好的空間局部性。所以我們可以斷定這個函數具有良好的局部性。
- 在循環遍歷連續內存時，我們稱兩輪循環見元素的間隔為步長，上面的`sumvec`稱為步長為1的引用模式。而步長k則稱之為步長為k的引用模式。
- 一般來說，步長越長。空間局部性越差。步長為1則空間局部性最好。
- 可以先到，在遍歷二維數組時，因為數組按照行優先連續存儲，如果行優先遍歷，那麼空間局部性會比較好，如果按照列優先遍歷，空間局部性就會相對更差。

**對程序指令引用的局部性**：
- 除了數據，指令也會被加載到緩存中。
- 很容易想到，循環的指令引用會有比較好的空間局部性，因為循環體會被執行多次，我們可以預料到循環體的代碼會一致位於緩存中，不會出現未命中的情況（當然有個前提是循環不能長到緩存裝不下，或者循環中不至於執行了太多東西導致將循環體的代碼替換出緩存）。
- 代碼區別於數據的一個重要屬性是它是運行時不能被修改的。

小結：
- 重複引用相同變量的程序具有良好的時間局部性。
- 對於步長為k的引用模式的循環，步長越小，空間局部性越好。步長為1的引用模式的程序有很好的空間局部性，在內存中跳來跳去的程序空間局部性會很差。
- 對於取指令來說，循環具有很好的時間和空間局部性。循環體越小，循環迭代次數越多，局部性越小。
- 通常來說，看一眼代碼就能對程序中的局部性有清晰的認識，這是一項很重要的技能。當然想要利用局部性來優化可能並不是一個簡單的事情，但是有清晰的認識之後至少指明瞭方向。

## 6.3 存儲器層次結構

計算機的存儲器層次（memory hierarchy）：

|層次|存儲|典型訪問速度|
|:-:|:-:|:-:|
|L0|寄存器|1個週期之內，0ns
|L1|L1緩存（SRAM）|4個週期左右，1~2ns
|L2|L2緩存（SRAM）|10個週期左右，4ns
|L3|L3緩存（SRAM）|50個週期左右，25ns
|L4|主存（DRAM）|200週期左右，50~100ns
|L5|本地二級存儲（本地磁盤SSD）|100000週期左右，50us
|L6|遠程二級存儲<p>（分佈式文件系統、WEB服務器）|取決於服務器遠近，信道長度，典型在幾百ms左右

- 不一定十足準確，但數量級一定是差不多的。
- 從上到下，單位容量越來越貴，通常來說容量也越來越大，速度也越來越慢。
- 三個層級緩存的典型容量舉例：L1 32KB（指令數據緩存均為32KB是分開的，並且每個核心都有一份），L2 256KB（每個核心都有一份256KB），L3 8MB（所有核心共享）。
- 更多信息：[Latency Numbers Every Programmer Should Know](https://colin-scott.github.io/personal_website/research/interactive_latency.html)。

![](memory_hierarchy.JPG)

- Ulrich Drepper經典論文：[What Every Programmer Should Know About Memory](What%20Every%20Programmer%20Should%20Know%20About%20Memory.pdf)

### 存儲器層次結構中的緩存

存儲器層次結構的中心思想是：每一層都是下一層的緩存。
- 相鄰兩層之間使用約定大小的數據塊（block，chunk）進行數據交換，但是不同層次之間的數據大小可能不同。
- 比如L1緩存和寄存器的數據交換大小通常是一個字，L1與L2、L2與L3、以及L3與L4的大小通常是幾十字節（通常是一個緩存行長度，典型值64Bytes）。而L4與L5則可能是幾十或者幾千字節的塊。

緩存命中狀態：
- 緩存命中：上一層需要的數據恰好在下一層緩存中找到。
- 緩存未命中：上一層需要的數據沒有在下一層緩存中找到，就需要再向下查找。這是需要替換這一層的緩存塊，有一些典型替換策略比如LRU（最近最少使用）策略。
- 緩存未命中的種類：
    - 空的緩存：冷緩存（cold cache），強制性未命中或者冷未命中（cold miss），通常是短暫時間，比如程序剛運行時。
    - 因為緩存需要替換，因為緩存塊替換而導致的未命中稱為衝突未命中（conflict miss）。
    - 程序通常是按照一系列階段（循環）來運行的，每個階段訪問緩存塊的某個相對穩定不變的集合，稱這個集合為這個階段的工作集（working set）。
    - 當工作集大小超過緩存大小時，會發生容量未命中（capacity miss），換句話說就是緩存太小了，裝不下整個工作集。
- 緩存管理：將緩存劃分成塊、在不同層之間傳遞塊、判斷緩存命中還是未命中並處理他們的工作就是緩存管理。可以是硬件、軟件或者兩者結合。
    - 一般來說，L1、L2、L3緩存完全由內置在緩存中的硬件邏輯管理。
    - 在有虛擬內存的系統上，內存由操作系統軟件和CPU中的地址翻譯硬件共同管理。
    - 分佈式文件系統、網絡文件系統之類則由專門的軟件進程負責管理。

## 6.4 高速緩存存儲器

高速緩存的實現、替換策略、組相聯、全相聯等內容略。

## 6.5 編寫緩存友好的程序

編寫高速緩存友好的程序：
- 讓最常見的情況運行得快，也就是優化性能瓶頸。
- 儘量減少每個循環內部的緩存未命中數量：也就是要增強時間和空間局部性。

## 6.6 綜合：高速緩存對程序的影響

一個程序從存儲系統中讀取數據的速率稱之**讀吞吐量**（read throughput），或者有時稱為讀帶寬。通常以MB/s為單位，用來衡量程序的存儲性能。在循環中，以不同步長和工作集大小作為測試，可以得到一個讀帶寬的時間與空間局部性的二維函數，稱為**存儲器山**（the memory mountain）：

![](the_memory_mountain.JPG)

- 可以看到，步長越大，空間局部性越弱，讀帶寬越低。
- 工作集越大，時間局部性越弱，讀帶寬越低。
- 當步長為1，工作集大小和L1緩存大小相當時性能最佳。
- 比較有趣的是最左側，步長最小時因為**指令預取機制**（prefetching）的存在可以有非常高的讀帶寬。這是Core i7存儲器系統中提供的，在小步長時會自動識別，並提前預取需要的數據到緩存中，預防了緩存失效。步長越小效果會越明顯。
- 我們也可以在代碼中手動進行緩存預取以提升性能，Intel的SSE指令集提供了手動預取指令：
```C
#include <mmintrinsics.h>
void _mm_prefetch(char * p , int i ); // 其中 p 是數據所在的內存地址，i 是要載入哪一個層級的Cache
```
- [GCC緩存預取相關支持的文檔](https://gcc.gnu.org/projects/prefetch.html)，內建有`__builtin_prefetch `函數。

## 6.7 小節

理解存儲器層次結構本質的程序員能夠利用這些知識編寫更高效的程序，無論存儲器結構是怎麼樣的，推薦技術：
- 將注意力放在循環內部，大部分計算和訪問發生在這裡。
- 按照數據對象存儲在內存中的順序、以步長為1訪問數據，使得空間局部性最大。
- 一旦存儲器讀入了一個數據對象，就儘可能多地使用它，從而使時間局部性最大。

總體來說，CPU緩存對程序員是透明的，所有操作和策略都是由CPU完成的，瞭解CPU cache的設計、原理有利於我們更好利用CPU緩存，寫出緩存友好的程序。

## 補充

- 蘇黎世聯邦理工：[計算機體系結構](https://www.bilibili.com/video/BV1Vf4y1i7YG/)，講了很多關於內存的東西。
- 大牛Brendan Gregg的網站：[https://www.brendangregg.com/](https://www.brendangregg.com/)，更多關於高性能編程的東西。