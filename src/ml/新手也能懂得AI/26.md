## 蒐集資料與訓練模型時會發生的常見問題 & 解決方式



今天是課程倒數第二天，我相信你在學習的過程中產生了很多的疑問，所以今天我要來統整在訓練時常見的問題與解決方式。但注意這些回答**都是參考解答不一定是最佳解**，因為在深度學習的技術中，我們沒有經過實驗是不會知道結果的。

## loss值相關問題

Q1:train loss與test loss趨近不變
A1:這通常代表神經網路學習完畢，若準確率不足可以嘗試更換神經網路架構。

Q2:為什麼train loss與test loss不管怎麼樣訓練都會非常的高，但卻會穩定下降
A2:通常這種情況會發生在回歸任務，最主要是因為資料沒有縮放到0~1之間導致loss值很高。

Q3:train loss 下降，test卻不會變動了該怎麼辦?
A3:神經網路已經overfitting了，若準確率足夠應該要做Early stopping的動作，若不足應該降低學習率或增加神經網路的深度來解決這個問題

Q4:train loss下降(不變)，test卻上升了這是怎麼回事?
A4:通常不會遇到這些種狀況，當你遇到這種情況最大的可能性就是**資料集有問題**(亂數資料)，可以試試將資料前處理後再放入神經網路訓練，看問題能否被改善

Q5:train loss不斷上升，test loss不斷上升
A5:會產生這問題的主要原因是**神經網路無法有效學習到資料的特徵**，通常遇到此情況只要降低學習率就會有不錯的結果。

## 模型相關問題

Q1:神經網路的各層參數該選擇多少?
A1:一般會以2的倍數去建立參數，若是圖片的部分(CNN)會有2n+1來設定，但還是要經過實驗才能知道最好的結果。

Q2:每層該選用那些激勵函數?
A2:通常在RNN神經網路中會選用tanh當作激勵函數(在RNN中比較重要的是資料分佈狀態而不是特徵)，在CNN中會選用relu(與RNN相反比較需要知道特徵而不是分佈)，回歸任務會選擇liner(為了能夠貼近實際值)，多分類任務會選擇softmax(softmax會回傳位子訊息及各機率很適合多分類)，二分類任務會選用sigmoid(數值會在0~1之間可以使用0.5作為分界線)。

Q3:損失函數該怎麼選擇?
A3:在回歸任務中若覺得異常資料不重要會選擇MAE，不重要則會選擇MSE，而在分類任務中多分類任務會選擇Categorical Crossentropy，二分法會選擇Binary Crossentropy

Q4:優化器該怎麼選擇?
A4:最通用的優化器我認為是adam，但若有無法收斂的問題可以試試用SGD[詳細內容可以看這裡](https://medium.com/ai-blog-tw/deep-learning-為什麼adam常常打不過sgd-癥結點與改善方案-fd514176f805)

Q5:學習率多少才適合?
A5:沒有特定的答案，通常我會使用1e-4來測試結果，若遇見問題再調整(可以觀看loss相關問題)

## 資料前處理相關問題

Q1:為何要將圖像灰階化
A1:因為灰階化能夠移除掉影像中的部分亮點，還能夠加速程式運算速度

Q2:圖片有雜訊、光影差距大該怎麼辦?
A2:可以使用一些濾波器(中值濾波器、平均濾波器、高斯濾波器...等)，來增強影像品質

Q3:有些圖片是斜的，但我需要這些數據可是會影響到準確率，該怎麼做?
A3:可以使用透視變換(Perspective Transformation)的方式將圖片轉正

Q4:什麼時候該降維資料?
A4:當資料維度太高、資料較混亂、需快速計算時都能夠使用

Q5:為何要資料標準化(縮放到0~1之間)，可以不要嗎?
A5:資料標準化是為了使梯度能夠快速且正常的下降，若沒有標準化loss值的差距就會過高，這樣不僅會影響準確率，還會增加訓練時間。

Q6:為何要做資料清洗(Data Cleansing)
A6:在訓練神經網路時我們需要去計算出每個結果的權重，若放入的資料是較混亂的，那計算上肯定會發生問題。

Q7:做NLP任務時該把符號刪除嗎?
A7:應該要刪除一些大量重複出現的符號(逗號、分號、引號)，留下一些能表達語氣的符號(驚嘆號、問號)

Q8:該刪除停用語嗎?
A8:這要看模型的架構才能夠決定，基本上無法解決多義詞的模型都應該刪除停用語

Q9:為何在做文字前處理時是將文字轉換成小寫而不是大寫
A9:這其實沒有什麼差，只是大寫符號通常在程式代表的是參數

## Pytorch、爬蟲常見問題

Q1:為何我訓練的速度會越來越慢
A1:通常是因為CPU或GPU的散熱問題導致效能越來越差

Q2:在pytorch訓練中為什麼會跑到一半才會提示無法在將資料放入GPU中了
A2:這是因為放入GPU的時機不對，通常出現這個問題是因為在dataset建立時就放入GPU中了，這導致python認為你還需要這些變數因此無法正常釋放GPU空間(python會自動釋放無用變數)

Q3:為什麼我在網頁上能看到我想要爬的資料，但程式內看不到?
A3:因為網站是採用AJAX的方式來取的資料的，所以我們該請求的網址應該是AJAX的網址。

Q4:selenium是一種動態爬蟲的方式可以簡易的寫出爬蟲程式為何大家都不用?
A4:最主要的原因還是因為selenium太緩慢了，我們使用requests的爬蟲方式只須對單一AJAX網址發送請求，但selenium卻是模仿瀏覽器的動作一次性的請求過多無用資料。

Q5:request該如何操作網頁上的物件?
A5:通常我們可以觀察網址中的參數來做一些基礎操作，但有些較複雜的動作(例如登入)就必須採用cookie的方式才能夠操作物件。

