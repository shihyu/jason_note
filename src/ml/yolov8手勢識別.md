#  æœ¬æ–‡å°‡æ‰‹æŠŠæ‰‹æ•™ä½ ç”¨YoloV8è¨“ç·´è‡ªå·±çš„è³‡æ–™é›†ä¸¦å¯¦ç¾æ‰‹å‹¢è­˜åˆ¥



## å®‰è£ç’°å¢ƒ

ã€1ã€‘å®‰è£torch, torchvisionå°æ‡‰ç‰ˆæœ¬ï¼Œé€™è£¡å…ˆä¸‹è¼‰å¥½ï¼Œç›´æ¥å®‰è£

```python
pip install torchvision-0.14.1+cu116-cp38-cp38-win_amd64.whl
pip install torch-1.13.1+cu116-cp38-cp38-win_amd64.whl
```

å®‰è£å¥½å¾Œå¯ä»¥æŸ¥çœ‹æ˜¯å¦å®‰è£æˆåŠŸï¼Œä¸Šé¢å®‰è£çš„gpuç‰ˆæœ¬ï¼ŒæŸ¥çœ‹æŒ‡ä»¤èˆ‡çµæœï¼š

```python
import torch
print(torch.__version__)
print(torch.cuda.is_available())
```

ã€2ã€‘å®‰è£ultralytics

```sh
pip install ultralytics
```

**ã€3ã€‘ä¸‹è¼‰YoloV8é è¨“ç·´æ¨¡å‹ï¼š**[GitHub - ultralytics/ultralytics: NEW - YOLOv8 ğŸš€ in PyTorch > ONNX > OpenVINO > CoreML > TFLite](https://github.com/ultralytics/ultralytics)

![img](images/269ddd96c1e404280c4547b45b90463c.png)

ã€4ã€‘é‹è¡Œdemoæ¸¬è©¦å®‰è£æ˜¯å¦æˆåŠŸï¼š

```python
from ultralytics import YOLO
# Load a model
model = YOLO('yolov8n.pt')  # pretrained YOLOv8n model
 
# Run batched inference on a list of images
results = model(['1.jpg', '2.jpg'])  # return a list of Results objects
 
# Process results list
for result in results:
    boxes = result.boxes  # Boxes object for bounding box outputs
    masks = result.masks  # Masks object for segmentation masks outputs
    keypoints = result.keypoints  # Keypoints object for pose outputs
    probs = result.probs  # Probs object for classification outputs
    result.show()  # display to screen
    result.save(filename='result.jpg')  # save to disk
```



![](images/cab930e0b8ebc9b7894ab1e67c68ff7d.png)



## æ¨™è¨»/è£½ä½œè³‡æ–™é›†
ã€1ã€‘æº–å‚™å¥½å¾…æ¨™è¨»åœ–ç‰‡

    å¯ä»¥è‡ªå·±å¯«ä¸€å€‹å¾æ”å½±æ©Ÿå­˜åœ–çš„æŒ‡ä»¤ç¢¼ä¿å­˜ä¸€ä¸‹ä¸åŒæ‰‹å‹¢åœ–åˆ°æœ¬åœ°ï¼Œé€™è£¡æä¾›ä¸€å€‹ä¾›åƒè€ƒï¼š

```python
import cv2
 
cap = cv2.VideoCapture(0)
flag = 0
 
if(cap.isOpened()): #è¦–è¨Šæ‰“é–‹æˆåŠŸ
  flag = 1
else:
  flag = 0
  print('open cam failed!')
 
if(flag==1):
  while(True):
    cv2.namedWindow("frame")
    ret,frame = cap.read()#è®€å–ä¸€å¹€
    if ret==False: #è®€å–å¹€å¤±æ•—
      break
    cv2.imshow("frame", frame)
    if cv2.waitKey(50)&0xFF ==27: #æŒ‰ä¸‹Escéµé€€å‡º
      cv2.imwrite("1.jpg",frame)
      break
 
cap.release()
cv2.destroyAllWindows()
```

æœ¬æ–‡ä½¿ç”¨å…±3ç¨®æ‰‹å‹¢**1ï¼Œ2ï¼Œ5**ï¼Œä¸‰ç¨®æ‰‹å‹¢å„300å¼µï¼Œå¤§å®¶å¯ä»¥æ ¹æ“šå¯¦éš›æƒ…æ³å¢æ¸›æ¨£æœ¬æ•¸é‡ã€‚

![img](images/8e2b111498ea21f92640153562bf2f68.png)

**ã€2ã€‘æ¨™è¨»æ¨£æœ¬**

  æ¨™è¨»å·¥å…·ä½¿ç”¨labelimgå³å¯ï¼Œç›´æ¥pipå®‰è£ï¼š

```sh
pip install labelimg
```

å®‰è£å®Œæˆå¾Œï¼Œå‘½ä»¤åˆ—ç›´æ¥è¼¸å…¥labelimgï¼ŒEnterå³å¯æ‰“é–‹labelimgï¼Œè³‡æ–™é›†é¡å‹åˆ‡æ›æˆYOLOï¼Œç„¶å¾Œä¾æ¬¡å®Œæˆæ¨™è¨»å³å¯ã€‚

![img](images/79a3709ec710ac4848a4fb0ae0ca0e53.png)

**ã€3ã€‘æ¨™è¨»åŠƒåˆ†**

  æ¨™è¨»å¥½ä¹‹å¾Œï¼Œä½¿ç”¨ä¸‹é¢çš„æŒ‡ä»¤ç¢¼åŠƒåˆ†è¨“ç·´é›†ã€é©—è­‰é›†ï¼Œæ³¨æ„è¨­å®šæ­£ç¢ºçš„åœ–ç‰‡å’Œtxtè·¯å¾‘ï¼š

```python
import os
import random
import shutil
 
# è¨­å®šæª”æ¡ˆè·¯å¾‘å’ŒåŠƒåˆ†æ¯”ä¾‹
root_path = "./voc_yolo/"
image_dir = "./JPEGImages/"
label_dir = "./Annotations/"
train_ratio = 0.7
val_ratio = 0.2
test_ratio = 0.1
 
# å»ºç«‹è¨“ç·´é›†ã€é©—è­‰é›†å’Œæ¸¬è©¦é›†ç›®éŒ„
os.makedirs("images/train", exist_ok=True)
os.makedirs("images/val", exist_ok=True)
os.makedirs("images/test", exist_ok=True)
os.makedirs("labels/train", exist_ok=True)
os.makedirs("labels/val", exist_ok=True)
os.makedirs("labels/test", exist_ok=True)
 
# ç²å–æ‰€æœ‰åœ–åƒæª”æ¡ˆåç¨±
image_files = os.listdir(image_dir)
total_images = len(image_files)
random.shuffle(image_files)
 
# è¨ˆç®—åŠƒåˆ†æ•¸é‡
train_count = int(total_images * train_ratio)
val_count = int(total_images * val_ratio)
test_count = total_images - train_count - val_count
 
# åŠƒåˆ†è¨“ç·´é›†
train_images = image_files[:train_count]
for image_file in train_images:
    label_file = image_file[:image_file.rfind(".")] + ".txt"
    shutil.copy(os.path.join(image_dir, image_file), "images/train/")
    shutil.copy(os.path.join(label_dir, label_file), "labels/train/")
 
# åŠƒåˆ†é©—è­‰é›†
val_images = image_files[train_count:train_count+val_count]
for image_file in val_images:
    label_file = image_file[:image_file.rfind(".")] + ".txt"
    shutil.copy(os.path.join(image_dir, image_file), "images/val/")
    shutil.copy(os.path.join(label_dir, label_file), "labels/val/")
 
# åŠƒåˆ†æ¸¬è©¦é›†
test_images = image_files[train_count+val_count:]
for image_file in test_images:
    label_file = image_file[:image_file.rfind(".")] + ".txt"
    shutil.copy(os.path.join(image_dir, image_file), "images/test/")
    shutil.copy(os.path.join(label_dir, label_file), "labels/test/")
 
# ç”Ÿæˆè¨“ç·´é›†åœ–ç‰‡è·¯å¾‘txtæª”æ¡ˆ
with open("train.txt", "w") as file:
    file.write("\n".join([root_path + "images/train/" + image_file for image_file in train_images]))
 
# ç”Ÿæˆé©—è­‰é›†åœ–ç‰‡è·¯å¾‘txtæª”æ¡ˆ
with open("val.txt", "w") as file:
    file.write("\n".join([root_path + "images/val/" + image_file for image_file in val_images]))
 
# ç”Ÿæˆæ¸¬è©¦é›†åœ–ç‰‡è·¯å¾‘txtæª”æ¡ˆ
with open("test.txt", "w") as file:
    file.write("\n".join([root_path + "images/test/" + image_file for image_file in test_images]))
 
print("è³‡æ–™åŠƒåˆ†å®Œæˆï¼")
```

æ¥è‘—æœƒç”ŸæˆåŠƒåˆ†å¥½çš„è³‡æ–™é›†å¦‚ä¸‹ï¼š

![åœ–ç‰‡](images/f838ac46fe7b9b5ce2da84cebc0ce628.png)

æ‰“é–‹imagesè³‡æ–™å¤¾ï¼š



![åœ–ç‰‡](images/a78027dffb44523ab536c727391e3b0c.png)



æ‰“é–‹imagesä¸‹çš„trainè³‡æ–™å¤¾ï¼š

![åœ–ç‰‡](images/dda3002c54988fe2fe1607f6873d1206.png)

æ‰“é–‹labelsä¸‹çš„trainè³‡æ–™å¤¾ï¼š

![åœ–ç‰‡](images/0cd5a7a0e32f180cdea7ca1a36f63741.png)

## è¨“ç·´èˆ‡é æ¸¬

**ã€1ã€‘é–‹å§‹è¨“ç·´**

  è¨“ç·´æŒ‡ä»¤ç¢¼å¦‚ä¸‹ï¼š

```python
from ultralytics import YOLO
# Load a model
model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)
 
results = model.train(data='hand.yaml', epochs=30, imgsz=640, device=[0],
                      workers=0,lr0=0.001,batch=8,amp=False)
```

  hand.yamlå…§å®¹å¦‚ä¸‹ï¼Œæ³¨æ„ä¿®æ”¹è‡ªå·±çš„è³‡æ–™é›†è·¯å¾‘å³å¯ï¼š

```python
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# COCO8 dataset (first 8 images from COCO train2017) by Ultralytics
# Documentation: https://docs.ultralytics.com/datasets/detect/coco8/
# Example usage: yolo train data=coco8.yaml
# parent
# â”œâ”€â”€ ultralytics
# â””â”€â”€ datasets
#     â””â”€â”€ coco8  â† downloads here (1 MB)
 
# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: E:/Practice/DeepLearning/Yolo_Test/dataset/hand # dataset root dir
train: E:/Practice/DeepLearning/Yolo_Test/dataset/hand/images/train # train images (relative to 'path') 4 images
val: E:/Practice/DeepLearning/Yolo_Test/dataset/hand/images/val # val images (relative to 'path') 4 images
test: # test images (optional)
 
# Classes
names:
  0: hand-1
  1: hand-2
  2: hand-5
 
 
# Download script/URL (optional)
# download: https://ultralytics.com/assets/coco8.zip
```


CPUè¨“ç·´å°‡device=[0]æ”¹ç‚ºdevice='cpu'å³å¯

è¨“ç·´å®Œæˆå¾Œå†runs/detect/trainè³‡æ–™å¤¾ä¸‹ç”Ÿæˆå¦‚ä¸‹å…§å®¹ï¼š

åœ¨weightsè³‡æ–™å¤¾ä¸‹ç”Ÿæˆå…©å€‹æ¨¡å‹æª”æ¡ˆï¼Œç›´æ¥ä½¿ç”¨best.ptå³å¯ã€‚

![](images/2f7fe751fd98ab19c7675ebb95eb5e03.png)

ã€2ã€‘é æ¸¬æ¨ç†

é æ¸¬æŒ‡ä»¤ç¢¼å¦‚ä¸‹ï¼š

```python
from ultralytics import YOLO
# Load a model
model = YOLO('best.pt')  # pretrained YOLOv8n model
 
# Run batched inference on a list of images
results = model(['1 (1).jpg', '1 (2).jpg', '1 (3).jpg'])  # return a list of Results objects
 
# Process results list
for result in results:
    boxes = result.boxes  # Boxes object for bounding box outputs
    masks = result.masks  # Masks object for segmentation masks outputs
    keypoints = result.keypoints  # Keypoints object for pose outputs
    probs = result.probs  # Probs object for classification outputs
    result.show()  # display to screen
    result.save(filename='result.jpg')  # save to disk
```

é æ¸¬çµæœï¼š

![img](images/d8a21445b2e08a356e07ec5e65471c8c.png)

![img](images/d04539714f51fbb5c75076732a608412.png)

![img](images/e7681aec361b686d9c255612aee881b7.png)

