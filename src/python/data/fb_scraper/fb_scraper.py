# -*- coding: utf-8 -*-
from fb_graphql_scraper.facebook_graphql_scraper import (
    FacebookGraphqlScraper as fb_graphql_scraper,
)
import json


def print_results(res):
    """çµ±ä¸€çš„çµæœè¼¸å‡ºæ ¼å¼"""
    # ç°¡æ½”è¼¸å‡º
    print("=" * 60)
    print(f"ç”¨æˆ¶: {res['profile'][0]}")
    print(f"è¿½è¹¤è€…: {res['profile'][-1]}")
    print(f"å…± {len(res['data'])} ç¯‡è²¼æ–‡")
    print("=" * 60)

    for i, post in enumerate(res["data"], 1):
        print(f"\nã€è²¼æ–‡ {i}ã€‘{post['published_date2']}")
        print(
            f"ğŸ‘ {post['reaction_count.count']} | ğŸ’¬ {post['comment_rendering_instance.comments.total_count']} | ğŸ“¤ {post['share_count.count']}"
        )

        # é¡¯ç¤ºå…§å®¹ï¼ˆå‰80å­—ï¼‰
        content = post["context"].replace("\n", " ")
        # if len(content) > 80:
        #    content = content[:80] + "..."
        print(f"ğŸ“ {content}")
        print("-" * 40)

    # å„²å­˜å®Œæ•´è³‡æ–™åˆ° JSON
    with open("facebook_data.json", "w", encoding="utf-8") as f:
        json.dump(res, f, indent=2, ensure_ascii=False, default=str)
    print(f"\nâœ… å®Œæ•´è³‡æ–™å·²å„²å­˜åˆ° facebook_data.json")


## Example.1 - without logging in
if __name__ == "__main__":
    # è¨­å®šç›®æ¨™ç”¨æˆ¶
    facebook_user_name = ""
    facebook_user_id = "100077534854138"
    days_limit = 60  # Number of days within which to scrape posts

    # ä¿®æ­£ 1: ä½¿ç”¨æ­£ç¢ºçš„ Linux ChromeDriver è·¯å¾‘æˆ–è¨­ç‚º None
    driver_path = None  # è®“ç³»çµ±è‡ªå‹•å°‹æ‰¾ï¼Œæˆ–ä½¿ç”¨ä½ çš„å¯¦éš›è·¯å¾‘
    # driver_path = "/usr/local/bin/chromedriver"  # å¦‚æœä½ æ‰‹å‹•å®‰è£äº† ChromeDriver

    print("ğŸ” é–‹å§‹çˆ¬å– Facebook è³‡æ–™ï¼ˆæœªç™»å…¥æ¨¡å¼ï¼‰...")

    try:
        fb_spider = fb_graphql_scraper(driver_path=driver_path, open_browser=False)
        res = fb_spider.get_user_posts(
            fb_username_or_userid=facebook_user_id,
            days_limit=days_limit,
            display_progress=True,
        )

        # ä½¿ç”¨çµ±ä¸€çš„è¼¸å‡ºæ ¼å¼
        print_results(res)

        # å¦‚æœéœ€è¦æŸ¥çœ‹åŸå§‹ JSON æ ¼å¼ï¼Œå–æ¶ˆä¸‹é¢çš„è¨»è§£
        # print("\n" + "="*60)
        # print("åŸå§‹ JSON è³‡æ–™:")
        # print("="*60)
        # print(json.dumps(res, indent=2, ensure_ascii=False, default=str))

    except Exception as e:
        print(f"âŒ éŒ¯èª¤: {e}")

## Example.2 - login in your facebook account to collect data
# if __name__ == "__main__":
#     # ç™»å…¥å¸³è™Ÿè¨­å®š
#     facebook_user_name = ""
#     facebook_user_id = "100077534854138"
#     fb_account = "your_facebook_email@gmail.com"  # ä¿®æ­£ï¼šä½¿ç”¨çœŸå¯¦å¸³è™Ÿ
#     fb_pwd = "your_facebook_password"              # ä¿®æ­£ï¼šä½¿ç”¨çœŸå¯¦å¯†ç¢¼
#     days_limit = 60  # Number of days within which to scrape posts
#     driver_path = None  # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¢ºè·¯å¾‘
#
#     print("ğŸ” é–‹å§‹çˆ¬å– Facebook è³‡æ–™ï¼ˆç™»å…¥æ¨¡å¼ï¼‰...")
#
#     try:
#         fb_spider = fb_graphql_scraper(
#             fb_account=fb_account,
#             fb_pwd=fb_pwd,
#             driver_path=driver_path,
#             open_browser=False
#         )
#         res = fb_spider.get_user_posts(
#             fb_username_or_userid=facebook_user_id,
#             days_limit=days_limit,
#             display_progress=True
#         )
#
#         # ä½¿ç”¨çµ±ä¸€çš„è¼¸å‡ºæ ¼å¼
#         print_results(res)
#
#     except Exception as e:
#         print(f"âŒ éŒ¯èª¤: {e}")

"""
ä½¿ç”¨èªªæ˜:
1. æœªç™»å…¥æ¨¡å¼: ç›´æ¥åŸ·è¡Œå³å¯ï¼Œä½†å¯èƒ½å—åˆ°é™åˆ¶
2. ç™»å…¥æ¨¡å¼: 
   - è¨»è§£æ‰ Example.1 çš„ if __name__ == "__main__": å€å¡Š
   - å–æ¶ˆè¨»è§£ Example.2 çš„å€å¡Š
   - å¡«å…¥çœŸå¯¦çš„ Facebook å¸³è™Ÿå’Œå¯†ç¢¼
   - åŸ·è¡Œç¨‹å¼

æ³¨æ„äº‹é …:
- è«‹éµå®ˆ Facebook çš„æœå‹™æ¢æ¬¾
- å»ºè­°åªçˆ¬å–è‡ªå·±çš„è³‡æ–™æˆ–å…¬é–‹è³‡æ–™
- ç™»å…¥æ¨¡å¼å¯èƒ½ç²å¾—æ›´å¤šè³‡æ–™ï¼Œä½†ä¹Ÿæœ‰å¸³è™Ÿé¢¨éšª
"""
