{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ahmQx4ks9IsU"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "res = requests.get('https://cdn.openai.com/papers/gpt-4.pdf')\n",
        "with open('gpt-4.pdf', 'wb') as f:\n",
        "  f.write(res.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVahAZCJ_d4f",
        "outputId": "74fa40f9-3992-4226-c741-895be5f4a7d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-3.6.0-py3-none-any.whl (245 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.7/245.7 KB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from pypdf) (4.5.0)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "reader = PdfReader(\"gpt-4.pdf\")\n",
        "number_of_pages = len(reader.pages)\n",
        "page = reader.pages[0]\n",
        "text = page.extract_text()"
      ],
      "metadata": {
        "id": "zsqkzA3MAQr8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "cp5Nme6gAWa1",
        "outputId": "784bb30b-b495-4e87-afe9-45304511e04c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GPT-4 Technical Report\\nOpenAI\\x03\\nAbstract\\nWe report the development of GPT-4, a large-scale, multimodal model which can\\naccept image and text inputs and produce text outputs. While less capable than\\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance\\non various professional and academic benchmarks, including passing a simulated\\nbar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-\\nbased model pre-trained to predict the next token in a document. The post-training\\nalignment process results in improved performance on measures of factuality and\\nadherence to desired behavior. A core component of this project was developing\\ninfrastructure and optimization methods that behave predictably across a wide\\nrange of scales. This allowed us to accurately predict some aspects of GPT-4’s\\nperformance based on models trained with no more than 1/1,000th the compute of\\nGPT-4.\\n1 Introduction\\nThis technical report presents GPT-4, a large multimodal model capable of processing image and\\ntext inputs and producing text outputs. Such models are an important area of study as they have the\\npotential to be used in a wide range of applications, such as dialogue systems, text summarization,\\nand machine translation. As such, they have been the subject of substantial interest and progress in\\nrecent years [1–34].\\nOne of the main goals of developing such models is to improve their ability to understand and generate\\nnatural language text, particularly in more complex and nuanced scenarios. To test its capabilities\\nin such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans. In\\nthese evaluations it performs quite well and often outscores the vast majority of human test takers.\\nFor example, on a simulated bar exam, GPT-4 achieves a score that falls in the top 10% of test takers.\\nThis contrasts with GPT-3.5, which scores in the bottom 10%.\\nOn a suite of traditional NLP benchmarks, GPT-4 outperforms both previous large language models\\nand most state-of-the-art systems (which often have benchmark-speciﬁc training or hand-engineering).\\nOn the MMLU benchmark [ 35,36], an English-language suite of multiple-choice questions covering\\n57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but\\nalso demonstrates strong performance in other languages. On translated variants of MMLU, GPT-4\\nsurpasses the English-language state-of-the-art in 24 of 26 languages considered. We discuss these\\nmodel capability results, as well as model safety improvements and results, in more detail in later\\nsections.\\nThis report also discusses a key challenge of the project, developing deep learning infrastructure and\\noptimization methods that behave predictably across a wide range of scales. This allowed us to make\\npredictions about the expected performance of GPT-4 (based on small runs trained in similar ways)\\nthat were tested against the ﬁnal run to increase conﬁdence in our training.\\nDespite its capabilities, GPT-4 has similar limitations to earlier GPT models [ 1,37,38]: it is not fully\\nreliable (e.g. can suffer from “hallucinations”), has a limited context window, and does not learn\\n\\x03Please cite this work as “OpenAI (2023)\". Full authorship contribution statements appear at the end of the\\ndocument.arXiv:2303.08774v2  [cs.CL]  16 Mar 2023'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxpxvdc2A616",
        "outputId": "0b7d305e-eaf4-4d43-f9e6-b63ab6c12fa4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sentences = sent_tokenize(text)"
      ],
      "metadata": {
        "id": "6Rfw8dW0C6i6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "    print(sentence)\n",
        "    print('=' * 20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKd7vwQ_DYEP",
        "outputId": "f39890dd-74d0-4d53-db81-ded01b6afef4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-4 Technical Report\n",
            "OpenAI\u0003\n",
            "Abstract\n",
            "We report the development of GPT-4, a large-scale, multimodal model which can\n",
            "accept image and text inputs and produce text outputs.\n",
            "====================\n",
            "While less capable than\n",
            "humans in many real-world scenarios, GPT-4 exhibits human-level performance\n",
            "on various professional and academic benchmarks, including passing a simulated\n",
            "bar exam with a score around the top 10% of test takers.\n",
            "====================\n",
            "GPT-4 is a Transformer-\n",
            "based model pre-trained to predict the next token in a document.\n",
            "====================\n",
            "The post-training\n",
            "alignment process results in improved performance on measures of factuality and\n",
            "adherence to desired behavior.\n",
            "====================\n",
            "A core component of this project was developing\n",
            "infrastructure and optimization methods that behave predictably across a wide\n",
            "range of scales.\n",
            "====================\n",
            "This allowed us to accurately predict some aspects of GPT-4’s\n",
            "performance based on models trained with no more than 1/1,000th the compute of\n",
            "GPT-4.\n",
            "====================\n",
            "1 Introduction\n",
            "This technical report presents GPT-4, a large multimodal model capable of processing image and\n",
            "text inputs and producing text outputs.\n",
            "====================\n",
            "Such models are an important area of study as they have the\n",
            "potential to be used in a wide range of applications, such as dialogue systems, text summarization,\n",
            "and machine translation.\n",
            "====================\n",
            "As such, they have been the subject of substantial interest and progress in\n",
            "recent years [1–34].\n",
            "====================\n",
            "One of the main goals of developing such models is to improve their ability to understand and generate\n",
            "natural language text, particularly in more complex and nuanced scenarios.\n",
            "====================\n",
            "To test its capabilities\n",
            "in such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans.\n",
            "====================\n",
            "In\n",
            "these evaluations it performs quite well and often outscores the vast majority of human test takers.\n",
            "====================\n",
            "For example, on a simulated bar exam, GPT-4 achieves a score that falls in the top 10% of test takers.\n",
            "====================\n",
            "This contrasts with GPT-3.5, which scores in the bottom 10%.\n",
            "====================\n",
            "On a suite of traditional NLP benchmarks, GPT-4 outperforms both previous large language models\n",
            "and most state-of-the-art systems (which often have benchmark-speciﬁc training or hand-engineering).\n",
            "====================\n",
            "On the MMLU benchmark [ 35,36], an English-language suite of multiple-choice questions covering\n",
            "57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but\n",
            "also demonstrates strong performance in other languages.\n",
            "====================\n",
            "On translated variants of MMLU, GPT-4\n",
            "surpasses the English-language state-of-the-art in 24 of 26 languages considered.\n",
            "====================\n",
            "We discuss these\n",
            "model capability results, as well as model safety improvements and results, in more detail in later\n",
            "sections.\n",
            "====================\n",
            "This report also discusses a key challenge of the project, developing deep learning infrastructure and\n",
            "optimization methods that behave predictably across a wide range of scales.\n",
            "====================\n",
            "This allowed us to make\n",
            "predictions about the expected performance of GPT-4 (based on small runs trained in similar ways)\n",
            "that were tested against the ﬁnal run to increase conﬁdence in our training.\n",
            "====================\n",
            "Despite its capabilities, GPT-4 has similar limitations to earlier GPT models [ 1,37,38]: it is not fully\n",
            "reliable (e.g.\n",
            "====================\n",
            "can suffer from “hallucinations”), has a limited context window, and does not learn\n",
            "\u0003Please cite this work as “OpenAI (2023)\".\n",
            "====================\n",
            "Full authorship contribution statements appear at the end of the\n",
            "document.arXiv:2303.08774v2  [cs.CL]  16 Mar 2023\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CGrxusYDwZT",
        "outputId": "0b863b0a-f9d9-4414-edb2-2dfd4bece34b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
        "import openai\n",
        "openai.api_key = TOKEN\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"請你成為文章翻譯的小幫手，請協助翻譯以下技術文件，以繁體中文輸出\"},\n",
        "        {\"role\": \"user\", \"content\": sentences[0]},\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "ItRK4i9EEQBv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OPV08g0PE_1K",
        "outputId": "5397e6f2-2535-4da7-ebbe-a2f7610e61d8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GPT-4 技術報告\\nOpenAI\\n\\n摘要\\n本報告介紹了 GPT-4 的開發，這是一個大規模的多模式模型，可以接受圖像和文本輸入，並生成文本輸出。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = ''\n",
        "chunks = []\n",
        "for sentence in sentences:\n",
        "  input_sentences += sentence\n",
        "  if len(input_sentences) > 1000:\n",
        "    chunks.append(input_sentences)\n",
        "    input_sentences = ''\n",
        "chunks.append(input_sentences)"
      ],
      "metadata": {
        "id": "UFdN4uMnHDgR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLLlZtT2Hp-V",
        "outputId": "a4c78f8c-906b-44db-c49a-7faeee33c3e8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['GPT-4 Technical Report\\nOpenAI\\x03\\nAbstract\\nWe report the development of GPT-4, a large-scale, multimodal model which can\\naccept image and text inputs and produce text outputs.While less capable than\\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance\\non various professional and academic benchmarks, including passing a simulated\\nbar exam with a score around the top 10% of test takers.GPT-4 is a Transformer-\\nbased model pre-trained to predict the next token in a document.The post-training\\nalignment process results in improved performance on measures of factuality and\\nadherence to desired behavior.A core component of this project was developing\\ninfrastructure and optimization methods that behave predictably across a wide\\nrange of scales.This allowed us to accurately predict some aspects of GPT-4’s\\nperformance based on models trained with no more than 1/1,000th the compute of\\nGPT-4.1 Introduction\\nThis technical report presents GPT-4, a large multimodal model capable of processing image and\\ntext inputs and producing text outputs.',\n",
              " 'Such models are an important area of study as they have the\\npotential to be used in a wide range of applications, such as dialogue systems, text summarization,\\nand machine translation.As such, they have been the subject of substantial interest and progress in\\nrecent years [1–34].One of the main goals of developing such models is to improve their ability to understand and generate\\nnatural language text, particularly in more complex and nuanced scenarios.To test its capabilities\\nin such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans.In\\nthese evaluations it performs quite well and often outscores the vast majority of human test takers.For example, on a simulated bar exam, GPT-4 achieves a score that falls in the top 10% of test takers.This contrasts with GPT-3.5, which scores in the bottom 10%.On a suite of traditional NLP benchmarks, GPT-4 outperforms both previous large language models\\nand most state-of-the-art systems (which often have benchmark-speciﬁc training or hand-engineering).',\n",
              " 'On the MMLU benchmark [ 35,36], an English-language suite of multiple-choice questions covering\\n57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but\\nalso demonstrates strong performance in other languages.On translated variants of MMLU, GPT-4\\nsurpasses the English-language state-of-the-art in 24 of 26 languages considered.We discuss these\\nmodel capability results, as well as model safety improvements and results, in more detail in later\\nsections.This report also discusses a key challenge of the project, developing deep learning infrastructure and\\noptimization methods that behave predictably across a wide range of scales.This allowed us to make\\npredictions about the expected performance of GPT-4 (based on small runs trained in similar ways)\\nthat were tested against the ﬁnal run to increase conﬁdence in our training.Despite its capabilities, GPT-4 has similar limitations to earlier GPT models [ 1,37,38]: it is not fully\\nreliable (e.g.can suffer from “hallucinations”), has a limited context window, and does not learn\\n\\x03Please cite this work as “OpenAI (2023)\".',\n",
              " 'Full authorship contribution statements appear at the end of the\\ndocument.arXiv:2303.08774v2  [cs.CL]  16 Mar 2023']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"請你成為文章翻譯的小幫手，請協助翻譯以下技術文件，以繁體中文輸出\"},\n",
        "        {\"role\": \"user\", \"content\": chunks[0]},\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "n10iVG6UHq4M"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "HvmOUKSAHxCI",
        "outputId": "55ebb101-8c0e-4726-ad95-40c35ce51c5b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GPT-4技術報告\\nOpenAI\\n\\n摘要\\n我們報告了GPT-4的開發，這是一個可接受圖像和文本輸入並生成文本輸出的大規模多模型。儘管在許多現實世界情景中不如人類能力，GPT-4在各種專業和學術基準測試中表現出人類水平的性能，包括通過模擬的律師考試，得分排名前10%。GPT-4是一個基於Transformer的模型，預先訓練以預測文檔中的下一個標記。後訓練對齊過程會提高事實準確性和符合期望行為的性能。該項目的核心組件是開發在各種尺度上行為可預測的基礎設施和優化方法。這使我們能夠基於最多1/1,000的計算量訓練的模型來準確預測GPT-4的某些方面性能。\\n\\n簡介\\n本技術報告介紹GPT-4，這是一個大型多模型，可處理圖像和文本輸入並生成文本輸出。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 流程整理"
      ],
      "metadata": {
        "id": "V_H0znjWH_AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "pdf_name = \"gpt-4.pdf\" #@param {type:\"string\"}\n",
        "reader = PdfReader(pdf_name)\n",
        "number_of_pages = len(reader.pages)\n",
        "\n",
        "chunks = []\n",
        "\n",
        "for i in range(number_of_pages):\n",
        "  page = reader.pages[i]\n",
        "  text = page.extract_text()\n",
        "  sentences = sent_tokenize(text)\n",
        "  input_sentences = ''\n",
        "  \n",
        "  for sentence in sentences:\n",
        "    input_sentences += sentence\n",
        "    if len(input_sentences) > 1000:\n",
        "      chunks.append(input_sentences)\n",
        "      input_sentences = ''\n",
        "  chunks.append(input_sentences)"
      ],
      "metadata": {
        "id": "45k5JHzbIzcG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"請你成為文章翻譯的小幫手，請協助翻譯以下技術文件，以繁體中文輸出\"},\n",
        "        {\"role\": \"user\", \"content\": chunks[i]},\n",
        "    ]\n",
        "  )\n",
        "  print('原文:', chunks[i])\n",
        "  print('翻譯結果:',completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fpcfnZgJmtm",
        "outputId": "79d5f79c-971a-449e-e581-96fab0a502ff"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原文: GPT-4 Technical Report\n",
            "OpenAI\u0003\n",
            "Abstract\n",
            "We report the development of GPT-4, a large-scale, multimodal model which can\n",
            "accept image and text inputs and produce text outputs.While less capable than\n",
            "humans in many real-world scenarios, GPT-4 exhibits human-level performance\n",
            "on various professional and academic benchmarks, including passing a simulated\n",
            "bar exam with a score around the top 10% of test takers.GPT-4 is a Transformer-\n",
            "based model pre-trained to predict the next token in a document.The post-training\n",
            "alignment process results in improved performance on measures of factuality and\n",
            "adherence to desired behavior.A core component of this project was developing\n",
            "infrastructure and optimization methods that behave predictably across a wide\n",
            "range of scales.This allowed us to accurately predict some aspects of GPT-4’s\n",
            "performance based on models trained with no more than 1/1,000th the compute of\n",
            "GPT-4.1 Introduction\n",
            "This technical report presents GPT-4, a large multimodal model capable of processing image and\n",
            "text inputs and producing text outputs.\n",
            "翻譯結果: GPT-4技術報告\n",
            "OpenAI\n",
            "摘要\n",
            "本報告介紹GPT-4的開發，它是一個大型的多模態模型，能夠接受圖像和文本輸入並產生文本輸出。儘管在許多現實場景中不如人類能力強，但GPT-4在各種專業和學術測試中表現出人類水平的性能，包括以接近前10％的考生水平通過模擬律師考試。GPT-4是一個基於Transformer的模型，預先訓練以預測文檔中的下一個對象。加上後訓練對齊過程，使其在事實性和符合所需行為的測量方面表現出更好的性能。此項目的核心組件是開發可在各種尺度上可預測的基礎設施和優化方法，這使我們能夠根據使用的訓練模型（計算資源不超過GPT-4的1000分之1）來精確預測GPT-4的某些方面的表現。\n",
            "1引言\n",
            "本技術報告介紹GPT-4，這是一個大型的多模態模型，能夠處理圖像和文本輸入並產生文本輸出。\n",
            "原文: Such models are an important area of study as they have the\n",
            "potential to be used in a wide range of applications, such as dialogue systems, text summarization,\n",
            "and machine translation.As such, they have been the subject of substantial interest and progress in\n",
            "recent years [1–34].One of the main goals of developing such models is to improve their ability to understand and generate\n",
            "natural language text, particularly in more complex and nuanced scenarios.To test its capabilities\n",
            "in such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans.In\n",
            "these evaluations it performs quite well and often outscores the vast majority of human test takers.For example, on a simulated bar exam, GPT-4 achieves a score that falls in the top 10% of test takers.This contrasts with GPT-3.5, which scores in the bottom 10%.On a suite of traditional NLP benchmarks, GPT-4 outperforms both previous large language models\n",
            "and most state-of-the-art systems (which often have benchmark-speciﬁc training or hand-engineering).\n",
            "翻譯結果: 這樣的模型是一個重要的研究領域，因為它們有潛力應用在各種應用場景，例如對話系統、文字摘要和機器翻譯。因此，它們近年來成為了受到廣泛關注和進展的研究主題[1-34]。開發這樣的模型的主要目標之一是提高其理解和生成自然語言文本的能力，特別是在更複雜和微妙的情況下。為了測試其在這樣的情況下的能力，GPT-4在一系列最初設計給人類的考試中進行了評估。在這些評估中，它表現得相當好，並且經常超過了絕大多數的人類考生。例如，在模擬的酒吧考試中，GPT-4獲得了排名前10％的分數。這與GPT-3.5形成對比，後者獲得了排名最後10％的分數。在一系列傳統的自然語言處理基準測試中，GPT-4優於以前的大型語言模型和大多數最先進的系統（這些系統通常有基準測試特定的訓練或手工設計）。\n",
            "原文: On the MMLU benchmark [ 35,36], an English-language suite of multiple-choice questions covering\n",
            "57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but\n",
            "also demonstrates strong performance in other languages.On translated variants of MMLU, GPT-4\n",
            "surpasses the English-language state-of-the-art in 24 of 26 languages considered.We discuss these\n",
            "model capability results, as well as model safety improvements and results, in more detail in later\n",
            "sections.This report also discusses a key challenge of the project, developing deep learning infrastructure and\n",
            "optimization methods that behave predictably across a wide range of scales.This allowed us to make\n",
            "predictions about the expected performance of GPT-4 (based on small runs trained in similar ways)\n",
            "that were tested against the ﬁnal run to increase conﬁdence in our training.Despite its capabilities, GPT-4 has similar limitations to earlier GPT models [ 1,37,38]: it is not fully\n",
            "reliable (e.g.can suffer from “hallucinations”), has a limited context window, and does not learn\n",
            "\u0003Please cite this work as “OpenAI (2023)\".\n",
            "翻譯結果: 在 MMLU 基准测试[35,36]中，這是一個包含57個主題的英文多選題套件，GPT-4 不僅在英文方面表現比現有的模型更好，而且在其他語言方面也表現出色。在MMLU的翻譯變體中，GPT-4在26種語言中的24種語言中超越了英語最先進的水平。我們將在後面的章節中更詳細地討論這些模型能力結果以及模型安全改進和結果。本報告還討論了該項目的重要挑戰之一，即開發可以在廣泛的尺度上可預測地行為的深度學習基礎設施和優化方法。這使我們能夠對GPT-4的預期表現進行預測（基於以類似方式訓練的小型運行），並將其與最終運行進行測試以增加我們的訓練信心。儘管具有這些能力，GPT-4與早期的GPT模型[1,37,38]存在類似的限制：它不是完全可靠的（例如可能會出現“幻覺”），具有有限的上下文窗口，並且無法學習。請引用本文為“OpenAI（2023）”。\n",
            "原文: Full authorship contribution statements appear at the end of the\n",
            "document.arXiv:2303.08774v2  [cs.CL]  16 Mar 2023\n",
            "翻譯結果: 完整的作者貢獻聲明會出現在文件末尾。arXiv:2303.08774v2 [cs.CL]於2023年3月16日。\n",
            "原文: from experience.Care should be taken when using the outputs of GPT-4, particularly in contexts\n",
            "where reliability is important.GPT-4’s capabilities and limitations create signiﬁcant and novel safety challenges, and we believe\n",
            "careful study of these challenges is an important area of research given the potential societal impact.This report includes an extensive system card (after the Appendix) describing some of the risks we\n",
            "foresee around bias, disinformation, over-reliance, privacy, cybersecurity, proliferation, and more.It also describes interventions we made to mitigate potential harms from the deployment of GPT-4,\n",
            "including adversarial testing with domain experts, and a model-assisted safety pipeline.2 Scope and Limitations of this Technical Report\n",
            "This report focuses on the capabilities, limitations, and safety properties of GPT-4.GPT-4 is a\n",
            "Transformer-style model [ 39] pre-trained to predict the next token in a document, using both publicly\n",
            "available data (such as internet data) and data licensed from third-party providers.\n",
            "翻譯結果: 從經驗來看，使用GPT-4的輸出時應當謹慎，特別是在可靠性很重要的情況下。GPT-4的能力和限制帶來了重大和新穎的安全挑戰，我們相信對這些挑戰進行仔細研究是一個重要的研究領域，因為其可能對社會產生影響。本報告包括一份廣泛的系統卡（附於附錄後），描述了我們對偏見、虛假信息、過度依賴、隱私、網絡安全、擴散等風險的預見。同時，它還描述了我們為減輕GPT-4部署可能造成的損害所做的干預措施，包括與領域專家進行對抗測試和模型輔助的安全流程。本技術報告的範圍和限制\n",
            "本報告重點關注GPT-4的能力、限制和安全屬性。GPT-4是一種基於Transformer風格的模型[39]，預先訓練以預測文檔中的下一個標記，使用公開可用的數據（如互聯網數據）和從第三方供應商獲得的數據。\n",
            "原文: The model was\n",
            "then ﬁne-tuned using Reinforcement Learning from Human Feedback (RLHF) [ 40].Given both\n",
            "the competitive landscape and the safety implications of large-scale models like GPT-4, this report\n",
            "contains no further details about the architecture (including model size), hardware, training compute,\n",
            "dataset construction, training method, or similar.We are committed to independent auditing of our technologies, and shared some initial steps and\n",
            "ideas in this area in the system card accompanying this release.2We plan to make further technical\n",
            "details available to additional third parties who can advise us on how to weigh the competitive and\n",
            "safety considerations above against the scientiﬁc value of further transparency.3 Predictable Scaling\n",
            "A large focus of the GPT-4 project was building a deep learning stack that scales predictably.The\n",
            "primary reason is that for very large training runs like GPT-4, it is not feasible to do extensive\n",
            "model-speciﬁc tuning.To address this, we developed infrastructure and optimization methods that\n",
            "have very predictable behavior across multiple scales.\n",
            "翻譯結果: 本模型隨後使用Reinforcement Learning from Human Feedback (RLHF) [40]進行微調。考慮到GPT-4等大型模型的競爭環境和安全影響，本報告未進一步公開有關架構（包括模型大小）、硬件、訓練計算、數據集構建、培訓方法等方面的細節。我們致力於獨立審核我們的技術，在本次發布的系統卡片中提供了一些初步的步驟和想法。我們計劃向其他第三方提供進一步的技術細節，以便他們能夠建議我們如何在進一步透明度的科學價值與競爭和安全考慮之間取得平衡。可預測擴展GPT-4項目的主要焦點是構建一個能夠可預測地縮放的深度學習堆棧。主要原因是對於像GPT-4這樣的非常大的培訓過程，不可行進行廣泛的模型特定調整。為了解決這個問題，我們開發了基礎設施和優化方法，這些方法在多個尺度上具有非常可預測的行為。\n",
            "原文: These improvements allowed us to reliably\n",
            "predict some aspects of the performance of GPT-4 from smaller models trained using 1;000\u0002–\n",
            "10;000\u0002less compute.3.1 Loss Prediction\n",
            "The ﬁnal loss of properly-trained large language models is thought to be well approximated by power\n",
            "laws in the amount of compute used to train the model [41, 42, 2, 14, 15].To verify the scalability of our optimization infrastructure, we predicted GPT-4’s ﬁnal loss on our\n",
            "internal codebase (not part of the training set) by ﬁtting a scaling law with an irreducible loss term\n",
            "(as in Henighan et al.[15]):L(C) =aCb+c;from models trained using the same methodology\n",
            "but using at most 10,000x less compute than GPT-4.This prediction was made shortly after the run\n",
            "started, without use of any partial results.The ﬁtted scaling law predicted GPT-4’s ﬁnal loss with\n",
            "high accuracy (Figure 1).3.2 Scaling of Capabilities on HumanEval\n",
            "Having a sense of the capabilities of a model before training can improve decisions around alignment,\n",
            "safety, and deployment.\n",
            "翻譯結果: 這些改進使我們能夠可靠地預測使用比GPT-4少1,000-10,000倍運算資源進行訓練的較小模型的某些性能方面。3.1損失預測\n",
            "正確訓練大型語言模型的最終損失被認為可以用用於訓練模型的運算資源量的冪律來近似表示[41、42、2、14、15]。為了驗證我們的優化基礎設施的可擴展性，我們使用相同的方法進行了訓練，但使用的運算資源最多比GPT-4少10,000倍的模型，通過擬合帶有不可約損失項的縮放定律（如 Henighan 等人[15] 所述），在我們的內部代碼庫（不是訓練集的一部分）上預測了GPT-4的最終損失。這個預測是在運行開始後不久進行的，沒有使用任何部分結果。擬合的縮放定律高精度地預測了GPT-4的最終損失（圖1）。3.2人工評估能力的擴展\n",
            "在訓練之前了解模型的能力可以改進相關的決策，如對齊、安全和部署等。\n",
            "原文: In addition to predicting ﬁnal loss, we developed methodology to predict\n",
            "more interpretable metrics of capability.One such metric is pass rate on the HumanEval dataset [ 43],\n",
            "which measures the ability to synthesize Python functions of varying complexity.We successfully\n",
            "predicted the pass rate on a subset of the HumanEval dataset by extrapolating from models trained\n",
            "with at most 1;000\u0002less compute (Figure 2).For an individual problem in HumanEval, performance may occasionally worsen with scale.Despite\n",
            "these challenges, we ﬁnd an approximate power law relationship \u0000EP[log(pass _rate(C))] = \u000b\u0003C\u0000k\n",
            "2In addition to the accompanying system card, OpenAI will soon publish additional thoughts on the social\n",
            "and economic implications of AI systems, including the need for effective regulation.2\n",
            "翻譯結果: 除了預測最終損失外，我們還開發了預測更易解釋的能力指標的方法之一是HumanEval數據集上的通過率[43]，該數據集測量了合成不同複雜度Python函數的能力。我們從使用最多1000倍計算量所訓練的模型中推斷出，在HumanEval數據集的子集上成功預測了通過率（圖2）。對於HumanEval中的單個問題，性能偶爾會隨著規模變化而惡化。儘管存在這些挑戰，我們發現大約存在一個指數關係EP [log（pass_rate（C））] = \u000bvCk。除了伴隨的系統卡片之外，OpenAI很快還將發表有關AI系統社會和經濟影響的其他見解，包括需要有效的監管。\n",
            "原文: Observed\n",
            "Prediction\n",
            "gpt-4\n",
            "100p 10n 1µ 100µ 0.01 1\n",
            "Compute1.02.03.04.05.06.0Bits per wordOpenAI codebase next word predictionFigure 1.Performance of GPT-4 and smaller models.The metric is ﬁnal loss on a dataset derived\n",
            "from our internal codebase.This is a convenient, large dataset of code tokens which is not contained in\n",
            "the training set.We chose to look at loss because it tends to be less noisy than other measures across\n",
            "different amounts of training compute.A power law ﬁt to the smaller models (excluding GPT-4) is\n",
            "shown as the dotted line; this ﬁt accurately predicts GPT-4’s ﬁnal loss.The x-axis is training compute\n",
            "normalized so that GPT-4 is 1.Observed\n",
            "Prediction\n",
            "gpt-4\n",
            "1µ 10µ 100µ 0.001 0.01 0.1 1\n",
            "Compute012345– Mean Log Pass RateCapability prediction on 23 coding problems\n",
            "Figure 2.Performance of GPT-4 and smaller models.The metric is mean log pass rate on a subset of\n",
            "the HumanEval dataset.A power law ﬁt to the smaller models (excluding GPT-4) is shown as the dotted\n",
            "line; this ﬁt accurately predicts GPT-4’s performance.\n",
            "翻譯結果: 觀察值\n",
            "預測值\n",
            "gpt-4\n",
            "100p 10n 1µ 100µ 0.01 1\n",
            "計算1.02.03.04.05.06.0\n",
            "每詞比特數\n",
            "OpenAI程式庫下一個詞語的預測\n",
            "圖1. GPT-4和較小模型的表現。\n",
            "指標是我們內部程式庫衍生數據集上的最終損失，這是一個方便的大型的包含在訓練集中的程式碼標記資料集，我們選擇考慮損失，因為它在不同的訓練計算量之下 tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend  tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend tend AD\n",
            "有較少的噪聲。排除GPT-4的較小模型的功率定律擬合顯示為虛線；這個擬合準確地預測了GPT-4的最終損失。 x-軸進行訓練計算標準化，以便GPT-4的值為1。\n",
            "觀察值\n",
            "預測值\n",
            "gpt-4\n",
            "1µ 10µ 100µ 0.001 0.01 0.1 1\n",
            "計算012345– 在23個編碼問題上的能力預測\n",
            "圖2. GPT-4和較小模型的表現。\n",
            "指標是HumanEval數據集的均值對數通過率的子集，排除GPT-4的較小模型的功率定律擬合顯示為虛線；這個擬合準確地預測了GPT-4的表現。\n",
            "原文: The x-axis is training compute normalized so that\n",
            "GPT-4 is 1.3\n",
            "翻譯結果: x軸是訓練計算的標準化值，以GPT-4為1.3。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "原文: GPT-4 Technical Report\n",
        "OpenAI\u0003\n",
        "Abstract\n",
        "We report the development of GPT-4, a large-scale, multimodal model which can\n",
        "accept image and text inputs and produce text outputs.While less capable than\n",
        "humans in many real-world scenarios, GPT-4 exhibits human-level performance\n",
        "on various professional and academic benchmarks, including passing a simulated\n",
        "bar exam with a score around the top 10% of test takers.GPT-4 is a Transformer-\n",
        "based model pre-trained to predict the next token in a document.The post-training\n",
        "alignment process results in improved performance on measures of factuality and\n",
        "adherence to desired behavior.A core component of this project was developing\n",
        "infrastructure and optimization methods that behave predictably across a wide\n",
        "range of scales.This allowed us to accurately predict some aspects of GPT-4’s\n",
        "performance based on models trained with no more than 1/1,000th the compute of\n",
        "GPT-4.1 Introduction\n",
        "This technical report presents GPT-4, a large multimodal model capable of processing image and\n",
        "text inputs and producing text outputs.\n",
        "\n",
        "翻譯結果: GPT-4技術報告\n",
        "OpenAI\n",
        "摘要\n",
        "本報告介紹GPT-4的開發，它是一個大型的多模態模型，能夠接受圖像和文本輸入並產生文本輸出。\n",
        "儘管在許多現實場景中不如人類能力強，但GPT-4在各種專業和學術測試中表現出人類水平的性能，包括以接近前10％的考生水平通過模擬律師考試。\n",
        "GPT-4是一個基於Transformer的模型，預先訓練以預測文檔中的下一個對象。加上後訓練對齊過程，使其在事實性和符合所需行為的測量方面表現出更好的性能。\n",
        "此項目的核心組件是開發可在各種尺度上可預測的基礎設施和優化方法，這使我們能夠根據使用的訓練模型（計算資源不超過GPT-4的1000分之1）來精確預測GPT-4的某些方面的表現。\n",
        "1引言\n",
        "本技術報告介紹GPT-4，這是一個大型的多模態模型，能夠處理圖像和文本輸入並產生文本輸出。"
      ],
      "metadata": {
        "id": "VK4zli0pJpTb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}