# 百萬級吞吐量的交易所餘額系統 — 系統實作

## 百萬級吞吐量的交易所餘額系統 — 系統實作

[

![vic](https://miro.medium.com/v2/resize:fill:56:56/1*oKDGV_y2Sq7nAUHmdtgNhg.png)



](https://vicxu.medium.com/?source=post_page---byline--68203fe708a5---------------------------------------)

11 min read

1 day ago

> talk is cheap, show me the code

上一篇分享了[『百萬級吞吐量的交易所餘額系統 — 系統設計』](https://vicxu.medium.com/%E7%99%BE%E8%90%AC%E7%B4%9A-tps-%E7%9A%84%E4%BA%A4%E6%98%93%E6%89%80%E9%A4%98%E9%A1%8D%E7%B3%BB%E7%B5%B1-3297140272b2)，介紹了高吞吐跟高可用的系統設計。

然而系統設計能給予輪廓與方向，但只有實作才能發掘細節！

秉持著 「talk is cheap, show me the code」的精神，我開發了 AXS 專案，接下來分享 AXS 的實作細節吧！

## 目錄

-   **如何讓單線程 Consumer 批次處理訊息？**
-   **如何高效地批次寫入餘額變動到 DB？**
-   **如何處理新幣種的新增？**
-   **如何實作 Consumer side 的冪等以及 Leader Election 避免腦裂？**
-   **如何壓測 Consumer Side 的吞吐量？**

## **如何讓單線程 Consumer 批次處理訊息？**

交易員一秒會多次下單，若能批次處理能提升不少效能，例如 in memory 操作使用 BigCache 套件要 marshal & unmarshal 物件，批次處理相同用戶多個請求就只要 marshal & unmarshal 一次。

Kafka consumer 可設定最少拉取多少 bytes 資料，但 poll API 是回傳 message，因此要用 array 暫存讀出的 message，直到數量到 batch size (e.g 200) 後一次處理。

為避免訊息累積太慢，造成延遲，需要額外 ticker thread 定期處理 (e.g 100ms) array 中資料，由於 ticket thread 跟 consumer 會 concurrent read & write array，所以 array 要上鎖。

> 但有不上鎖跟不需要額外 thread 的實作方式嗎？

Kafka consumer poll API 有 timeout 機制，可設定兩個 timeout duration :

-   longPoll => 1sec
-   batchLatency => 100ms

先用 longPoll 等第一筆訊息，收到後，改用 batchLatency，當 poll timeout 後，array 有值就處理，如果第二筆訊息在 100ms 內到，就能被 aggregate ，若太慢，第一筆訊息最多等 100ms 後被處理。

處理完 message 後把 timeout 改回 longPoll，避免太頻繁呼叫 poll API，這樣可單 thread 實現完善的 batch 機制，能累積瞬間訊息一次處理，也可控制延遲時間，處理沒累積到量的訊息。

```
longPoll = 1s  
batchLatency = 100ms  
batchSize = 200  
pollTimeout = longPoll  
msgsBuffer = \[\]  
for {  
   msg, err = consumer.Poll(pollTimeout)  
   if err != nil && err == timeOutErr {  
    if len(msgsBuffer) > 0 {  
     process(msgsBuffer)  
     msgsBuffer = msgsBuffer\[:0\]  
    }  
    pollTimeout = longPoll  
   }  
   if err == nil {  
   msgsBuffer = append(msgsBuffer, msg)  
   if len(msgsBuffer) >= batchSize {  
     process(msgsBuffer)  
     msgsBuffer = msgsBuffer\[:0\]  
   }  
   pollTimeout = batchLatency  
 }  
}
```

## 如何高效地批次寫入餘額變動到 DB？

常見批次 UPDATE 的寫法有 **SWITCH CASE** 跟 **UPDATE JOIN：**

**SWITCH CASE**

```
UPDATE accounts  
SET   
    balance \= CASE id  
        WHEN 1 THEN 1000  
        WHEN 2 THEN 1500  
        WHEN 3 THEN 2000  
        ELSE balance  
    END,

    updated\_msec \= CASE id  
        WHEN 1 THEN 1710000000000  
        WHEN 2 THEN 1710000001000  
        WHEN 3 THEN 1710000002000  
        ELSE updated\_msec  
    END  
WHERE id IN (1,2,3);


```

**UPDATE JOIN**

```
UPDATE accounts AS a  
JOIN (  
    SELECT \* FROM (  
        SELECT 1 AS id, 1000 AS balance, 1710000000000 AS updated\_msec  
        UNION ALL  
        SELECT 2, 1500, 1710000001000  
        UNION ALL  
        SELECT 3, 2000, 1710000002000  
    ) AS x  
) AS u ON a.id = u.id  
SET   
    a.balance = u.balance,  
    a.updated\_msec = u.updated\_msec;
```

note: 上述為 MySQL 語法，PG 略有不同

實測下，當資料量超過 100 筆時，UPDATE JOIN 效能顯著較好，原因有兩個：

-   SWITCH CASE 字串較長，網路傳輸更久
-   SWITCH CASE 語法較複雜，parser 執行較久，分析出的 AST 較複雜也會加長 optimizer 分析時間

由此可見雖批次數量相同，過於複雜語法在 praser & optimizer 階段仍會顯著影響效能。

> 那有比 UPDATE JOIN 更簡單的語法？

答案是 JOIN 一張 temp table :

```
CREATE TEMPORARY TABLE tmp\_updates (  
    id BIGINT PRIMARY KEY,  
    new\_value VARCHAR(255)  
);

INSERT INTO tmp\_updates (id, new\_value) VALUES  
(1, 'A'),  
(2, 'B'),  
(3, 'C');

UPDATE your\_table t  
JOIN tmp\_updates u ON t.id \= u.id  
SET t.col \= u.new\_value;


```

但會多 **INSERT** 的時間，雖然 **UPDATE** 變得很短很簡單，但實務上會更久，因此要優化 **INSERT** 執行時間，已 PG 為例，可用兩個技巧：

-   **UNLOGGED TABLE** : temp table 用 UNLOGGED Table，寫入沒有 WAL，只有 async flush，寫入是 in memory 沒有 I/O，由於是臨時資料，UPDATE 後就可 TRUNCATE ，因此不用 Durability。
-   **COPY** : INSERT 大量 rows 語法變長，parser 也會久，而 COPY 語法可把資料用 bytes 形式傳輸，且不經過 parser & optimizer ，可以直接 execute 效能更快。

Press enter or click to view image in full size

![](https://miro.medium.com/v2/resize:fit:1225/1*3xmjOViqD9N8p-gyDXM19w.png)

實測 10k 筆 & 2k 筆 & 300 筆資料，Copy & JOIN temp table 效能會是JOIN 的 2 ~ 3 倍。

[

![Become a member](https://miro.medium.com/v2/da:true/resize:fit:0/60026f4340686a391639ac58864da18070aa773cea45de6e55fa47fd56bfdb74)

![Become a member](https://miro.medium.com/v2/da:true/resize:fit:0/c061bd6cb52734164bf0c66f2543a6bc2acbe24ae3985dc15c898b3ddb2e1940)

](https://medium.com/plans?source=upgrade_membership---post_li_non_moc_upsell--68203fe708a5---------------------------------------)

最後避免有舊資料，用 temp table 前要先 TRUNCATE ，但 TRUNCATE 會 lock table，因此要為每個 consumer 建立自己的 temp table (e.g temp\_table\_partition\_1 )，在 consumer 內 batch update 是單線程因此 lock table 沒關係。

## **如何處理新幣種的新增？**

常見餘額 schema 是一個幣種一個 row，上新幣種時，所有用戶新增一筆餘額為 0 的 row 不現實，要會採用 lazy insert，加值第一筆錢時 insert，因此在 batch update sql 不只 update 還要判斷 insert 情境。

簡單解法是 INSERT ON DUPLICATE KEY UPDATE ，但有兩個缺點：

-   會先嘗試 INSERT 並檢查 unique key 碰撞，多一個 O(logN) 的 index lookup 跟多 index page lock
-   如果是 MySQL 還會有 gap lock，併發時容易造成 Dead Lock

更好做法是用 CTE 功能，先 join temp table 去 update，在找出 update not found 資料 insert：

```
WITH try\_update AS (  
UPDATE account\_balances ab  
 SET available = ab.available + t.available\_delta  
 FROM temp\_balance\_write\_records t  
 WHERE ab.account\_id = t.account\_id  
 AND ab.currency\_code = t.currency\_code  
 AND ab.available + t.available\_delta >= 0  
RETURNING t.account\_id,  t.currency\_code  
),  
missing AS (  
SELECT t.\*  
 FROM temp\_balance\_write\_records t  
 LEFT JOIN try\_update u  
 ON u.account\_id = t.account\_id  
 AND u.shard\_id = t.shard\_id  
 AND u.currency\_code = t.currency\_code  
 WHERE u.account\_id IS NULL  
),

try\_insert AS (  
 INSERT INTO account\_balances (  
 account\_id, shard\_id, currency\_code,  
 user\_id, available, updated\_msec  
 )  
 SELECT  
 m.account\_id, m.shard\_id, m.currency\_code,  
 m.user\_id, m.available\_delta, m.updated\_msec  
 FROM missing m WHERE m.available\_delta >= 0  
 RETURNING account\_id  
),  
validate AS (  
 SELECT  
  (SELECT count(\*) FROM try\_update) AS updated\_rows,  
  (SELECT count(\*) FROM try\_insert) AS inserted\_rows  
 )  
)  
SELECT \*  
FROM validate;


```

上述為 PG 範例，而 MySQL 也有 CTE，但 UPDATE 到 not found 資料會有 gap lock ， INSERT 可能會被 lock 造成 dead lock。

MySQL 更好的做法是先讀取餘額，SELECT 時標記不存在幣種，更新時精準 INSERT 不存在資料，由於單一用戶是單線程，可確保 SELECT 跟 INSERT 不會 race condition。

## 如何實作 Consumer side 的冪等以及 Leader Election 避免腦裂？

Kafka Producer 有冪等性配置，能保證 exactly once，但 Producer exactly once 不代表 Consumer exactly once，因此 Consumer Side 也要冪等處理。

常見方式為 Commit Offset 並等 broker ack，但會影響 consumer 速率，更好做法是讓 DB 的資料一致性與 Offset 綁定，因此要在 batch update balance 的 transaction 新增兩個 SQL 操作：

-   批次 update change log 的狀態，同時 WHERE status = INIT 確保冪等
-   update offset 進 db

這樣 DB 資料一致性就能包括事件的冪等跟 consumer 的 exactly once。

為實現高可用 & zero downtime 更新，需實現 leader election：

-   啟動時 acquire leader lock
-   獲取後要有個 ticker thread 定期 extend leader lock TTL

該該機制最大風險就是腦裂：

1.  leader A 的 ticker thread 因為 GC STW 延遲
2.  follower B 成功搶到 leader lock 開始 consume，此時 offset 可能是 leader A db flush 前的值
3.  leader A 的 db flush thread 沒意識到 leader 被搶還是完成 batch update transaction
4.  最終 follower B 成為 leader 後會重複處理請求

解決腦裂問題，無法用 redis 實現 leader lock，要用 db 並把 leader lock 的檢查放進 batch update transaction 裡面，更新時 leader lock 被搶走就 rollback。

最終入庫資料一定能確保：

-   冪等性，不會重複處理
-   consumer offset 不會遺漏不會重複消費，會從正確的 offset replay 餘額請求
-   不會腦裂，不會同時有兩個 leader 將相同餘額請求更新到 db

## 如何壓測 Consumer Side 的吞吐量？

AXS 使用 xk6 套件 — 是 k6 的 extension 工具，支援 kafka consumer 功能。

由於 client 端 consumer 會因為不同配置影響 consume rate，為精準測試吞吐量，AXS 做法是在 consumer application 計算每次處理時間跟批次訊息量，將結果 produce 到壓測 topic，由 xk6 script 接收並統計。

該方法可壓測出 application 層不同邏輯時間，例如 unmarshal kafka payload，記憶體操作等，也能計算 end-to-end throughput，不過 e2e throughput 不代表是 consumer throughput，因為 e2e 會受限於 k6 client 送請求的速度。

詳細壓測結果參考 [Stress Test Doc](https://github.com/vx416/axs/blob/main/stresstest/README.md)。
