{"key": "comp/sugarcrepe_replace_obj", "dataset": "SugarCrepe Replace-obj", "metrics": {"image_acc": 1.0, "text_acc": 0.9594430923461914, "acc": 0.9594430923461914, "main_metric": 0.9594430923461914}}
{"key": "comp/sugarcrepe_replace_att", "dataset": "SugarCrepe Replace-att", "metrics": {"image_acc": 1.0, "text_acc": 0.8654822111129761, "acc": 0.8654822111129761, "main_metric": 0.8654822111129761}}
{"key": "comp/sugarcrepe_replace_rel", "dataset": "SugarCrepe Replace-rel", "metrics": {"image_acc": 1.0, "text_acc": 0.7112375497817993, "acc": 0.7112375497817993, "main_metric": 0.7112375497817993}}
{"key": "comp/sugarcrepe_swap_obj", "dataset": "SugarCrepe Swap-obj", "metrics": {"image_acc": 1.0, "text_acc": 0.6285714507102966, "acc": 0.6285714507102966, "main_metric": 0.6285714507102966}}
{"key": "comp/sugarcrepe_swap_att", "dataset": "SugarCrepe Swap-att", "metrics": {"image_acc": 1.0, "text_acc": 0.7012012004852295, "acc": 0.7012012004852295, "main_metric": 0.7012012004852295}}
{"key": "comp/sugarcrepe_add_obj", "dataset": "SugarCrepe Add-obj", "metrics": {"image_acc": 1.0, "text_acc": 0.9272550940513611, "acc": 0.9272550940513611, "main_metric": 0.9272550940513611}}
{"key": "comp/sugarcrepe_add_att", "dataset": "SugarCrepe Add-att", "metrics": {"image_acc": 1.0, "text_acc": 0.8424855470657349, "acc": 0.8424855470657349, "main_metric": 0.8424855470657349}}
{"key": "longclip/sharegpt4v-1k", "dataset": "sharegpt4v-1k", "metrics": {"image_retrieval_recall@1": 0.9660000205039978, "text_retrieval_recall@1": 0.9760000109672546, "image_retrieval_recall@5": 0.9959999918937683, "text_retrieval_recall@5": 0.9980000257492065, "image_retrieval_recall@10": 0.9990000128746033, "text_retrieval_recall@10": 0.9990000128746033, "mean_recall@1": 0.9710000157356262, "main_metric": 0.9710000157356262}}
{"key": "longclip/sharegpt4v-llava15k", "dataset": "sharegpt4v-llava15k", "metrics": {"image_retrieval_recall@1": 0.8573390245437622, "text_retrieval_recall@1": 0.9029094576835632, "image_retrieval_recall@5": 0.9644328355789185, "text_retrieval_recall@5": 0.981235682964325, "image_retrieval_recall@10": 0.9807780385017395, "text_retrieval_recall@10": 0.9913697242736816, "mean_recall@1": 0.8801242411136627, "main_metric": 0.8801242411136627}}
{"key": "longclip/urban1k", "dataset": "urban1k", "metrics": {"image_retrieval_recall@1": 0.7820000052452087, "text_retrieval_recall@1": 0.8230000138282776, "image_retrieval_recall@5": 0.9259999990463257, "text_retrieval_recall@5": 0.9390000104904175, "image_retrieval_recall@10": 0.9559999704360962, "text_retrieval_recall@10": 0.9739999771118164, "mean_recall@1": 0.8025000095367432, "main_metric": 0.8025000095367432}}
{"key": "vtab/caltech101", "dataset": "Caltech-101", "metrics": {"acc1": 0.8522596548890715, "acc5": 0.9506984387838948, "mean_per_class_recall": 0.9521106191719062, "main_metric": 0.9521106191719062}}
{"key": "cifar10", "dataset": "CIFAR-10", "metrics": {"acc1": 0.9865, "acc5": 0.9999, "mean_per_class_recall": 0.9865, "main_metric": 0.9865}}
{"key": "vtab/cifar100", "dataset": "CIFAR-100", "metrics": {"acc1": 0.8951, "acc5": 0.9874, "mean_per_class_recall": 0.8950999999999999, "main_metric": 0.8951}}
{"key": "vtab/clevr_count_all", "dataset": "CLEVR Counts", "metrics": {"acc1": 0.36673333333333336, "acc5": 0.9024, "mean_per_class_recall": 0.3692912219051608, "main_metric": 0.36673333333333336}}
{"key": "vtab/clevr_closest_object_distance", "dataset": "CLEVR Distance", "metrics": {"acc1": 0.16286666666666666, "acc5": 0.9172, "mean_per_class_recall": 0.1491936741773228, "main_metric": 0.16286666666666666}}
{"key": "country211", "dataset": "Country211", "metrics": {"acc1": 0.2864454976303318, "acc5": 0.5395260663507109, "mean_per_class_recall": 0.2864454976303317, "main_metric": 0.2864454976303318}}
{"key": "vtab/dtd", "dataset": "Describable Textures", "metrics": {"acc1": 0.6808510638297872, "acc5": 0.9420212765957446, "mean_per_class_recall": 0.6808510638297871, "main_metric": 0.6808510638297872}}
{"key": "vtab/eurosat", "dataset": "EuroSAT", "metrics": {"acc1": 0.6857407407407408, "acc5": 0.9848148148148148, "mean_per_class_recall": 0.6941042633105754, "main_metric": 0.6857407407407408}}
{"key": "fgvc_aircraft", "dataset": "FGVC Aircraft", "metrics": {"acc1": 0.44704470447044703, "acc5": 0.8466846684668466, "mean_per_class_recall": 0.4462566844919786, "main_metric": 0.4462566844919786}}
{"key": "food101", "dataset": "Food-101", "metrics": {"acc1": 0.9508118811881188, "acc5": 0.9950891089108911, "mean_per_class_recall": 0.9508118811881189, "main_metric": 0.9508118811881188}}
{"key": "gtsrb", "dataset": "GTSRB", "metrics": {"acc1": 0.6338875692794933, "acc5": 0.8186856690419636, "mean_per_class_recall": 0.6091482720271901, "main_metric": 0.6338875692794933}}
{"key": "imagenet1k", "dataset": "ImageNet 1k", "metrics": {"acc1": 0.81904, "acc5": 0.96884, "mean_per_class_recall": 0.81898, "main_metric": 0.81904}}
{"key": "imagenet_sketch", "dataset": "ImageNet Sketch", "metrics": {"acc1": 0.6982452003379905, "acc5": 0.9022775059443101, "mean_per_class_recall": 0.6983764705882353, "main_metric": 0.6982452003379905}}
{"key": "imagenetv2", "dataset": "ImageNet v2", "metrics": {"acc1": 0.7472, "acc5": 0.9372, "mean_per_class_recall": 0.7477, "main_metric": 0.7472}}
{"key": "imagenet-a", "dataset": "ImageNet-A", "metrics": {"acc1": 0.6889333333333333, "acc5": 0.8982666666666667, "mean_per_class_recall": 0.6564198269900607, "main_metric": 0.6889333333333333}}
{"key": "imagenet-o", "dataset": "ImageNet-O", "metrics": {"acc1": 0.407, "acc5": 0.7475, "mean_per_class_recall": 0.4258093755788416, "main_metric": 0.407}}
{"key": "imagenet-r", "dataset": "ImageNet-R", "metrics": {"acc1": 0.9170333333333334, "acc5": 0.9811333333333333, "mean_per_class_recall": 0.9062396907519651, "main_metric": 0.9170333333333334}}
{"key": "vtab/kitti_closest_vehicle_distance", "dataset": "KITTI Vehicle Distance", "metrics": {"acc1": 0.21659634317862167, "acc5": null, "mean_per_class_recall": 0.2983654180439798, "main_metric": 0.21659634317862167}}
{"key": "mnist", "dataset": "MNIST", "metrics": {"acc1": 0.896, "acc5": 0.9766, "mean_per_class_recall": 0.8949876810074902, "main_metric": 0.896}}
{"key": "objectnet", "dataset": "ObjectNet", "metrics": {"acc1": 0.7538494669968774, "acc5": 0.90658985678906, "mean_per_class_recall": 0.7440426373604258, "main_metric": 0.7538494669968774}}
{"key": "vtab/flowers", "dataset": "Oxford Flowers-102", "metrics": {"acc1": 0.8625792811839323, "acc5": 0.9552772808586762, "mean_per_class_recall": 0.8484530941378748, "main_metric": 0.8484530941378748}}
{"key": "vtab/pets", "dataset": "Oxford-IIIT Pet", "metrics": {"acc1": 0.958571817934042, "acc5": 0.9991823385118561, "mean_per_class_recall": 0.9582848486940757, "main_metric": 0.9582848486940757}}
{"key": "voc2007", "dataset": "Pascal VOC 2007", "metrics": {"acc1": 0.8221153846153846, "acc5": 0.9795005341880342, "mean_per_class_recall": 0.8869328355449282, "main_metric": 0.8221153846153846}}
{"key": "vtab/pcam", "dataset": "PatchCamelyon", "metrics": {"acc1": 0.631988525390625, "acc5": null, "mean_per_class_recall": 0.6319753805801036, "main_metric": 0.631988525390625}}
{"key": "renderedsst2", "dataset": "Rendered SST2", "metrics": {"acc1": 0.557386051619989, "acc5": null, "mean_per_class_recall": 0.5578209136703144, "main_metric": 0.557386051619989}}
{"key": "vtab/resisc45", "dataset": "RESISC45", "metrics": {"acc1": 0.7447619047619047, "acc5": 0.9593650793650793, "mean_per_class_recall": 0.7513004002758776, "main_metric": 0.7447619047619047}}
{"key": "cars", "dataset": "Stanford Cars", "metrics": {"acc1": 0.9510011192637732, "acc5": 0.999253824151225, "mean_per_class_recall": 0.9516825216100003, "main_metric": 0.9510011192637732}}
{"key": "stl10", "dataset": "STL-10", "metrics": {"acc1": 0.987875, "acc5": 1.0, "mean_per_class_recall": 0.9878749999999998, "main_metric": 0.987875}}
{"key": "sun397", "dataset": "SUN397", "metrics": {"acc1": 0.7649097964212811, "acc5": 0.9652886330617725, "mean_per_class_recall": 0.7648851751811485, "main_metric": 0.7649097964212811}}
{"key": "vtab/svhn", "dataset": "SVHN", "metrics": {"acc1": 0.6923786109403811, "acc5": 0.928318992009834, "mean_per_class_recall": 0.6800140649543895, "main_metric": 0.6923786109403811}}
{"key": "retrieval/flickr_1k_test_image_text_retrieval", "dataset": "Flickr", "metrics": {"image_retrieval_recall@1": 0.7770000100135803, "text_retrieval_recall@1": 0.9200000166893005, "image_retrieval_recall@5": 0.9423999786376953, "text_retrieval_recall@5": 0.9890000224113464, "image_retrieval_recall@10": 0.9664000272750854, "text_retrieval_recall@10": 0.9950000047683716, "mean_recall@1": 0.8485000133514404, "main_metric": 0.8485000133514404}}
{"key": "retrieval/mscoco_2014_5k_test_image_text_retrieval", "dataset": "MSCOCO", "metrics": {"image_retrieval_recall@1": 0.5163534879684448, "text_retrieval_recall@1": 0.6904000043869019, "image_retrieval_recall@5": 0.7608156800270081, "text_retrieval_recall@5": 0.8787999749183655, "image_retrieval_recall@10": 0.8411835432052612, "text_retrieval_recall@10": 0.9296000003814697, "mean_recall@1": 0.6033767461776733, "main_metric": 0.6033767461776733}}
{"key": "misc/winogavil", "dataset": "WinoGAViL", "metrics": {"avg_jaccard_score": 0.616227630541411, "jaccard_score_5": 0.6442171717171716, "jaccard_score_6": 0.616942644588433, "jaccard_score_10": 0.5735524256651017, "jaccard_score_12": 0.5700600801068091, "jaccard_score_5-6": 0.6302325581395348, "jaccard_score_10-12": 0.5718021634883461, "main_metric": 0.5718021634883461}}
{"key": "wilds/iwildcam", "dataset": "iWildCam", "metrics": {"acc1": 0.28992077773363556, "acc5": 0.552826528943002, "mean_per_class_recall": 0.22826079278642045, "acc_avg": 0.29111263155937195, "recall-macro_all": 0.22826079278642045, "F1-macro_all": 0.19265028646076687, "main_metric": 0.19265028646076687}}
{"key": "wilds/camelyon17", "dataset": "Camelyon17", "metrics": {"acc1": 0.5989489030498272, "acc5": null, "mean_per_class_recall": 0.5989489030498272, "acc_avg": 0.5989488959312439, "acc_slide:0": NaN, "count_slide:0": 0.0, "acc_slide:1": NaN, "count_slide:1": 0.0, "acc_slide:2": NaN, "count_slide:2": 0.0, "acc_slide:3": NaN, "count_slide:3": 0.0, "acc_slide:4": NaN, "count_slide:4": 0.0, "acc_slide:5": NaN, "count_slide:5": 0.0, "acc_slide:6": NaN, "count_slide:6": 0.0, "acc_slide:7": NaN, "count_slide:7": 0.0, "acc_slide:8": NaN, "count_slide:8": 0.0, "acc_slide:9": NaN, "count_slide:9": 0.0, "acc_slide:10": NaN, "count_slide:10": 0.0, "acc_slide:11": NaN, "count_slide:11": 0.0, "acc_slide:12": NaN, "count_slide:12": 0.0, "acc_slide:13": NaN, "count_slide:13": 0.0, "acc_slide:14": NaN, "count_slide:14": 0.0, "acc_slide:15": NaN, "count_slide:15": 0.0, "acc_slide:16": NaN, "count_slide:16": 0.0, "acc_slide:17": NaN, "count_slide:17": 0.0, "acc_slide:18": NaN, "count_slide:18": 0.0, "acc_slide:19": NaN, "count_slide:19": 0.0, "acc_slide:20": 0.9364829659461975, "count_slide:20": 3810.0, "acc_slide:21": 0.6932864189147949, "count_slide:21": 3694.0, "acc_slide:22": 0.7349514365196228, "count_slide:22": 7210.0, "acc_slide:23": 0.6722768545150757, "count_slide:23": 5288.0, "acc_slide:24": 0.4548984169960022, "count_slide:24": 7727.0, "acc_slide:25": 0.7681125998497009, "count_slide:25": 4334.0, "acc_slide:26": 0.5625163912773132, "count_slide:26": 3815.0, "acc_slide:27": 0.7129060626029968, "count_slide:27": 4556.0, "acc_slide:28": 0.4855386018753052, "count_slide:28": 31878.0, "acc_slide:29": 0.6469941735267639, "count_slide:29": 12742.0, "acc_wg": 0.4548984169960022, "main_metric": 0.5989489030498272}}
{"key": "wilds/fmow", "dataset": "FMoW", "metrics": {"acc1": 0.2806676316265605, "acc5": 0.5873439478921657, "mean_per_class_recall": 0.30051638215989906, "acc_avg": 0.28066763281822205, "acc_year:0": NaN, "count_year:0": 0.0, "acc_year:1": NaN, "count_year:1": 0.0, "acc_year:2": NaN, "count_year:2": 0.0, "acc_year:3": NaN, "count_year:3": 0.0, "acc_year:4": NaN, "count_year:4": 0.0, "acc_year:5": NaN, "count_year:5": 0.0, "acc_year:6": NaN, "count_year:6": 0.0, "acc_year:7": NaN, "count_year:7": 0.0, "acc_year:8": NaN, "count_year:8": 0.0, "acc_year:9": NaN, "count_year:9": 0.0, "acc_year:10": NaN, "count_year:10": 0.0, "acc_year:11": NaN, "count_year:11": 0.0, "acc_year:12": NaN, "count_year:12": 0.0, "acc_year:13": NaN, "count_year:13": 0.0, "acc_year:14": 0.2926248610019684, "count_year:14": 15959.0, "acc_year:15": 0.24963408708572388, "count_year:15": 6149.0, "acc_worst_year": 0.24963408708572388, "acc_region:0": 0.25347572565078735, "count_region:0": 4963.0, "acc_region:1": 0.3118811845779419, "count_region:1": 5858.0, "acc_region:2": 0.19745469093322754, "count_region:2": 2593.0, "acc_region:3": 0.2911266088485718, "count_region:3": 8024.0, "acc_region:4": 0.40390390157699585, "count_region:4": 666.0, "acc_region:5": 0.75, "count_region:5": 4.0, "acc_worst_region": 0.19745469093322754, "main_metric": 0.19745469093322754}}
{"key": "fairness/dollar_street", "dataset": "Dollar Street", "metrics": {"acc1": 0.5820725092777619, "acc5": 0.8315729374821581, "mean_per_class_recall": 0.6088171052069874, "acc_top5_avg": 0.831572949886322, "acc_top5_income_ds:0": 0.6810747385025024, "count_income_ds:0": 856.0, "acc_top5_income_ds:1": 0.8325791954994202, "count_income_ds:1": 884.0, "acc_top5_income_ds:2": 0.8812430500984192, "count_income_ds:2": 901.0, "acc_top5_income_ds:3": 0.9280742406845093, "count_income_ds:3": 862.0, "acc_top5_wg": 0.6810747385025024, "main_metric": 0.6810747385025024}}
{"key": "fairness/geode", "dataset": "GeoDE", "metrics": {"acc1": 0.9413036515054453, "acc5": 0.997357463164638, "mean_per_class_recall": 0.9405272060571143, "acc_avg": 0.9413036704063416, "acc_region:0": 0.9215031266212463, "count_region:0": 2395.0, "acc_region:1": 0.9447761178016663, "count_region:1": 2010.0, "acc_region:2": 0.9463781714439392, "count_region:2": 2126.0, "acc_region:3": 0.9414483904838562, "count_region:3": 1947.0, "acc_region:4": 0.94365394115448, "count_region:4": 1757.0, "acc_region:5": 0.9525077939033508, "count_region:5": 2253.0, "acc_wg": 0.9215031266212463, "main_metric": 0.9215031266212463}}
{"key": "fairness/fairface", "dataset": "FairFace", "metrics": {"acc_race_avg": 0.8698192238807678, "acc_race_race_binary:0": 0.4997601807117462, "count_race_binary:0": 2085.0, "acc_race_race_binary:1": 0.9568158984184265, "count_race_binary:1": 8869.0, "acc_race_wg": 0.4997601807117462, "acc_gender_avg": 0.8945590853691101, "acc_gender_race_binary:0": 0.9194244742393494, "acc_gender_race_binary:1": 0.8887134790420532, "acc_gender_wg": 0.8887134790420532, "acc_age_avg": 0.4223114848136902, "acc_age_race_binary:0": 0.4273381233215332, "acc_age_race_binary:1": 0.4211297631263733, "acc_age_wg": 0.4211297631263733, "acc_gender_x_avg": 0.8945590853691101, "acc_gender_x_race:0_gender:0": 0.9224029779434204, "count_race:0_gender:0": 799.0, "acc_gender_x_race:0_gender:1": 0.7080581188201904, "count_race:0_gender:1": 757.0, "acc_gender_x_race:1_gender:0": 0.9099822044372559, "count_race:1_gender:0": 1122.0, "acc_gender_x_race:1_gender:1": 0.930425763130188, "count_race:1_gender:1": 963.0, "acc_gender_x_race:2_gender:0": 0.9389110207557678, "count_race:2_gender:0": 753.0, "acc_gender_x_race:2_gender:1": 0.8256880640983582, "count_race:2_gender:1": 763.0, "acc_gender_x_race:3_gender:0": 0.9205548763275146, "count_race:3_gender:0": 793.0, "acc_gender_x_race:3_gender:1": 0.8855421543121338, "count_race:3_gender:1": 830.0, "acc_gender_x_race:4_gender:0": 0.9692496657371521, "count_race:4_gender:0": 813.0, "acc_gender_x_race:4_gender:1": 0.9292929172515869, "count_race:4_gender:1": 396.0, "acc_gender_x_race:5_gender:0": 0.8693877458572388, "count_race:5_gender:0": 735.0, "acc_gender_x_race:5_gender:1": 0.9220588207244873, "count_race:5_gender:1": 680.0, "acc_gender_x_race:6_gender:0": 0.8404118418693542, "count_race:6_gender:0": 777.0, "acc_gender_x_race:6_gender:1": 0.946959912776947, "count_race:6_gender:1": 773.0, "acc_gender_x_wg": 0.7080581188201904, "toxicity_crime_avg": 0.07586269825696945, "toxicity_crime_race:0": 0.05077120661735535, "count_race:0": 1556.0, "toxicity_crime_race:1": 0.11990407854318619, "count_race:1": 2085.0, "toxicity_crime_race:2": 0.04155672714114189, "count_race:2": 1516.0, "toxicity_crime_race:3": 0.06839186698198318, "count_race:3": 1623.0, "toxicity_crime_race:4": 0.09429280459880829, "count_race:4": 1209.0, "toxicity_crime_race:5": 0.060070671141147614, "count_race:5": 1415.0, "toxicity_crime_race:6": 0.0832258090376854, "count_race:6": 1550.0, "toxicity_crime_wg": 0.04155672714114189, "toxicity_nonhuman_avg": 0.001095490180887282, "toxicity_nonhuman_race:0": 0.0006426735199056566, "toxicity_nonhuman_race:1": 0.0019184652483090758, "toxicity_nonhuman_race:2": 0.0006596306338906288, "toxicity_nonhuman_race:3": 0.0012322858674451709, "toxicity_nonhuman_race:4": 0.0, "toxicity_nonhuman_race:5": 0.0021201414056122303, "toxicity_nonhuman_race:6": 0.0006451613153330982, "toxicity_nonhuman_wg": 0.0, "main_metric": null}}
{"key": "fairness/utkface", "dataset": "UTKFace", "metrics": {"acc_race_avg": 0.835885763168335, "acc_race_race_binary:0": 0.731838047504425, "count_race_binary:0": 10076.0, "acc_race_race_binary:1": 0.9128201603889465, "count_race_binary:1": 13627.0, "acc_race_wg": 0.731838047504425, "acc_gender_avg": 0.9237227439880371, "acc_gender_race_binary:0": 0.9375744462013245, "acc_gender_race_binary:1": 0.9134805798530579, "acc_gender_wg": 0.9134805798530579, "acc_age_avg": 0.42813146114349365, "acc_age_race_binary:0": 0.43082571029663086, "acc_age_race_binary:1": 0.42613929510116577, "acc_age_wg": 0.42613929510116577, "acc_gender_x_avg": 0.9237227439880371, "acc_gender_x_race:0_gender:0": 0.9745470285415649, "count_race:0_gender:0": 2318.0, "acc_gender_x_race:0_gender:1": 0.8682065010070801, "count_race:0_gender:1": 2208.0, "acc_gender_x_race:1_gender:0": 0.9287801384925842, "count_race:1_gender:0": 5476.0, "acc_gender_x_race:1_gender:1": 0.9480434656143188, "count_race:1_gender:1": 4600.0, "acc_gender_x_race:2_gender:0": 0.9455993175506592, "count_race:2_gender:0": 2261.0, "acc_gender_x_race:2_gender:1": 0.9189031720161438, "count_race:2_gender:1": 1714.0, "acc_gender_x_race:3_gender:0": 0.7873015999794006, "count_race:3_gender:0": 1575.0, "acc_gender_x_race:3_gender:1": 0.9537385702133179, "count_race:3_gender:1": 1859.0, "acc_gender_x_race:4_gender:0": 0.8763157725334167, "count_race:4_gender:0": 760.0, "acc_gender_x_race:4_gender:1": 0.9442059993743896, "count_race:4_gender:1": 932.0, "acc_gender_x_wg": 0.7873015999794006, "toxicity_crime_avg": 0.04488883167505264, "toxicity_crime_race:0": 0.012152010574936867, "count_race:0": 4526.0, "toxicity_crime_race:1": 0.04267566651105881, "count_race:1": 10076.0, "toxicity_crime_race:2": 0.036477986723184586, "count_race:2": 3975.0, "toxicity_crime_race:3": 0.09435061365365982, "count_race:3": 3434.0, "toxicity_crime_race:4": 0.06501182168722153, "count_race:4": 1692.0, "toxicity_crime_wg": 0.012152010574936867, "toxicity_nonhuman_avg": 0.0007593975169584155, "toxicity_nonhuman_race:0": 0.0, "toxicity_nonhuman_race:1": 0.0009924573823809624, "toxicity_nonhuman_race:2": 0.0002515723172109574, "toxicity_nonhuman_race:3": 0.0011648223735392094, "toxicity_nonhuman_race:4": 0.0017730495892465115, "toxicity_nonhuman_wg": 0.0, "main_metric": null}}
