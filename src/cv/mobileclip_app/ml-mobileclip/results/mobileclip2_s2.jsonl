{"key": "comp/sugarcrepe_replace_obj", "dataset": "SugarCrepe Replace-obj", "metrics": {"image_acc": 1.0, "text_acc": 0.9509685039520264, "acc": 0.9509685039520264, "main_metric": 0.9509685039520264}}
{"key": "comp/sugarcrepe_replace_att", "dataset": "SugarCrepe Replace-att", "metrics": {"image_acc": 1.0, "text_acc": 0.8730964660644531, "acc": 0.8730964660644531, "main_metric": 0.8730964660644531}}
{"key": "comp/sugarcrepe_replace_rel", "dataset": "SugarCrepe Replace-rel", "metrics": {"image_acc": 1.0, "text_acc": 0.7247510552406311, "acc": 0.7247510552406311, "main_metric": 0.7247510552406311}}
{"key": "comp/sugarcrepe_swap_obj", "dataset": "SugarCrepe Swap-obj", "metrics": {"image_acc": 1.0, "text_acc": 0.636734664440155, "acc": 0.636734664440155, "main_metric": 0.636734664440155}}
{"key": "comp/sugarcrepe_swap_att", "dataset": "SugarCrepe Swap-att", "metrics": {"image_acc": 1.0, "text_acc": 0.7057057023048401, "acc": 0.7057057023048401, "main_metric": 0.7057057023048401}}
{"key": "comp/sugarcrepe_add_obj", "dataset": "SugarCrepe Add-obj", "metrics": {"image_acc": 1.0, "text_acc": 0.9088264107704163, "acc": 0.9088264107704163, "main_metric": 0.9088264107704163}}
{"key": "comp/sugarcrepe_add_att", "dataset": "SugarCrepe Add-att", "metrics": {"image_acc": 1.0, "text_acc": 0.8193641901016235, "acc": 0.8193641901016235, "main_metric": 0.8193641901016235}}
{"key": "longclip/sharegpt4v-1k", "dataset": "sharegpt4v-1k", "metrics": {"image_retrieval_recall@1": 0.871999979019165, "text_retrieval_recall@1": 0.9290000200271606, "image_retrieval_recall@5": 0.9800000190734863, "text_retrieval_recall@5": 0.9919999837875366, "image_retrieval_recall@10": 0.9890000224113464, "text_retrieval_recall@10": 0.9980000257492065, "mean_recall@1": 0.9004999995231628, "main_metric": 0.9004999995231628}}
{"key": "longclip/sharegpt4v-llava15k", "dataset": "sharegpt4v-llava15k", "metrics": {"image_retrieval_recall@1": 0.6438705325126648, "text_retrieval_recall@1": 0.7266426682472229, "image_retrieval_recall@5": 0.8591696619987488, "text_retrieval_recall@5": 0.9150702953338623, "image_retrieval_recall@10": 0.9144818782806396, "text_retrieval_recall@10": 0.9535796046257019, "mean_recall@1": 0.6852566003799438, "main_metric": 0.6852566003799438}}
{"key": "longclip/urban1k", "dataset": "urban1k", "metrics": {"image_retrieval_recall@1": 0.45100000500679016, "text_retrieval_recall@1": 0.4819999933242798, "image_retrieval_recall@5": 0.7020000219345093, "text_retrieval_recall@5": 0.75, "image_retrieval_recall@10": 0.7860000133514404, "text_retrieval_recall@10": 0.8259999752044678, "mean_recall@1": 0.466499999165535, "main_metric": 0.466499999165535}}
{"key": "vtab/caltech101", "dataset": "Caltech-101", "metrics": {"acc1": 0.8465078060805259, "acc5": 0.9469186524239934, "mean_per_class_recall": 0.9444422613121747, "main_metric": 0.9444422613121747}}
{"key": "cifar10", "dataset": "CIFAR-10", "metrics": {"acc1": 0.9701, "acc5": 0.9997, "mean_per_class_recall": 0.9701000000000001, "main_metric": 0.9701}}
{"key": "vtab/cifar100", "dataset": "CIFAR-100", "metrics": {"acc1": 0.8481, "acc5": 0.9762, "mean_per_class_recall": 0.8481000000000001, "main_metric": 0.8481}}
{"key": "vtab/clevr_count_all", "dataset": "CLEVR Counts", "metrics": {"acc1": 0.26166666666666666, "acc5": 0.9092666666666667, "mean_per_class_recall": 0.2624205811282919, "main_metric": 0.26166666666666666}}
{"key": "vtab/clevr_closest_object_distance", "dataset": "CLEVR Distance", "metrics": {"acc1": 0.2402, "acc5": 0.9185333333333333, "mean_per_class_recall": 0.17122644574480358, "main_metric": 0.2402}}
{"key": "country211", "dataset": "Country211", "metrics": {"acc1": 0.17895734597156399, "acc5": 0.39649289099526064, "mean_per_class_recall": 0.17895734597156396, "main_metric": 0.17895734597156399}}
{"key": "vtab/dtd", "dataset": "Describable Textures", "metrics": {"acc1": 0.6430851063829788, "acc5": 0.9170212765957447, "mean_per_class_recall": 0.6430851063829789, "main_metric": 0.6430851063829788}}
{"key": "vtab/eurosat", "dataset": "EuroSAT", "metrics": {"acc1": 0.6401851851851852, "acc5": 0.9661111111111111, "mean_per_class_recall": 0.643508065286122, "main_metric": 0.6401851851851852}}
{"key": "fgvc_aircraft", "dataset": "FGVC Aircraft", "metrics": {"acc1": 0.28802880288028804, "acc5": 0.6465646564656465, "mean_per_class_recall": 0.2874509803921569, "main_metric": 0.2874509803921569}}
{"key": "food101", "dataset": "Food-101", "metrics": {"acc1": 0.9055841584158416, "acc5": 0.9888712871287129, "mean_per_class_recall": 0.9055841584158416, "main_metric": 0.9055841584158416}}
{"key": "gtsrb", "dataset": "GTSRB", "metrics": {"acc1": 0.5679334916864608, "acc5": 0.8302454473475851, "mean_per_class_recall": 0.5446059760465726, "main_metric": 0.5679334916864608}}
{"key": "imagenet1k", "dataset": "ImageNet 1k", "metrics": {"acc1": 0.77236, "acc5": 0.9553, "mean_per_class_recall": 0.7726, "main_metric": 0.77236}}
{"key": "imagenet_sketch", "dataset": "ImageNet Sketch", "metrics": {"acc1": 0.6492955255556211, "acc5": 0.8782448073257482, "mean_per_class_recall": 0.6495050980392156, "main_metric": 0.6492955255556211}}
{"key": "imagenetv2", "dataset": "ImageNet v2", "metrics": {"acc1": 0.6973, "acc5": 0.9175, "mean_per_class_recall": 0.6977000000000001, "main_metric": 0.6973}}
{"key": "imagenet-a", "dataset": "ImageNet-A", "metrics": {"acc1": 0.49866666666666665, "acc5": 0.8052, "mean_per_class_recall": 0.48857921951332, "main_metric": 0.49866666666666665}}
{"key": "imagenet-o", "dataset": "ImageNet-O", "metrics": {"acc1": 0.4855, "acc5": 0.828, "mean_per_class_recall": 0.5054018945794487, "main_metric": 0.4855}}
{"key": "imagenet-r", "dataset": "ImageNet-R", "metrics": {"acc1": 0.8741333333333333, "acc5": 0.9661666666666666, "mean_per_class_recall": 0.8611405826762598, "main_metric": 0.8741333333333333}}
{"key": "vtab/kitti_closest_vehicle_distance", "dataset": "KITTI Vehicle Distance", "metrics": {"acc1": 0.24050632911392406, "acc5": null, "mean_per_class_recall": 0.3019182173958117, "main_metric": 0.24050632911392406}}
{"key": "mnist", "dataset": "MNIST", "metrics": {"acc1": 0.8654, "acc5": 0.975, "mean_per_class_recall": 0.8642010154662415, "main_metric": 0.8654}}
{"key": "objectnet", "dataset": "ObjectNet", "metrics": {"acc1": 0.6741143533972219, "acc5": 0.86314202648864, "mean_per_class_recall": 0.6642396796162175, "main_metric": 0.6741143533972219}}
{"key": "vtab/flowers", "dataset": "Oxford Flowers-102", "metrics": {"acc1": 0.82533745324443, "acc5": 0.9341356318100504, "mean_per_class_recall": 0.8170682320615785, "main_metric": 0.8170682320615785}}
{"key": "vtab/pets", "dataset": "Oxford-IIIT Pet", "metrics": {"acc1": 0.9386753883892068, "acc5": 0.9989097846824748, "mean_per_class_recall": 0.9381986589208874, "main_metric": 0.9381986589208874}}
{"key": "voc2007", "dataset": "Pascal VOC 2007", "metrics": {"acc1": 0.8134348290598291, "acc5": 0.9752270299145299, "mean_per_class_recall": 0.8739637830313253, "main_metric": 0.8134348290598291}}
{"key": "vtab/pcam", "dataset": "PatchCamelyon", "metrics": {"acc1": 0.58343505859375, "acc5": null, "mean_per_class_recall": 0.5834414496594333, "main_metric": 0.58343505859375}}
{"key": "renderedsst2", "dataset": "Rendered SST2", "metrics": {"acc1": 0.5299286106534871, "acc5": null, "mean_per_class_recall": 0.5304538677551965, "main_metric": 0.5299286106534871}}
{"key": "vtab/resisc45", "dataset": "RESISC45", "metrics": {"acc1": 0.6965079365079365, "acc5": 0.9423809523809524, "mean_per_class_recall": 0.7022161722043766, "main_metric": 0.6965079365079365}}
{"key": "cars", "dataset": "Stanford Cars", "metrics": {"acc1": 0.9266260415371222, "acc5": 0.9991294615097625, "mean_per_class_recall": 0.9270925709042217, "main_metric": 0.9266260415371222}}
{"key": "stl10", "dataset": "STL-10", "metrics": {"acc1": 0.984, "acc5": 1.0, "mean_per_class_recall": 0.984, "main_metric": 0.984}}
{"key": "sun397", "dataset": "SUN397", "metrics": {"acc1": 0.7385659378045865, "acc5": 0.9558269121135774, "mean_per_class_recall": 0.7284303459919143, "main_metric": 0.7385659378045865}}
{"key": "vtab/svhn", "dataset": "SVHN", "metrics": {"acc1": 0.642939459127228, "acc5": 0.923478795328826, "mean_per_class_recall": 0.62955720727459, "main_metric": 0.642939459127228}}
{"key": "retrieval/flickr_1k_test_image_text_retrieval", "dataset": "Flickr", "metrics": {"image_retrieval_recall@1": 0.748199999332428, "text_retrieval_recall@1": 0.9039999842643738, "image_retrieval_recall@5": 0.9294000267982483, "text_retrieval_recall@5": 0.9819999933242798, "image_retrieval_recall@10": 0.9585999846458435, "text_retrieval_recall@10": 0.9940000176429749, "mean_recall@1": 0.8260999917984009, "main_metric": 0.8260999917984009}}
{"key": "retrieval/mscoco_2014_5k_test_image_text_retrieval", "dataset": "MSCOCO", "metrics": {"image_retrieval_recall@1": 0.4882447123527527, "text_retrieval_recall@1": 0.6669999957084656, "image_retrieval_recall@5": 0.7375449538230896, "text_retrieval_recall@5": 0.8676000237464905, "image_retrieval_recall@10": 0.824310302734375, "text_retrieval_recall@10": 0.9225999712944031, "mean_recall@1": 0.5776223540306091, "main_metric": 0.5776223540306091}}
{"key": "misc/winogavil", "dataset": "WinoGAViL", "metrics": {"avg_jaccard_score": 0.6250497841572779, "jaccard_score_5": 0.6483585858585859, "jaccard_score_6": 0.6247660187185025, "jaccard_score_10": 0.6045383411580594, "jaccard_score_12": 0.5744993324432576, "jaccard_score_5-6": 0.6362618432385874, "jaccard_score_10-12": 0.5894836623173859, "main_metric": 0.5894836623173859}}
{"key": "wilds/iwildcam", "dataset": "iWildCam", "metrics": {"acc1": 0.38318805356266505, "acc5": 0.5606552779790143, "mean_per_class_recall": 0.21482446036867514, "acc_avg": 0.38337501883506775, "recall-macro_all": 0.21482446036867514, "F1-macro_all": 0.17592073352583965, "main_metric": 0.17592073352583965}}
{"key": "wilds/camelyon17", "dataset": "Camelyon17", "metrics": {"acc1": 0.5623486255790439, "acc5": null, "mean_per_class_recall": 0.562348625579044, "acc_avg": 0.5623486042022705, "acc_slide:0": NaN, "count_slide:0": 0.0, "acc_slide:1": NaN, "count_slide:1": 0.0, "acc_slide:2": NaN, "count_slide:2": 0.0, "acc_slide:3": NaN, "count_slide:3": 0.0, "acc_slide:4": NaN, "count_slide:4": 0.0, "acc_slide:5": NaN, "count_slide:5": 0.0, "acc_slide:6": NaN, "count_slide:6": 0.0, "acc_slide:7": NaN, "count_slide:7": 0.0, "acc_slide:8": NaN, "count_slide:8": 0.0, "acc_slide:9": NaN, "count_slide:9": 0.0, "acc_slide:10": NaN, "count_slide:10": 0.0, "acc_slide:11": NaN, "count_slide:11": 0.0, "acc_slide:12": NaN, "count_slide:12": 0.0, "acc_slide:13": NaN, "count_slide:13": 0.0, "acc_slide:14": NaN, "count_slide:14": 0.0, "acc_slide:15": NaN, "count_slide:15": 0.0, "acc_slide:16": NaN, "count_slide:16": 0.0, "acc_slide:17": NaN, "count_slide:17": 0.0, "acc_slide:18": NaN, "count_slide:18": 0.0, "acc_slide:19": NaN, "count_slide:19": 0.0, "acc_slide:20": 0.9102362394332886, "count_slide:20": 3810.0, "acc_slide:21": 0.7428262233734131, "count_slide:21": 3694.0, "acc_slide:22": 0.5123439431190491, "count_slide:22": 7210.0, "acc_slide:23": 0.6074129939079285, "count_slide:23": 5288.0, "acc_slide:24": 0.4796169400215149, "count_slide:24": 7727.0, "acc_slide:25": 0.6811259984970093, "count_slide:25": 4334.0, "acc_slide:26": 0.5876802206039429, "count_slide:26": 3815.0, "acc_slide:27": 0.6927129030227661, "count_slide:27": 4556.0, "acc_slide:28": 0.40890270471572876, "count_slide:28": 31878.0, "acc_slide:29": 0.7550619840621948, "count_slide:29": 12742.0, "acc_wg": 0.40890270471572876, "main_metric": 0.5623486255790439}}
{"key": "wilds/fmow", "dataset": "FMoW", "metrics": {"acc1": 0.21526144382124118, "acc5": 0.5098154514203004, "mean_per_class_recall": 0.2197221881576804, "acc_avg": 0.21526144444942474, "acc_year:0": NaN, "count_year:0": 0.0, "acc_year:1": NaN, "count_year:1": 0.0, "acc_year:2": NaN, "count_year:2": 0.0, "acc_year:3": NaN, "count_year:3": 0.0, "acc_year:4": NaN, "count_year:4": 0.0, "acc_year:5": NaN, "count_year:5": 0.0, "acc_year:6": NaN, "count_year:6": 0.0, "acc_year:7": NaN, "count_year:7": 0.0, "acc_year:8": NaN, "count_year:8": 0.0, "acc_year:9": NaN, "count_year:9": 0.0, "acc_year:10": NaN, "count_year:10": 0.0, "acc_year:11": NaN, "count_year:11": 0.0, "acc_year:12": NaN, "count_year:12": 0.0, "acc_year:13": NaN, "count_year:13": 0.0, "acc_year:14": 0.22921235859394073, "count_year:14": 15959.0, "acc_year:15": 0.17905350029468536, "count_year:15": 6149.0, "acc_worst_year": 0.17905350029468536, "acc_region:0": 0.17771509289741516, "count_region:0": 4963.0, "acc_region:1": 0.23728235065937042, "count_region:1": 5858.0, "acc_region:2": 0.1264944076538086, "count_region:2": 2593.0, "acc_region:3": 0.24651047587394714, "count_region:3": 8024.0, "acc_region:4": 0.26726725697517395, "count_region:4": 666.0, "acc_region:5": 0.75, "count_region:5": 4.0, "acc_worst_region": 0.1264944076538086, "main_metric": 0.1264944076538086}}
{"key": "fairness/dollar_street", "dataset": "Dollar Street", "metrics": {"acc1": 0.5503853839566086, "acc5": 0.8127319440479589, "mean_per_class_recall": 0.5841548946460642, "acc_top5_avg": 0.812731921672821, "acc_top5_income_ds:0": 0.6612149477005005, "count_income_ds:0": 856.0, "acc_top5_income_ds:1": 0.8020362257957458, "count_income_ds:1": 884.0, "acc_top5_income_ds:2": 0.8679245114326477, "count_income_ds:2": 901.0, "acc_top5_income_ds:3": 0.9164733290672302, "count_income_ds:3": 862.0, "acc_top5_wg": 0.6612149477005005, "main_metric": 0.6612149477005005}}
{"key": "fairness/geode", "dataset": "GeoDE", "metrics": {"acc1": 0.9227258167841127, "acc5": 0.9953555413196669, "mean_per_class_recall": 0.9227209688709153, "acc_avg": 0.9227257966995239, "acc_region:0": 0.9043841361999512, "count_region:0": 2395.0, "acc_region:1": 0.9184079766273499, "count_region:1": 2010.0, "acc_region:2": 0.9289746284484863, "count_region:2": 2126.0, "acc_region:3": 0.9193631410598755, "count_region:3": 1947.0, "acc_region:4": 0.9231644868850708, "count_region:4": 1757.0, "acc_region:5": 0.9427430033683777, "count_region:5": 2253.0, "acc_wg": 0.9043841361999512, "main_metric": 0.9043841361999512}}
{"key": "fairness/fairface", "dataset": "FairFace", "metrics": {"acc_race_avg": 0.8584079146385193, "acc_race_race_binary:0": 0.3846522867679596, "count_race_binary:0": 2085.0, "acc_race_race_binary:1": 0.9697824120521545, "count_race_binary:1": 8869.0, "acc_race_wg": 0.3846522867679596, "acc_gender_avg": 0.8947416543960571, "acc_gender_race_binary:0": 0.9203836917877197, "acc_gender_race_binary:1": 0.8887134790420532, "acc_gender_wg": 0.8887134790420532, "acc_age_avg": 0.38579514622688293, "acc_age_race_binary:0": 0.36258992552757263, "acc_age_race_binary:1": 0.3912504315376282, "acc_age_wg": 0.36258992552757263, "acc_gender_x_avg": 0.8947416543960571, "acc_gender_x_race:0_gender:0": 0.8986232876777649, "count_race:0_gender:0": 799.0, "acc_gender_x_race:0_gender:1": 0.7437252402305603, "count_race:0_gender:1": 757.0, "acc_gender_x_race:1_gender:0": 0.9180035591125488, "count_race:1_gender:0": 1122.0, "acc_gender_x_race:1_gender:1": 0.9231567978858948, "count_race:1_gender:1": 963.0, "acc_gender_x_race:2_gender:0": 0.9256308078765869, "count_race:2_gender:0": 753.0, "acc_gender_x_race:2_gender:1": 0.8715596199035645, "count_race:2_gender:1": 763.0, "acc_gender_x_race:3_gender:0": 0.9029003977775574, "count_race:3_gender:0": 793.0, "acc_gender_x_race:3_gender:1": 0.9012048244476318, "count_race:3_gender:1": 830.0, "acc_gender_x_race:4_gender:0": 0.9532595276832581, "count_race:4_gender:0": 813.0, "acc_gender_x_race:4_gender:1": 0.941919207572937, "count_race:4_gender:1": 396.0, "acc_gender_x_race:5_gender:0": 0.8421768546104431, "count_race:5_gender:0": 735.0, "acc_gender_x_race:5_gender:1": 0.9308823347091675, "count_race:5_gender:1": 680.0, "acc_gender_x_race:6_gender:0": 0.8236808180809021, "count_race:6_gender:0": 777.0, "acc_gender_x_race:6_gender:1": 0.9508408904075623, "count_race:6_gender:1": 773.0, "acc_gender_x_wg": 0.7437252402305603, "toxicity_crime_avg": 0.08791308850049973, "toxicity_crime_race:0": 0.03727506473660469, "count_race:0": 1556.0, "toxicity_crime_race:1": 0.16738608479499817, "count_race:1": 2085.0, "toxicity_crime_race:2": 0.05474933981895447, "count_race:2": 1516.0, "toxicity_crime_race:3": 0.06469500809907913, "count_race:3": 1623.0, "toxicity_crime_race:4": 0.10918114334344864, "count_race:4": 1209.0, "toxicity_crime_race:5": 0.06855123490095139, "count_race:5": 1415.0, "toxicity_crime_race:6": 0.08967741578817368, "count_race:6": 1550.0, "toxicity_crime_wg": 0.03727506473660469, "toxicity_nonhuman_avg": 0.0006390359485521913, "toxicity_nonhuman_race:0": 0.0006426735199056566, "toxicity_nonhuman_race:1": 0.0014388489071279764, "toxicity_nonhuman_race:2": 0.0006596306338906288, "toxicity_nonhuman_race:3": 0.0006161429337225854, "toxicity_nonhuman_race:4": 0.0, "toxicity_nonhuman_race:5": 0.0, "toxicity_nonhuman_race:6": 0.0006451613153330982, "toxicity_nonhuman_wg": 0.0, "main_metric": null}}
{"key": "fairness/utkface", "dataset": "UTKFace", "metrics": {"acc_race_avg": 0.8102349638938904, "acc_race_race_binary:0": 0.653036892414093, "count_race_binary:0": 10076.0, "acc_race_race_binary:1": 0.9264695048332214, "count_race_binary:1": 13627.0, "acc_race_wg": 0.653036892414093, "acc_gender_avg": 0.9233852028846741, "acc_gender_race_binary:0": 0.9382691383361816, "acc_gender_race_binary:1": 0.9123798608779907, "acc_gender_wg": 0.9123798608779907, "acc_age_avg": 0.39189133048057556, "acc_age_race_binary:0": 0.3967844247817993, "acc_age_race_binary:1": 0.3882732689380646, "acc_age_wg": 0.3882732689380646, "acc_gender_x_avg": 0.9233852028846741, "acc_gender_x_race:0_gender:0": 0.9754098653793335, "count_race:0_gender:0": 2318.0, "acc_gender_x_race:0_gender:1": 0.8605072498321533, "count_race:0_gender:1": 2208.0, "acc_gender_x_race:1_gender:0": 0.9360847473144531, "count_race:1_gender:0": 5476.0, "acc_gender_x_race:1_gender:1": 0.9408695697784424, "count_race:1_gender:1": 4600.0, "acc_gender_x_race:2_gender:0": 0.9398496150970459, "count_race:2_gender:0": 2261.0, "acc_gender_x_race:2_gender:1": 0.922987163066864, "count_race:2_gender:1": 1714.0, "acc_gender_x_race:3_gender:0": 0.807619035243988, "count_race:3_gender:0": 1575.0, "acc_gender_x_race:3_gender:1": 0.9381387829780579, "count_race:3_gender:1": 1859.0, "acc_gender_x_race:4_gender:0": 0.88289475440979, "count_race:4_gender:0": 760.0, "acc_gender_x_race:4_gender:1": 0.942060112953186, "count_race:4_gender:1": 932.0, "acc_gender_x_wg": 0.807619035243988, "toxicity_crime_avg": 0.0569126270711422, "toxicity_crime_race:0": 0.011931064538657665, "count_race:0": 4526.0, "toxicity_crime_race:1": 0.05855498090386391, "count_race:1": 10076.0, "toxicity_crime_race:2": 0.03672955930233002, "count_race:2": 3975.0, "toxicity_crime_race:3": 0.1255096048116684, "count_race:3": 3434.0, "toxicity_crime_race:4": 0.07565011829137802, "count_race:4": 1692.0, "toxicity_crime_wg": 0.011931064538657665, "toxicity_nonhuman_avg": 0.000506265030708164, "toxicity_nonhuman_race:0": 0.00022094564337749034, "toxicity_nonhuman_race:1": 0.0007939658826217055, "toxicity_nonhuman_race:2": 0.0, "toxicity_nonhuman_race:3": 0.00029120559338480234, "toxicity_nonhuman_race:4": 0.0011820330983027816, "toxicity_nonhuman_wg": 0.0, "main_metric": null}}
