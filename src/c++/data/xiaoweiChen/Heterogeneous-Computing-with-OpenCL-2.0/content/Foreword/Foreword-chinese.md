#序

计算时代在这已经进入异构计算时代，其意味着CPU和GPU可以同时处理同一计算任务。异构计算设计师们正在扩展异构计算的范围，为的就是让异构机器和硬件供应商能在更广阔的空间发挥自己的能量。硬件层面的变化为未来出现的新应用提供了更广阔的平台。不过，因为设计结构不同，传统编程模型在异构平台上的表现很难令人满意，这样就意味着要对新的编程模型进行学习，例如OpenCL中的编程模型。

OpenCL设计之初，设计们注意到，传统算法实现可以分为两类：第一类是延迟密集型(比如：电子表格遍历)，算法工程师们使用C或C++在CPU上进行实现；第二类是吞吐密集型(比如：矩阵相乘)，算法工程师会使用CUDA在GPU上进行实现。两种方式虽有关联，但是每种方式只工作在一种处理器上——C++不能在GPU上运行，CUDA无法在CPU上运行。开发者在实现算法时，只能使用其中一种。不过，算法应该能在不同的设备上混合实现，这才是异构设备的正式能力。现在的问题是如何在这样的设备上进行混合编程？

一种解决方案就是为现有的平台添加新的特性，C++和CUDA也都在积极的向好的方向发展，以迎接新硬件平台的挑战。另一种解决方式就是为异构计算创造一种新的编程模式，Apple公司为这种新的方式提供了提案和范例。这个提案被很多公司的技术部门重新定义，最终形成OpenCL。在设计之初，我很幸运是这些技术部门的一员。我们对kernel语言有着很多的预期：(1)让开发者只写一次kernel代码；(2)让已经写好的kernel代码可以在CPU，GPU，FPGA等设备上有效移植和运行；(3)kernel代码和硬件底层紧密相关，开发者就可充分利用每个设备来提升应用的性能；(4)最大抽象化编程模型，这样在每个公司的机器上只要编译一遍，就可以在其他同型号机器上使用。当然，和任何项目一样，我们想快速完成这些目标。为了加速实现，我们基于C99进行kernel语言的实现。在6个月内，OpenCL 1.0标准就诞生了，并且在1年内第一版的代码实现就出现了。之后，OpenCL就与“真正的”开发者见面了……

之后发生了什么？首先，C开发者说，一些C++特性(内存模型，原子操作等等)的添加让他们的工作更加高效。CUDA开发者说，NVIDIA将所有新特性都添加入CUDA(比如：嵌套并行)，这让写程序更加简单，应用运行起来更加快。第二，硬件架构也是作为异构计算的一种探索，硬件供应商会提，如何移除CPU和GPU都需要独立内存的问题。近期，集成设备技术发展对于硬件来说是一重大的改变，这使得GPU和CPU可以放在同一芯片上(NVIDIA的tegra和AMD的APU都是这方面的例子)。第三，即使标准写的很谨慎，并且有一致性检查套件，不过在编译器实现方面，并不是总按标准来——有时同一套代码会在不同的设备上得到不同的结果。

所以就会之后的再修订，并产生出更加成熟的标准——OpenCL 2.0。

新标准的最大改进，就是能让开发者充分利用集成CPU和GPU的处理器。

较大的改变有如下内容：

- 共享虚拟内存——主机和设备端可以共享复杂数据结构指针，比如：树和链表；以减少花在数据结构转换上的精力。
- 动态并行——可以在不用主机代码参与的情况下，进行内核的加载，为的就是减小加载内核所产生的瓶颈。
- 统一地址空间——这样同样的函数就可以处理GPU和CPU上的数据，以减少编程的难度。
- C++原子操作——工作项可以跨越工作组共享数据和设备，可以让更多的算法使用OpenCL实现。

这本书充分的介绍了OpenCL，可以作为OpenCL编程课的教材，也可以作为并行编程课的一部分。不管怎么说，这本书对于想要学习OpenCL的开发者来说是很值得拥有的。

本书的作者也在高性能GPU和CPU混合编程方面，做了很多时间，花费了很多精力。我个人对他们的工作表示尊敬。之前版本对之前版本的OpenCL的覆盖的很全面，本版本将会覆盖到所有OpenCL 2.0添加的新特性。

我在这里希望读者们通过这本书，能对OpenCL进行了解，并在未来写出牛逼的异构应用。

------------------

Norm Rubin

NVIDIA研究科学家

东北大学访问学者

2015年1月




