#3.8 CUDA編程者使用OpenCL的注意事項

英偉達的CUDA C提供的API與OpenCL類似。代碼清單3.6用使用CUDA實現了向量相加，OpenCL和CUDA中的很多命令都可以相互對應。OpenCL API中有更多的參數，這是因為OpenCL需要在運行時去查找平臺，並對程序進行編譯。CUDA C只針對英偉達的GPU，其只有一個平臺可以使用，所以平臺的查找自動完成；將程序編譯成PTX的過程可以在編譯主機端二進制文件的時候進行(CUDA沒有運行時編譯)。

OpenCL中平臺在運行時進行查找，程序需要選擇一個目標設備，並在運行時進行編譯。程序的編譯不能在運行時之外完成，因為不知道哪個具體設備要去執行內核，無法在這種情況下生成中間碼(IL/ISA)。比如，一個OpenCL內核在AMD GPU上測試有沒有問題，但當其需要運行在Intel的設備上時，編譯器生成的中間碼就和AMD平臺上的不太一樣。從而，對與平臺的查找，以及在運行時進行編譯程序就能避免這樣的問題。

OpenCL和CUDA C最大的區別是，CUDA C提供一些特殊的操作完成內核啟動，其編譯需要使用一套工具鏈，這套工具鏈中需要包含英偉達支持的預處理器。預處理器生成的代碼，和OpenCL的內核代碼十分相近。

{%ace edit=false, lang='c_cpp'%}
#include <stdio.h>
#include <stdlib.h>
#include <math.h>

// CUDA kernel. Eache thread computes one element of C
__global__ void vecAdd(int *A, int *B, int *C, int elements){
  // Compute the global thread ID using CUDA intrinsics
  int id = blocakIdx.x * blocakDim.x + threadIdx.x;
  
  // Must check that the thread is not out of bounds
  if (id < elements)
    C[id] = A[id] + B[id];
}

int main(int argc, char *argv[]){
  // Elements in each array
  const int elements = 2048;
  
  // Compute the size of the data
  size_t datasize = sizeof(int) * elements;
  
  // Allocate space for input/output host data
  int *A = (int *)malloc(datasize); // Input array
  int *B = (int *)malloc(datasize); // Input array
  int *C = (int *)malloc(datasize); // Output array
  
  // Device input vectors
  int *bufA;
  int *bufB;
  // Device output vectors
  int *bufC;
  
  // Allocate memeory for each vector on GPU
  cudaMalloc(&bufA, datasize);
  cudaMalloc(&bufB, datasize);
  cudaMalloc(&bufC, datasize);
  
  int i;
  // Initialize vectors on host
  for (i = 0; i < elements; i++){
    A[i] = i;
	B[i] = i;
  }
  
  // Copy host vectors to device
  cudaMemcpy(bufA, A, datasize, cudaMemcpyHostToDevice);
  cudaMemcpy(bufB, B, datasize, cudaMemcpyHostToDevice);
  
  int blockSize, gridSize;
  
  // Number of threads in each thread block
  blockSize = 256;
  
  // Number of thread blocks in grid
  gridSize = elements / blockSize;
  
  // Execute the kernel
  vecAdd<<<gridSize, blockSize>>>(bufA, bufB, bufC, elements);
  
  // Copy array back to host
  cudaMemcpy(C, bufC, datasize, cudaMemcpyDeviceToHost);
  
  // Release device memeory
  cudaFree(bufA);
  cudaFree(bufB);
  cudaFree(bufC);
  
  // Release host memeoy
  free(A);
  free(B);
  free(C);
}
{%endace%}

代碼清單3.6 CUDA C版本的向量相加