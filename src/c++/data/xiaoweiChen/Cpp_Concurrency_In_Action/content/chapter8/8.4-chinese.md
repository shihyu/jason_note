# 8.4 設計併發代碼的注意事項

目前為止，在本章中我們已經看到了很多線程間劃分工作的方法，影響性能的因素，以及這些因素是如何影響你選擇數據訪問模式和數據結構的。雖然，已經有了很多設計併發代碼的內容。你還需要考慮很多事情，比如異常安全和可擴展性。隨著系統中核數的增加，性能越來越高(無論是在減少執行時間，還是增加吞吐率)，這樣的代碼稱為“可擴展”代碼。理想狀態下，性能隨著核數的增加線性增長，也就是當系統有100個處理器時，其性能是系統只有1核時的100倍。

雖然，非擴展性代碼依舊可以正常工作——單線程應用就無法擴展——例如，異常安全是一個正確性問題。如果你的代碼不是異常安全的，最終會破壞不變量，或是造成條件競爭，亦或是你的應用意外終止，因為某個操作會拋出異常。有了這個想法，我們就率先來看一下異常安全的問題。

## 8.4.1 並行算法中的異常安全

異常安全是衡量`C++`代碼一個很重要的指標，併發代碼也不例外。實際上，相較於串行算法，並行算法常會格外要求注意異常問題。當一個操作在串行算法中拋出一個異常，算法只需要考慮對其本身進行處理，以避免資源洩露和損壞不變量；這裡可以允許異常傳遞給調用者，由調用者對異常進行處理。通過對比，在並行算法中很多操作要運行在獨立的線程上。在這種情況下，異常就不再允許被傳播，因為這將會使調用堆棧出現問題。如果一個函數在創建一個新線程後帶著異常退出，那麼這個應用將會終止。

作為一個具體的例子，讓我們回顧一下清單2.8中的parallel_accumulate函數：

清單8.2 `std::accumulate`的原始並行版本(源於清單2.8)

```
template<typename Iterator,typename T>
struct accumulate_block
{
  void operator()(Iterator first,Iterator last,T& result)
  {
    result=std::accumulate(first,last,result);  // 1
  }
};

template<typename Iterator,typename T>
T parallel_accumulate(Iterator first,Iterator last,T init)
{
  unsigned long const length=std::distance(first,last);  // 2

  if(!length)
    return init;

  unsigned long const min_per_thread=25;
  unsigned long const max_threads=
    (length+min_per_thread-1)/min_per_thread;

  unsigned long const hardware_threads=
    std::thread::hardware_concurrency();
  
  unsigned long const num_threads=
    std::min(hardware_threads!=0?hardware_threads:2,max_threads);
  
  unsigned long const block_size=length/num_threads;
  
  std::vector<T> results(num_threads);  // 3
  std::vector<std::thread> threads(num_threads-1);  // 4

  Iterator block_start=first;  // 5
  for(unsigned long i=0;i<(num_threads-1);++i)
  {
    Iterator block_end=block_start;  // 6
    std::advance(block_end,block_size);
    threads[i]=std::thread(  // 7
      accumulate_block<Iterator,T>(),
      block_start,block_end,std::ref(results[i]));
    block_start=block_end;  // 8
  }
  accumulate_block()(block_start,last,results[num_threads-1]);  // 9

  std::for_each(threads.begin(),threads.end(),
    std::mem_fn(&std::thread::join));

  return std::accumulate(results.begin(),results.end(),init);  // 10
}
```

現在讓我們來看一下異常要在哪拋出：基本上就是在調用函數的地方拋出異常，或在用戶定義類型上執行某個操作時可能拋出異常。

首先，需要調用distance②，其會對用戶定義的迭代器類型進行操作。因為，這時還沒有做任何事情，所以對於調用線程來說，所有事情都沒問題。接下來，就需要分配results③和threads④。再後，調用線程依舊沒有做任何事情，或產生新的線程，所以到這裡也是沒有問題的。當然，如果在構造threads拋出異常，那麼對已經分配的results將會被清理，析構函數會幫你打理好一切。

跳過block_start⑤的初始化(因為也是安全的)，來到了產生新線程的循環⑥⑦⑧。當在⑦處創建了第一個線程，如果再拋出異常，就會出問題的；對於新的`std::thread`對象將會銷燬，程序將調用`std::terminate`來中斷程序的運行。使用`std::terminate`的地方，可不是什麼好地方。

accumulate_block⑨的調用就可能拋出異常，就會產生和上面類似的結果；線程對象將會被銷燬，並且調用`std::terminate`。另一方面，最終調用`std::accumulate`⑩可能會拋出異常，不過處理起來沒什麼難度，因為所有的線程在這裡已經匯聚回主線程了。

上面只是對於主線程來說的，不過還有很多地方會拋出異常：對於調用accumulate_block的新線程來說就會拋出異常①。沒有任何catch塊，所以這個異常不會被處理，並且當異常發生的時候會調用`std::terminater()`來終止應用的運行。

也許這裡的異常問題並不明顯，不過這段代碼是非異常安全的。

**添加異常安全**

好吧，我們已經確定所有拋出異常的地方了，並且知道異常所帶來的惡性後果。能為其做些什麼呢？就讓我們來解決一下在新線程上的異常問題。

在第4章時已經使用過工具來做這件事。如果你仔細的瞭解過新線程用來完成什麼樣的工作，要返回一個計算的結果的同時，允許代碼產生異常。這可以將`std::packaged_task`和`std::future`相結合，來解決這個問題。如果使用`std::packaged_task`重新構造代碼，代碼可能會是如下模樣。

清單8.3 使用`std::packaged_task`的並行`std::accumulate`

```
template<typename Iterator,typename T>
struct accumulate_block
{
  T operator()(Iterator first,Iterator last)  // 1
  {
    return std::accumulate(first,last,T());  // 2
  }
};

template<typename Iterator,typename T>
T parallel_accumulate(Iterator first,Iterator last,T init)
{
  unsigned long const length=std::distance(first,last);

  if(!length)
    return init;

  unsigned long const min_per_thread=25;
  unsigned long const max_threads=
    (length+min_per_thread-1)/min_per_thread;

  unsigned long const hardware_threads=
    std::thread::hardware_concurrency();

  unsigned long const num_threads=
    std::min(hardware_threads!=0?hardware_threads:2,max_threads);

  unsigned long const block_size=length/num_threads;

  std::vector<std::future<T> > futures(num_threads-1);  // 3
  std::vector<std::thread> threads(num_threads-1);

  Iterator block_start=first;
  for(unsigned long i=0;i<(num_threads-1);++i)
  {
    Iterator block_end=block_start;
    std::advance(block_end,block_size);
    std::packaged_task<T(Iterator,Iterator)> task(  // 4
      accumulate_block<Iterator,T>());
    futures[i]=task.get_future();  // 5
    threads[i]=std::thread(std::move(task),block_start,block_end);  // 6
    block_start=block_end;
  }
  T last_result=accumulate_block()(block_start,last);  // 7
  
  std::for_each(threads.begin(),threads.end(),
    std::mem_fn(&std::thread::join));

  T result=init;  // 8
  for(unsigned long i=0;i<(num_threads-1);++i)
  {
    result+=futures[i].get();  // 9
  }
  result += last_result;  // 10
  return result;
}
```

第一個修改就是調用accumulate_block的操作現在就是直接將結果返回，而非使用引用將結果存儲在某個地方①。使用`std::packaged_task`和`std::future`是線程安全的，所以你可以使用它們來對結果進行轉移。當調用`std::accumulate`②時，需要你顯示傳入T的默認構造函數，而非複用result的值，不過這只是一個小改動。

下一個改動就是，不用向量來存儲結果，而使用futures向量為每個新生線程存儲`std::future<T>`③。在新線程生成循環中，首先要為accumulate_block創建一個任務④。`std::packaged_task<T(Iterator,Iterator)>`聲明，需要操作的兩個Iterators和一個想要獲取的T。然後，從任務中獲取future⑤，再將需要處理的數據塊的開始和結束信息傳入⑥，讓新線程去執行這個任務。當任務執行時，future將會獲取對應的結果，以及任何拋出的異常。

使用future，就不能獲得到一組結果數組，所以需要將最終數據塊的結果賦給一個變量進行保存⑦，而非對一個數組進行填槽。同樣，因為需要從future中獲取結果，使用簡單的for循環，就要比使用`std::accumulate`好的多；循環從提供的初始值開始⑧，並且將每個future上的值進行累加⑨。如果相關任務拋出一個異常，那麼異常就會被future捕捉到，並且使用get()的時候獲取數據時，這個異常會再次拋出。最後，在返回結果給調用者之前，將最後一個數據塊上的結果添加入結果中⑩。

這樣，一個問題就已經解決：在工作線程上拋出的異常，可以在主線程上拋出。如果不止一個工作線程拋出異常，那麼只有一個能在主線程中拋出，不過這不會有產生太大的問題。如果這個問題很重要，你可以使用類似`std::nested_exception`來對所有拋出的異常進行捕捉。

剩下的問題就是，當生成第一個新線程和當所有線程都匯入主線程時，拋出異常；這樣會讓線程產生洩露。最簡單的方法就是捕獲所有拋出的線程，匯入的線程依舊是joinable()的，並且會再次拋出異常：

```
try
{
  for(unsigned long i=0;i<(num_threads-1);++i)
  {
    // ... as before
  }
  T last_result=accumulate_block()(block_start,last);

  std::for_each(threads.begin(),threads.end(),
  std::mem_fn(&std::thread::join));
}
catch(...)
{
  for(unsigned long i=0;i<(num_thread-1);++i)
  {
  if(threads[i].joinable())
    thread[i].join();
  }
  throw;
}
```

現在好了，無論線程如何離開這段代碼，所有線程都可以被匯入。不過，*try-catch*很不美觀，並且這裡有重複代碼。可以將“正常”控制流上的線程在*catch*塊上執行的線程進行匯入。重複代碼是沒有必要的，因為這就意味著更多的地方需要改變。不過，現在讓我們來提取一個對象的析構函數；畢竟，析構函數是`C++`中處理資源的慣用方式。看一下你的類：

```
class join_threads
{
  std::vector<std::thread>& threads;
public:
  explicit join_threads(std::vector<std::thread>& threads_):
    threads(threads_)
  {}
  ~join_threads()
  {
    for(unsigned long i=0;i<threads.size();++i)
    {
      if(threads[i].joinable())
        threads[i].join();
    }
  }
};
```

這個類和在清單2.3中看到的thread_guard類很相似，除了使用向量的方式來擴展線程量。用這個類簡化後的代碼如下所示：

清單8.4 異常安全版`std::accumulate`

```
template<typename Iterator,typename T>
T parallel_accumulate(Iterator first,Iterator last,T init)
{
  unsigned long const length=std::distance(first,last);

  if(!length)
    return init;

  unsigned long const min_per_thread=25;
  unsigned long const max_threads=
    (length+min_per_thread-1)/min_per_thread;

  unsigned long const hardware_threads=
    std::thread::hardware_concurrency();

  unsigned long const num_threads=
    std::min(hardware_threads!=0?hardware_threads:2,max_threads);

  unsigned long const block_size=length/num_threads;

  std::vector<std::future<T> > futures(num_threads-1);
  std::vector<std::thread> threads(num_threads-1);
  join_threads joiner(threads);  // 1

  Iterator block_start=first;
  for(unsigned long i=0;i<(num_threads-1);++i)
  {
    Iterator block_end=block_start;
    std::advance(block_end,block_size);
    std::packaged_task<T(Iterator,Iterator)> task(
      accumulate_block<Iterator,T>());
    futures[i]=task.get_future();
    threads[i]=std::thread(std::move(task),block_start,block_end);
    block_start=block_end;
  }
  T last_result=accumulate_block()(block_start,last);
  T result=init;
  for(unsigned long i=0;i<(num_threads-1);++i)
  {
    result+=futures[i].get();  // 2
  }
  result += last_result;
  return result;
}
```

當創建了線程容器，就對新類型創建了一個實例①，可讓退出線程進行匯入。然後，可以再顯式的匯入循環中將線程刪除，在原理上來說是安全的：因為線程，無論怎麼樣退出，都需要匯入主線程。注意這裡對futures[i].get()②的調用，將會阻塞線程，直到結果準備就緒，所以這裡不需要顯式的將線程進行匯入。和清單8.2中的原始代碼不同：原始代碼中，你需要將線程匯入，以確保results向量被正確填充。不僅需要異常安全的代碼，還需要較短的函數實現，因為這裡已經將匯入部分的代碼放到新(可複用)類型中去了。

**std::async()的異常安全**

現在，你已經瞭解了，當需要顯式管理線程的時候，需要代碼是異常安全的。那現在讓我們來看一下使用`std::async()`是怎麼樣完成異常安全的。在本例中，標準庫對線程進行了較好的管理，並且當“期望”處以就緒狀態的時候，就能生成一個新的線程。對於異常安全，還需要注意一件事，如果在沒有等待的情況下對“期望”實例進行銷燬，析構函數會等待對應線程執行完畢後才執行。這就能橋面的必過線程洩露的問題，因為線程還在執行，且持有數據的引用。下面的代碼將展示使用`std::async()`完成異常安全的實現。

清單8.5 異常安全並行版`std::accumulate`——使用`std::async()`

```
template<typename Iterator,typename T>
T parallel_accumulate(Iterator first,Iterator last,T init)
{
  unsigned long const length=std::distance(first,last);  // 1
  unsigned long const max_chunk_size=25;
  if(length<=max_chunk_size)
  {
    return std::accumulate(first,last,init);  // 2
  }
  else
  {
    Iterator mid_point=first;
    std::advance(mid_point,length/2);  // 3
    std::future<T> first_half_result=
      std::async(parallel_accumulate<Iterator,T>,  // 4
        first,mid_point,init);
    T second_half_result=parallel_accumulate(mid_point,last,T());  // 5
    return first_half_result.get()+second_half_result;  // 6
  }
}
```

這個版本對數據進行遞歸劃分，而非在預計算後對數據進行分塊；因此，這個版本要比之前的版本簡單很多，並且這個版本也是異常安全的。和之前一樣，一開始要確定序列的長度①，如果其長度小於數據塊包含數據的最大數量，那麼可以直接調用`std::accumulate`②。如果元素的數量超出了數據塊包含數據的最大數量，那麼就需要找到數量中點③，將這個數據塊分成兩部分，然後再生成一個異步任務對另一半數據進行處理④。第二半的數據是通過直接的遞歸調用來處理的⑤，之後將兩個塊的結果加和到一起⑥。標準庫能保證`std::async`的調用能夠充分的利用硬件線程，並且不會產生線程的超額認購，一些“異步”調用是在調用get()⑥後同步執行的。

優雅的地方，不僅在於利用硬件併發的優勢，並且還能保證異常安全。如果有異常在遞歸調用⑤中拋出，通過調用`std::async`④所產生的“期望”，將會在異常傳播時被銷燬。這就需要依次等待異步任務的完成，因此也能避免懸空線程的出現。另外，當異步任務拋出異常，且被future所捕獲，在對get()⑥調用的時候，future中存儲的異常，會再次拋出。

除此之外，在設計併發代碼的時候還要考慮哪些其他因素？讓我們來看一下*擴展性* (scalability)。隨著系統中核數的增加，應用性能如何提升？

## 8.4.2 可擴展性和Amdahl定律

擴展性代表了應用利用系統中處理器執行任務的能力。一種極端就是將應用寫死為單線程運行，這種應用就是完全不可擴展的；即使添加了100個處理器到你的系統中，應用的性能都不會有任何改變。另一種就是像SETI@Home[3]項目一樣，讓應用使用系統中成千上萬的處理器(以個人電腦的形式加入網絡的用戶)成為可能。

對於任意的多線程程序，在程序運行的時候，運行的工作線程數量會有所不同。應用初始階段只有一個線程，之後會在這個線程上衍生出新的線程。理想狀態：每個線程都做著有用的工作，不過這種情況幾乎是不可能發生的。線程通常會花時間進行互相等待，或等待I/O操作的完成。

一種簡化的方式就是就是將程序劃分成“串行”部分和“並行”部分。串行部分：只能由單線程執行一些工作的地方。並行部分：可以讓所有可用的處理器一起工作的部分。當在多處理系統上運行你的應用時，“並行”部分理論上會完成的相當快，因為其工作被劃分為多份，放在不同的處理器上執行。“串行”部分則不同，還是隻能一個處理器執行所有工作。這樣(簡化)假設下，就可以對隨著處理數量的增加，估計一下性能的增益：當程序“串行”部分的時間用fs來表示，那麼性能增益(P)就可以通過處理器數量(N)進行估計：

![](../../images/chapter8/amdahl_law.png)

這就是Amdahl定律，在討論併發程序性能的時候都會引用到的公式。如果每行代碼都能並行化，串行部分就為0，那麼性能增益就為N。或者，當串行部分為1/3時，當處理器數量無限增長，你都無法獲得超過3的性能增益。

Amdahl定律明確了，對代碼最大化併發可以保證所有處理器都能用來做有用的工作。如果將“串行”部分的減小，或者減少線程的等待，就可以在多處理器的系統中獲取更多的性能收益。或者，當能提供更多的數據讓系統進行處理，並且讓並行部分做最重要的工作，就可以減少“串行”部分，以獲取更高的性能增益。

擴展性：當有更多的處理器加入時，減少一個動作的執行時間，或在給定時間內做更多工作。有時這兩個指標是等價的(如果處理器的速度相當快，那麼就可以處理更多的數據)，有時不是。選擇線程間的工作劃分的技術前，辨別哪些方面是能否擴展的就十分的重要。

本節開始已經提到，線程並非任何時候都做的是有用的工作。有時，它們會等待其他線程，或者等待I/O完成，亦或是等待其他的事情。如果線程在等待的時候，系統中還有必要的任務需要完成時，就可以將等待“隱藏”起來。

## 8.4.3 使用多線程隱藏延遲

之前討論了很多有關多線程性能的話題。現在假設，線程在一個處理器上運行時不會偷懶，並且做的工作都很有用。當然，這只是假設；在實際應用中，線程會經常因為等待某些事情而阻塞。

不論等待的理由是什麼，如果有和系統中物理單元相同數量的線程，那麼線程阻塞就意味著在等待CPU時間片。處理器將會在阻塞的時間內運行另一個線程，而不是什麼事情都不做。因此，當知道一些線程需要像這樣耗費相當一段時間進行等待時，可以利用CPU的空閒時間去運行一個或多個線程。

試想一個病毒掃描程序，使用流水線對線程間的工作進行劃分。第一個線程對文件系統中的文件進行檢查，並將它們放入一個隊列中。同時，另一個線程從隊列中獲取文件名，加載文件，之後對它們進行病毒掃描。線程對文件系統中的文件進行掃描就會受到I/O操作的限制，所以可以通過執行額外的掃描線程，充分利用CPU的“空閒”時間。這時還需要一個文件搜索線程，以及足夠多的掃描線程。當掃描線程為了掃描文件，還要從磁盤上讀取到重要部分的文件時，就能體會到多掃描線程的意義所在了。不過，在某些時候線程也過於多，系統將會因為越來越多的任務切換而降低效率，就像8.2.5節描述的那樣。

同之前一樣，這也是一種優化，對修改(線程數量)前後性能的測量很重要；優化的線程數量高度依賴要完成工作的先天屬性，以及等待時間所佔的百分比。

應用可能不用額外的線程，而使用CPU的空閒時間。例如，如果一個線程因為I/O操作被阻塞，這個線程可能會使用異步I/O(如果可以用的話)，當I/O操作在後臺執行完成後，線程就可以做其他有用的工作了。在其他情況下，當一個線程等待其他線程去執行一個操作時，比起阻塞，不如讓阻塞線程自己來完成這個操作，就像在第7章中看到的無鎖隊列那樣。在一個極端的例子中，當一個線程等待一個任務完成，並且這個任務還沒有被其他任何線程所執行時，等待線程就可以執行這個任務，或執行另一個不完整的任務。在清單8.1中看到這樣的例子，排序函數持續的嘗試對數據進行排序，即使那些數據已經不需要排序了。

比起添加線程數量讓其對處理器進行充分利用，有時也要在增加線程的同時，確保外部事件被及時的處理，以提高系統的響應能力。

## 8.4.4 使用併發提高響應能力

很多流行的圖形化用戶接口框架都是*事件驅動型*(event driven)；對圖形化接口進行操作是通過按下按鍵或移動鼠標進行，將產生一系列需要應用處理的事件或信息。系統也可能產生信息或事件。為了確定所有事件和信息都能被正確的處理，應用通常會有一個事件循環，就像下面的代碼：

```
while(true)
{
  event_data event=get_event();
  if(event.type==quit)
    break;
  process(event);
}
```

顯然，API中的細節可能不同，不過結構通常是一樣的：等待一個事件，對其做必要的處理，之後等待下一個事件。如果是一個單線程應用，那麼就會讓長期任務很難書寫，如同在8.1.3節中所描述。為了確保用戶輸入被及時的處理，無論應時在做些什麼，get_event()和process()必須以合理的頻率調用。這就意味著任務要被週期性的懸掛，並且返回到事件循環中，或get_event()/process()必須在一個合適地方進行調用。每個選項的複雜程度取決於任務的實現方式。

通過使用併發分離關注，可以將一個很長的任務交給一個全新的線程，並且留下一個專用的GUI線程來處理這些事件。線程可以通過簡單的機制進行通訊，而不是將事件處理代碼和任務代碼混在一起。下面的例子就是展示了這樣的分離。

清單8.6 將GUI線程和任務線程進行分離

```
std::thread task_thread;
std::atomic<bool> task_cancelled(false);

void gui_thread()
{
  while(true)
  {
    event_data event=get_event();
    if(event.type==quit)
      break;
    process(event);
  }
}

void task()
{
  while(!task_complete() && !task_cancelled)
  {
    do_next_operation();
  }
  if(task_cancelled)
  {
    perform_cleanup();
  }
  else
  {
    post_gui_event(task_complete);
  }
}

void process(event_data const& event)
{
  switch(event.type)
  {
  case start_task:
    task_cancelled=false;
    task_thread=std::thread(task);
    break;
  case stop_task:
    task_cancelled=true;
    task_thread.join();
    break;
  case task_complete:
    task_thread.join();
    display_results();
    break;
  default:
    //...
  }
}
```

通過這種方式對關注進行分離，用戶線程將總能及時的對事件進行響應，及時完成任務需要花費很長事件。使用應用的時候，響應事件通常也是影響用戶體驗的重要一點；無論是特定操作被不恰當的執行(無論是什麼操作)，應用都會被完全鎖住。通過使用專門的事件處理線程，GUI就能處理GUI指定的信息了(比如對於調整窗口的大小或顏色)，而不需要中斷處理器，進行耗時的處理；同時，還能向長期任務傳遞相關的信息。

現在，你可以將本章中在設計併發代碼時要考慮的所有問題進行一下回顧。作為一個整體，它們都很具有代表性，不過當你熟練的使用“多線程編程”時，考慮其中的很多問題將變成你習慣。如果你是初學者，我希望這些例子能讓你明白，這些問題是如何影響多線程代碼的。

------------

[3] http://setiathome.ssl.berkeley.edu/