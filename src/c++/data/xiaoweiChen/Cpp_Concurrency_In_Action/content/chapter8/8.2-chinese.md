# 8.2 影響併發代碼性能的因素

`多處理系統中，使用併發的方式來提高代碼的效率時，你需要了解一下有哪些因素會影響併發的效率。即使已經使用多線程對關注進行分離，還需要確定是否會對性能造成負面影響。因為，在16核機器上應用的速度與單核機器相當時，用戶是不會打死你的。

之後你會看到，在多線程代碼中有很多因素會影響性能——對線程處理的數據做一些簡單的改動(其他不變)，都可能對性能產生戲劇性的效果。所以，多言無益，讓我們來看一下這些因素吧，從明顯的開始：目標系統有多少個處理器？

## 8.2.1 有多少個處理器？

處理器個數是影響多線程應用的首要因素。在某些情況下，你對目標硬件會很熟悉，並且針對硬件進行設計，並在目標系統或副本上進行測量。如果是這樣，那你很幸運；不過，要知道這些都是很奢侈的。你可能在一個類似的平臺上進行開發，不過你所使用的平臺與目標平臺的差異很大。例如，你可能會在一個雙芯或四芯的系統上做開發，不過你的用戶系統可能就只有一個處理器(可能有很多芯)，或多個單芯處理器，亦或是多核多芯的處理器。在不同的平臺上，併發程序的行為和性能特點就可能完全不同，所以你需要仔細考慮那些地方會被影響到，如果會被影響，就需要在不同平臺上進行測試。

一個單核16芯的處理器和四核雙芯或十六核單芯的處理器相同：在任何系統上，都能運行16個併發線程。當線程數量少於16個時，會有處理器處於空閒狀態(除非系統同時需要運行其他應用，不過我們暫時忽略這種可能性)。另一方面，當多於16個線程在運行的時候(都沒有阻塞或等待)，應用將會浪費處理器的運算時間在線程間進行切換，如第1章所述。這種情況發生時，我們稱其為*超額認購*(oversubscription)。

為了擴展應用線程的數量，與硬件所支持的併發線程數量一致，`C++`標準線程庫提供了`std::thread::hardware_concurrency()`。使用這個函數就能知道在給定硬件上可以擴展的線程數量了。

需要謹慎使用`std::thread::hardware_concurrency()`，因為代碼不會考慮有其他運行在系統上的線程(除非已經將系統信息進行共享)。最壞的情況就是，多線程同時調用`std::thread::hardware_concurrency()`函數來對線程數量進行擴展，這樣將導致龐大的超額認購。`std::async()`就能避免這個問題，因為標準庫會對所有的調用進行適當的安排。同樣，謹慎的使用線程池也可以避免這個問題。

不過，即使你已經考慮到所有在應用中運行的線程，程序還要被同時運行的其他程序所影響。雖然，在單用戶系統中，使用多個CPU密集型應用程序很罕見，但在某些領域，這種情況就很常見了。雖然系統能提供選擇線程數量的機制，但這種機制已經超出`C++`標準的範圍。這裡的一種選擇是使用與`std::async()`類似的工具，來為所有執行異步任務的線程的數量做考慮；另一種選擇就是，限制每個應用使用的處理芯個數。我倒是希望，這種限制能反映到`std::thread::hardware_concurrency()`上面(不能保證)。如果你需要處理這種情況，可以看一下你所使用的系統說明，瞭解一下是否有相關選項可供使用。

理想算法可能會取決於問題規模與處理單元的比值。大規模並行系統中有很多的處理單元，算法可能就會同時執行很多操作，讓應用更快的結束；這就要快於執行較少操作的平臺，因為該平臺上的每一個處理器只能執行很少的操作。

隨著處理器數量的增加，另一個問題就會來影響性能：多個處理器嘗試訪問同一個數據。

## 8.2.2 數據爭用與乒乓緩存

當兩個線程併發的在不同處理器上執行，並且對同一數據進行讀取，通常不會出現問題；因為數據將會拷貝到每個線程的緩存中，並且可以讓兩個處理器同時進行處理。不過，當有線程對數據進行修改的時候，這個修改需要更新到其他核芯的緩存中去，就要耗費一定的時間。根據線程的操作性質，以及使用到的內存序，這樣的修改可能會讓第二個處理器停下來，等待硬件內存更新緩存中的數據。即便是精確的時間取決於硬件的物理結構，不過根據CPU指令，這是一個特別特別慢的操作，相當於執行成百上千個獨立指令。

思考下面簡短的代碼段：

```
std::atomic<unsigned long> counter(0);
void processing_loop()
{
  while(counter.fetch_add(1,std::memory_order_relaxed)<100000000)
  {
    do_something();
  }
}
```

counter變量是全局的，所以任何線程都能調用processing_loop()去修改同一個變量。因此，當新增加的處理器時，counter變量必須要在緩存內做一份拷貝，再改變自己的值，或其他線程以發佈的方式對緩存中的拷貝副本進行更新。即使用`std::memory_order_relaxed`，編譯器不會為任何數據做同步操作，fetch_add是一個“讀-改-寫”操作，因此就要對最新的值進行檢索。如果另一個線程在另一個處理器上執行同樣的代碼，counter的數據需要在兩個處理器之間進行傳遞，那麼這兩個處理器的緩存中間就存有counter的最新值(當counter的值增加時)。如果do_something()足夠短，或有很多處理器來對這段代碼進行處理時，處理器將會互相等待；一個處理器準備更新這個值，另一個處理器正在修改這個值，所以該處理器就不得不等待第二個處理器更新完成，並且完成更新傳遞時，才能執行更新。這種情況被稱為*高競爭*(high contention)。如果處理器很少需要互相等待，那麼這種情況就是*低競爭*(low contention)。

在這個循環中，counter的數據將在每個緩存中傳遞若干次。這就叫做*乒乓緩存*(cache ping-pong)，這種情況會對應用的性能有著重大的影響。當一個處理器因為等待緩存轉移而停止運行時，這個處理器就不能做任何事情，所以對於整個應用來說，這就是一個壞消息。

你可能會想，這種情況不會發生在你身上；因為，你沒有使用任何循環。你確定嗎？那麼互斥鎖呢？如果你需要在循環中放置一個互斥量，那麼你的代碼就和之前從數據訪問的差不多了。為了鎖住互斥量，另一個線程必須將數據進行轉移，就能彌補處理器的互斥性，並且對數據進行修改。當這個過程完成時，將會再次對互斥量進行修改，並對線程進行解鎖，之後互斥數據將會傳遞到下一個需要互斥量的線程上去。轉移時間，就是第二個線程等待第一個線程釋放互斥量的時間：

```
std::mutex m;
my_data data;
void processing_loop_with_mutex()
{
  while(true)
  {
    std::lock_guard<std::mutex> lk(m);
    if(done_processing(data)) break;
  }
}
```

接下來看看最糟糕的部分：數據和互斥量已經準備好讓多個線程進訪問之後，當系統中的核心數和處理器數量增加時，很可能看到高競爭，以及一個處理器等待其他處理器的情況。如果在多線程情況下，能更快的對同樣級別的數據進行處理，線程就會對數據和互斥量進行競爭。這裡有很多這樣的情況，很多線程會同時嘗試對互斥量進行獲取，或者同時訪問變量，等等。

互斥量的競爭通常不同於原子操作的競爭，最簡單的原因是，互斥量通常使用操作系統級別的序列化線程，而非處理器級別的。如果有足夠的線程去執行任務，當有線程在等待互斥量時，操作系統會安排其他線程來執行任務，而處理器只會在其他線程運行在目標處理器上時，讓該處理器停止工作。不過，對互斥量的競爭，將會影響這些線程的性能；畢竟，只能讓一個線程在同一時間運行。

回顧第3章，一個很少更新的數據結構可以被一個“單作者，多讀者”互斥量(詳見3.3.2)。乒乓緩存效應可以抵消互斥所帶來的收益(工作量不利時)，因為所有線程訪問數據(即使是讀者線程)都會對互斥量進行修改。隨著處理器對數據的訪問次數增加，對於互斥量的競爭就會增加，並且持有互斥量的緩存行將會在核芯中進行轉移，因此會增加不良的鎖獲取和釋放次數。有一些方法可以改善這個問題，其本質就是讓互斥量對多行緩存進行保護，不過這樣的互斥量需要自己去實現。

如果乒乓緩存是一個糟糕的現象，那麼該怎麼避免它呢？在本章後面，答案會與提高併發潛能的指導意見相結合：減少兩個線程對同一個內存位置的競爭。

雖然，要實現起來並不簡單。即使給定內存位置被一個線程所訪問，可能還是會有乒乓緩存的存在,是因為另一種叫做*偽共享*(false sharing)的效應。

## 8.2.3 偽共享

處理器緩存通常不會用來處理在單個存儲位置，但其會用來處理稱為*緩存行*(cache lines)的內存塊。內存塊通常大小為32或64字節，實際大小需要由正在使用著的處理器模型來決定。因為硬件緩存進處理緩存行大小的內存塊，較小的數據項就在同一內存行的相鄰內存位置上。有時，這樣的設定還是挺不錯：當線程訪問的一組數據是在同一數據行中，對於應用的性能來說就要好於向多個緩存行進行傳播。不過，當在同一緩存行存儲的是無關數據，且需要被不同線程訪問，這就會造成性能問題。

假設你有一個int類型的數組，並且有一組線程可以訪問數組中的元素，且對數組的訪問很頻繁(包括更新)。通常int類型的大小要小於一個緩存行，同一個緩存行中可以存儲多個數據項。因此，即使每個線程都能對數據中的成員進行訪問，硬件緩存還是會產生乒乓緩存。每當線程訪問0號數據項，並對其值進行更新時，緩存行的所有權就需要轉移給執行該線程的處理器，這僅是為了讓更新1號數據項的線程獲取1號線程的所有權。緩存行是共享的(即使沒有數據存在)，因此使用*偽共享*來稱呼這種方式。這個問題的解決辦法就是對數據進行構造，讓同一線程訪問的數據項存在臨近的內存中(就像是放在同一緩存行中)，這樣那些能被獨立線程訪問的數據將分佈在相距很遠的地方，並且可能是存儲在不同的緩存行中。在本章接下來的內容中看到，這種思路對代碼和數據設計的影響。

如果多線程訪問同一內存行是一種糟糕的情況，那麼在單線程下的內存佈局將會如何帶來哪些影響呢？

## 8.2.4 如何讓數據緊湊？

偽共享發生的原因：某個線程所要訪問的數據過於接近另一線程的數據，另一個是與數據佈局相關的陷阱會直接影響單線程的性能。問題在於數據過於接近：當數據能被單線程訪問時，那麼數據就已經在內存中展開，就像是分佈在不同的緩存行上。另一方面，當內存中有能被單線程訪問緊湊的數據時，就如同數據分佈在同一緩存行上。因此，當數據已傳播，那麼將會有更多的緩存行將會從處理器的緩存上加載數據，這會增加訪問內存的延遲，以及降低數據的系能(與緊湊的數據存儲地址相比較)。

同樣的，如果數據已傳播，在給定緩存行上就即包含於當前線程有關和無關的數據。在極端情況下，當有更多的數據存在於緩存中，你會對數據投以更多的關注，而非這些數據去做了什麼。這就會浪費寶貴的緩存空間，增加處理器緩存缺失的情況，即使這個數據項曾經在緩存中存在過，還需要從主存中添加對應數據項到緩存中，因為在緩存中其位置已經被其他數據所佔有。

現在，對於單線程代碼來說就很關鍵了，何至於此呢？原因就是*任務切換*(task switching)。如果系統中的線程數量要比核芯多，每個核上都要運行多個線程。這就會增加緩存的壓力，為了避免偽共享，努力讓不同線程訪問不同緩存行。因此，當處理器切換線程的時候，就要對不同內存行上的數據進行重新加載(當不同線程使用的數據跨越了多個緩存行時)，而非對緩存中的數據保持原樣(當線程中的數據都在同一緩存行時)。

如果線程數量多於內核或處理器數量，操作系統可能也會選擇將一個線程安排給這個核芯一段時間，之後再安排給另一個核芯一段時間。因此就需要將緩存行從一個內核上，轉移到另一個內核上；這樣的話，就需要轉移很多緩存行，也就意味著要耗費很多時間。雖然，操作系統通常避免這樣的情況發生，不過當其發生的時候，對性能就會有很大的影響。

當有超級多的線程準備運行時(非等待狀態)，任務切換問題就會頻繁發生。這個問題我們之前也接觸過：超額認購。

## 8.2.5 超額認購和頻繁的任務切換

多線程系統中，通常線程的數量要多於處理的數量。不過，線程經常會花費時間來等待外部I/O完成，或被互斥量阻塞，或等待條件變量，等等；所以等待不是問題。應用使用額外的線程來完成有用的工作，而非讓線程在處理器處以閒置狀態時繼續等待。

這也並非長久之計，如果有很多額外線程，就會有很多線程準備執行，而且數量遠遠大於可用處理器的數量，不過操作系統就會忙於在任務間切換，以確保每個任務都有時間運行。如第1章所見，這將增加切換任務的時間開銷，和緩存問題造成同一結果。當無限制的產生新線程，超額認購就會加劇，如第4章的遞歸快速排序那樣；或者在通過任務類型對任務進行劃分的時候，線程數量大於處理器數量，這裡對性能影響的主要來源是CPU的能力，而非I/O。

如果只是簡單的通過數據劃分生成多個線程，那可以限定工作線程的數量，如8.1.2節中那樣。如果超額認購是對工作的天然劃分而產生，那麼不同的劃分方式對這種問題就沒有太多益處了。之前的情況是，需要選擇一個合適的劃分方案，可能需要對目標平臺有著更加詳細的瞭解，不過這也只限於性能已經無法接受，或是某種劃分方式已經無法提高性能的時候。

其他因素也會影響多線程代碼的性能。即使CPU類型和時鐘週期相同，乒乓緩存的開銷可以讓程序在兩個單核處理器和在一個雙核處理器上，產生巨大的性能差，不過這只是那些對性能影響可見的因素。接下來，讓我們看一下這些因素如何影響代碼與數據結構的設計。