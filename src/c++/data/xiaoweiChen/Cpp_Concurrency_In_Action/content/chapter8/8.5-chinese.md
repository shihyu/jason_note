# 8.5 在實踐中設計併發代碼

當為一個特殊的任務設計併發代碼時，需要根據任務本身來考慮之前所提到的問題。為了展示以上的注意事項是如何應用的，我們將看一下在`C++`標準庫中三個標準函數的並行實現。當你遇到問題時，這裡的例子可以作為很好的參照。在有較大的併發任務進行輔助下，我們也將實現一些函數。

我主要演示這些實現使用的技術，不過可能這些技術並不是最先進的；更多優秀的實現可以更好的利用硬件併發，不過這些實現可能需要到與並行算法相關的學術文獻，或者是多線程的專家庫中(比如：Inter的TBB[4])才能看到。

並行版的`std::for_each`可以看作為能最直觀體現並行概念，就讓我們從並行版的`std::for_each`開始吧！

## 8.5.1 並行實現：`std::for_each`

`std::for_each`的原理很簡單：其對某個範圍中的元素，依次調用用戶提供的函數。並行和串行調用的最大區別就是函數的調用順序。`std::for_each`是對範圍中的第一個元素調用用戶函數，接著是第二個，以此類推，而在並行實現中對於每個元素的處理順序就不能保證了，並且它們可能(我們希望如此)被併發的處理。

為了實現這個函數的並行版本，需要對每個線程上處理的元素進行劃分。你事先知道元素數量，所以可以處理前對數據進行劃分(詳見8.1.1節)。假設只有並行任務運行，就可以使用`std::thread::hardware_concurrency()`來決定線程的數量。同樣，這些元素都能被獨立的處理，所以可以使用連續的數據塊來避免偽共享(詳見8.2.3節)。

這裡的算法有點類似於並行版的`std::accumulate`(詳見8.4.1節)，不過比起計算每一個元素的加和，這裡對每個元素僅僅使用了一個指定功能的函數。因為不需要返回結果，可以假設這可能會對簡化代碼，不過想要將異常傳遞給調用者，就需要使用`std::packaged_task`和`std::future`機制對線程中的異常進行轉移。這裡展示一個樣本實現。

清單8.7 並行版`std::for_each`

```
template<typename Iterator,typename Func>
void parallel_for_each(Iterator first,Iterator last,Func f)
{
  unsigned long const length=std::distance(first,last);
  
  if(!length)
    return;

  unsigned long const min_per_thread=25;
  unsigned long const max_threads=
    (length+min_per_thread-1)/min_per_thread;

  unsigned long const hardware_threads=
    std::thread::hardware_concurrency();

  unsigned long const num_threads=
    std::min(hardware_threads!=0?hardware_threads:2,max_threads);

  unsigned long const block_size=length/num_threads;

  std::vector<std::future<void> > futures(num_threads-1);  // 1
  std::vector<std::thread> threads(num_threads-1);
  join_threads joiner(threads);

  Iterator block_start=first;
  for(unsigned long i=0;i<(num_threads-1);++i)
  {
    Iterator block_end=block_start;
    std::advance(block_end,block_size);
    std::packaged_task<void(void)> task(  // 2
      [=]()
      {
        std::for_each(block_start,block_end,f);
      });
    futures[i]=task.get_future();
    threads[i]=std::thread(std::move(task));  // 3
    block_start=block_end;
  }
  std::for_each(block_start,last,f);
  for(unsigned long i=0;i<(num_threads-1);++i)
  {
    futures[i].get();  // 4
  }
}
```

代碼結構與清單8.4的差不多。最重要的不同在於futures向量對`std::future<void>`類型①變量進行存儲，因為工作線程不會返回值，並且簡單的lambda函數會對block_start到block_end上的任務②執行f函數。這是為了避免傳入線程的構造函數③。當工作線程不需要返回一個值時，調用futures[i].get()④只是提供檢索工作線程異常的方法；如果不想把異常傳遞出去，就可以省略這一步。

實現並行`std::accumulate`的時候，使用`std::async`會簡化代碼；同樣，parallel_for_each也可以使用`std::async`。實現如下所示。

清單8.8 使用`std::async`實現`std::for_each`

```
template<typename Iterator,typename Func>
void parallel_for_each(Iterator first,Iterator last,Func f)
{
  unsigned long const length=std::distance(first,last);

  if(!length)
    return;

  unsigned long const min_per_thread=25;

  if(length<(2*min_per_thread))
  {
    std::for_each(first,last,f);  // 1
  }
  else
  {
    Iterator const mid_point=first+length/2;
    std::future<void> first_half=  // 2
      std::async(&parallel_for_each<Iterator,Func>,
                 first,mid_point,f);
    parallel_for_each(mid_point,last,f);  // 3
    first_half.get();  // 4
  }
}
```

和基於`std::async`的parallel_accumulate(清單8.5)一樣，是在運行時對數據進行迭代劃分的，而非在執行前劃分好，這是因為你不知道你的庫需要使用多少個線程。像之前一樣，當你將每一級的數據分成兩部分，異步執行另外一部分②，剩下的部分就不能再進行劃分了，所以直接運行這一部分③；這樣就可以直接對`std::for_each`①進行使用了。這裡再次使用`std::async`和`std::future`的get()成員函數④來提供對異常的傳播。

回到算法，函數需要對每一個元素執行同樣的操作(這樣的操作有很多種，初學者可能會想到`std::count`和`std::replace`)，一個稍微複雜一些的例子就是使用`std::find`。

## 8.5.2 並行實現：`std::find`

接下來是`std::find`算法，因為這是一種不需要對數據元素做任何處理的算法。比如，當第一個元素就滿足查找標準，那就沒有必要對其他元素進行搜索了。將會看到，算法屬性對於性能具有很大的影響，並且對並行實現的設計有著直接的影響。這個算法是一個很特別的例子，數據訪問模式都會對代碼的設計產生影響(詳見8.3.2節)。該類中的另一些算法包括`std::equal`和`std::any_of`。

當你和妻子或者搭檔，在一個紀念盒中找尋一張老照片，當找到這張照片時，就不會再看另外的照片了。不過，你得讓其他人知道你已經找到照片了(比如，大喊一聲“找到了！”)，這樣其他人就會停止搜索了。很多算法的特性就是要對每一個元素進行處理，所以它們沒有辦法像`std::find`一樣，一旦找到合適數據就停止執行。因此，你需要設計代碼對其進行使用——當得到想要的答案就中斷其他任務的執行，所以不能等待線程處理對剩下的元素進行處理。

如果不中斷其他線程，那麼串行版本的性能可能會超越並行版，因為串行算法可以在找到匹配元素的時候，停止搜索並返回。如果系統能支持四個併發線程，那麼每個線程就可以對總數據量的1/4進行檢查，並且在我們的實現只需要單核完成的1/4的時間，就能完成對所有元素的查找。如果匹配的元素在第一個1/4塊中，串行算法將會返回第一個，因為算法不需要對剩下的元素進行處理了。

一種辦法，中斷其他線程的一個辦法就是使用一個原子變量作為一個標識，在處理過每一個元素後就對這個標識進行檢查。如果標識被設置，那麼就有線程找到了匹配元素，所以算法就可以停止並返回了。用這種方式來中斷線程，就可以將那些沒有處理的數據保持原樣，並且在更多的情況下，相較於串行方式，性能能提升很多。缺點就是，加載原子變量是一個很慢的操作，會阻礙每個線程的運行。

如何返回值和傳播異常呢？現在你有兩個選擇。你可以使用一個future數組，使用`std::packaged_task`來轉移值和異常，在主線程上對返回值和異常進行處理；或者使用`std::promise`對工作線程上的最終結果直接進行設置。這完全依賴於你想怎麼樣處理工作線程上的異常。如果想停止第一個異常(即使還沒有對所有元素進行處理)，就可以使用`std::promise`對異常和最終值進行設置。另外，如果想要讓其他工作線程繼續查找，可以使用`std::packaged_task`來存儲所有的異常，當線程沒有找到匹配元素時，異常將再次拋出。

這種情況下，我會選擇`std::promise`，因為其行為和`std::find`更為接近。這裡需要注意一下搜索的元素是不是在提供的搜索範圍內。因此，在所有線程結束前，獲取future上的結果。如果被future阻塞住，所要查找的值不在範圍內，就會持續的等待下去。實現代碼如下。

清單8.9 並行find算法實現

```
template<typename Iterator,typename MatchType>
Iterator parallel_find(Iterator first,Iterator last,MatchType match)
{
  struct find_element  // 1
  {
    void operator()(Iterator begin,Iterator end,
                    MatchType match,
                    std::promise<Iterator>* result,
                    std::atomic<bool>* done_flag)
    {
      try
      {
        for(;(begin!=end) && !done_flag->load();++begin)  // 2
        {
          if(*begin==match)
          {
            result->set_value(begin);  // 3
            done_flag->store(true);  // 4
            return;
          }
        }
      }
      catch(...)  // 5
      {
        try
        {
          result->set_exception(std::current_exception());  // 6
          done_flag->store(true);
        }
        catch(...)  // 7
        {}
      }
    }
  };

  unsigned long const length=std::distance(first,last);

  if(!length)
    return last;

  unsigned long const min_per_thread=25;
  unsigned long const max_threads=
    (length+min_per_thread-1)/min_per_thread;

  unsigned long const hardware_threads=
    std::thread::hardware_concurrency();

  unsigned long const num_threads=
    std::min(hardware_threads!=0?hardware_threads:2,max_threads);

  unsigned long const block_size=length/num_threads;

  std::promise<Iterator> result;  // 8
  std::atomic<bool> done_flag(false);  // 9
  std::vector<std::thread> threads(num_threads-1);
  {  // 10
    join_threads joiner(threads);
    
    Iterator block_start=first;
    for(unsigned long i=0;i<(num_threads-1);++i)
    {
      Iterator block_end=block_start;
      std::advance(block_end,block_size);
      threads[i]=std::thread(find_element(),  // 11
                             block_start,block_end,match,
                             &result,&done_flag);
      block_start=block_end;
    }
    find_element()(block_start,last,match,&result,&done_flag);  // 12
  }
  if(!done_flag.load())  //13
  {
    return last;
  }
  return result.get_future().get();  // 14
}
```

清單8.9中的函數主體與之前的例子相似。這次，由find_element類①的函數調用操作實現，來完成查找工作的。循環通過在給定數據塊中的元素，檢查每一步上的標識②。如果匹配的元素被找到，就將最終的結果設置到promise③當中，並且在返回前對done_flag④進行設置。

如果有一個異常被拋出，那麼它就會被通用處理代碼⑤捕獲，並且在promise⑥嘗中試存儲前，對done_flag進行設置。如果對應promise已經被設置，設置在promise上的值可能會拋出一個異常，所以這裡⑦發生的任何異常，都可以捕獲並丟棄。

這意味著，當線程調用find_element查詢一個值，或者拋出一個異常時，如果其他線程看到done_flag被設置，那麼其他線程將會終止。如果多線程同時找到匹配值或拋出異常，它們將會對promise產生競爭。不過，這是良性的條件競爭；因為，成功的競爭者會作為“第一個”返回線程，因此這個結果可以接受。

回到parallel_find函數本身，其擁有用來停止搜索的promise⑧和標識⑨；隨著對範圍內的元素的查找⑪，promise和標識會傳遞到新線程中。主線程也使用find_element來對剩下的元素進行查找⑫。像之前提到的，需要在全部線程結束前，對結果進行檢查，因為結果可能是任意位置上的匹配元素。這裡將“啟動-匯入”代碼放在一個塊中⑩，所以所有線程都會在找到匹配元素時⑬進行匯入。如果找到匹配元素，就可以調用`std::future<Iterator>`(來自promise⑭)的成員函數get()來獲取返回值或異常。

不過，這裡假設你會使用硬件上所有可用的的併發線程，或使用其他機制對線程上的任務進行提前劃分。就像之前一樣，可以使用`std::async`，以及遞歸數據劃分的方式來簡化實現(同時使用`C++`標準庫中提供的自動縮放工具)。使用`std::async`的parallel_find實現如下所示。

清單8.10 使用`std::async`實現的並行find算法

```
template<typename Iterator,typename MatchType>  // 1
Iterator parallel_find_impl(Iterator first,Iterator last,MatchType match,
                            std::atomic<bool>& done)
{
  try
  {
    unsigned long const length=std::distance(first,last);
    unsigned long const min_per_thread=25;  // 2
    if(length<(2*min_per_thread))  // 3
    {
      for(;(first!=last) && !done.load();++first)  // 4
      {
        if(*first==match)
        {
          done=true;  // 5
          return first;
        }
      }
      return last;  // 6
    }
    else
    { 
      Iterator const mid_point=first+(length/2);  // 7
      std::future<Iterator> async_result=
        std::async(&parallel_find_impl<Iterator,MatchType>,  // 8
                   mid_point,last,match,std::ref(done));
      Iterator const direct_result=
        parallel_find_impl(first,mid_point,match,done);  // 9
      return (direct_result==mid_point)?
        async_result.get():direct_result;  // 10
    }
  }
  catch(...)
  {
    done=true;  // 11
    throw;
  }
}

template<typename Iterator,typename MatchType>
Iterator parallel_find(Iterator first,Iterator last,MatchType match)
{
  std::atomic<bool> done(false);
  return parallel_find_impl(first,last,match,done);  // 12
}
```

如果想要在找到匹配項時結束，就需要在線程之間設置一個標識來表明匹配項已經被找到。因此，需要將這個標識遞歸的傳遞。通過函數①的方式來實現是最簡單的辦法，只需要增加一個參數——一個done標識的引用，這個表示通過程序的主入口點傳入⑫。

核心實現和之前的代碼一樣。通常函數的實現中，會讓單個線程處理最少的數據項②；如果數據塊大小不足於分成兩半，就要讓當前線程完成所有的工作了③。實際算法在一個簡單的循環當中(給定範圍)，直到在循環到指定範圍中的最後一個，或找到匹配項，並對標識進行設置④。如果找到匹配項，標識done就會在返回前進行設置⑤。無論是因為已經查找到最後一個，還是因為其他線程對done進行了設置，都會停止查找。如果沒有找到，會將最後一個元素last進行返回⑥。

如果給定範圍可以進行劃分，首先要在`st::async`在對第二部分進行查找⑧前，要找數據中點⑦，而且需要使用`std::ref`將done以引用的方式傳遞。同時，可以通過對第一部分直接進行遞歸查找。兩部分都是異步的，並且在原始範圍過大時，直接遞歸查找的部分可能會再細化。

如果直接查找返回的是mid_point，這就意味著沒有找到匹配項，所以就要從異步查找中獲取結果。如果在另一半中沒有匹配項的話，返回的結果就一定是last，這個值的返回就代表了沒有找到匹配的元素⑩。如果“異步”調用被延遲(非真正的異步)，那麼實際上這裡會運行get()；這種情況下，如果對下半部分的元素搜索成功，那麼就不會執行對上半部分元素的搜索了。如果異步查找真實的運行在其他線程上，那麼async_result變量的析構函數將會等待該線程完成，所以這裡不會有線程洩露。

像之前一樣，`std::async`可以用來提供“異常-安全”和“異常-傳播”特性。如果直接遞歸拋出異常，future的析構函數就能讓異步執行的線程提前結束；如果異步調用拋出異常，那麼這個異常將會通過對get()成員函數的調用進行傳播⑩。使用*try/catch*塊只能捕捉在done發生的異常，並且當有異常拋出⑪時，所有線程都能很快的終止運行。不過，不使用*try/catch*的實現依舊沒問題，不同的就是要等待所有線程的工作是否完成。

實現中一個重要的特性就是，不能保證所有數據都能被`std::find`串行處理。其他並行算法可以借鑑這個特性，因為要讓一個算法並行起來這是必須具有的特性。如果有順序問題，元素就不能併發的處理了。如果每個元素獨立，雖然對於parallel_for_each不是很重要，不過對於parallel_find，即使在開始部分已經找到了匹配元素，也有可能返回範圍中最後一個元素；如果在知道結果的前提下，這樣的結果會讓人很驚訝。

OK，現在你已經使用了並行化的`std::find`。如在本節開始說的那樣，其他相似算法不需要對每一個數據元素進行處理，並且同樣的技術可以使用到這些類似的算法上去。我們將在第9章中看到“中斷線程”的問題。

為了完成我們的並行“三重奏”，我們將換一個角度來看一下`std::partial_sum`。對於這個算法，沒有太多的文獻可參考，不過讓這個算法並行起來是一件很有趣的事。

## 8.5.3 並行實現：`std::partial_sum`

`std::partial_sum`會計算給定範圍中的每個元素，並用計算後的結果將原始序列中的值替換掉。比如，有一個序列[1，2，3，4，5]，在執行該算法後會成為：[1，3(1+2)，6(1+2+3)，10(1+2+3+4)，15(1+2+3+4+5)]。讓這樣一個算法並行起來會很有趣，因為這裡不能講任務分塊，對每一塊進行獨立的計算。比如，原始序列中的第一個元素需要加到後面的一個元素中去。

確定某個範圍部分和的一種的方式，就是在獨立塊中計算部分和，然後將第一塊中最後的元素的值，與下一塊中的所有元素進行相加，依次類推。如果有個序列[1，2，3，4，5，6，7，8，9]，然後將其分為三塊，那麼在第一次計算後就能得到[{1，3，6}，{4，9，15}，{7，15，24}]。然後將6(第一塊的最後一個元素)加到第二個塊中，那麼就得到[{1，3，6}，{10，15，21}，{7，15，24}]。然後再將第二塊的最後一個元素21加到第三塊中去，就得到[{1，3，6}，{10，15，21}，{28，36，55}]。

將原始數據分割成塊，加上之前塊的部分和就能夠並行了。如果每個塊中的末尾元素都是第一個被更新的，那麼塊中其他的元素就能被其他線程所更新，同時另一個線程對下一塊進行更新，等等。當處理的元素比處理核心的個數多的時候，這樣完成工作沒問題，因為每一個核芯在每一個階段都有合適的數據可以進行處理。

如果有很多的處理器(就是要比處理的元素個數多)，那麼之前的方式就無法正常工作了。如果還是將工作劃分給每個處理器，那麼在第一步就沒必要去做了。這種情況下，傳遞結果就意味著讓處理器進行等待，這時需要給這些處於等待中的處理器一些工作。所以，可以採用完全不同的方式來處理這個問題。比起將數據塊中的最後一個元素的結果向後面的元素塊傳遞，可以對部分結果進行傳播：第一次與相鄰的元素(距離為1)相加和(和之前一樣)，之後和距離為2的元素相加，在後來和距離為4的元素相加，以此類推。比如，初始序列為[1，2，3，4，5，6，7，8，9]，第一次後為[1，3，5，7，9，11，13，15，17]，第二次後為[1，3，6，10，14，18, 22，26，30]，下一次就要隔4個元素了。第三次後[1, 3, 6, 10, 15, 21, 28, 36, 44]，下一次就要隔8個元素了。第四次後[1, 3, 6, 10, 15, 21, 28, 36, 45]，這就是最終的結果。雖然，比起第一種方法多了很多步驟，不過在可併發平臺下，這種方法提高了並行的可行性；每個處理器可在每一步中處理一個數據項。

總體來說，當有N個操作時(每步使用一個處理器)第二種方法需要log(N)[底為2]步；在本節中，N就相當於數據鏈表的長度。比起第一種，每個線程對分配塊做N/k個操作，然後在做N/k次結果傳遞(這裡的k是線程的數量)。因此，第一種方法的時間複雜度為O(N)，不過第二種方法的時間複雜度為Q(Nlog(N))。當數據量和處理器數量相近時，第二種方法需要每個處理器上log(N)個操作，第一種方法中每個處理器上執行的操作數會隨著k的增加而增多，因為需要對結果進行傳遞。對於處理單元較少的情況，第一種方法會比較合適；對於大規模並行系統，第二種方法比較合適。

不管怎麼樣，先將效率問題放一邊，讓我們來看一些代碼。下面清單實現的，就是第一種方法。

清單8.11 使用劃分的方式來並行的計算部分和

```
template<typename Iterator>
void parallel_partial_sum(Iterator first,Iterator last)
{
  typedef typename Iterator::value_type value_type;
  
  struct process_chunk  // 1
  {
    void operator()(Iterator begin,Iterator last,
                    std::future<value_type>* previous_end_value,
                    std::promise<value_type>* end_value)
    {
      try
      {
        Iterator end=last;
        ++end;
        std::partial_sum(begin,end,begin);  // 2
        if(previous_end_value)  // 3
        {
          value_type& addend=previous_end_value->get();  // 4
          *last+=addend;  // 5
          if(end_value)
          {
            end_value->set_value(*last);  // 6
          }
          std::for_each(begin,last,[addend](value_type& item)  // 7
                        {
                          item+=addend;
                        });
         }
         else if(end_value)
         {
           end_value->set_value(*last);  // 8
         }
       }
       catch(...)  // 9
       {
         if(end_value)
         {
           end_value->set_exception(std::current_exception());  // 10
         }
         else
         {
           throw;  // 11
         }
       }
     }
   };

  unsigned long const length=std::distance(first,last);

  if(!length)
    return last;

  unsigned long const min_per_thread=25;  // 12
  unsigned long const max_threads=
    (length+min_per_thread-1)/min_per_thread;

  unsigned long const hardware_threads=
    std::thread::hardware_concurrency();

  unsigned long const num_threads=
    std::min(hardware_threads!=0?hardware_threads:2,max_threads);

  unsigned long const block_size=length/num_threads;

  typedef typename Iterator::value_type value_type;

  std::vector<std::thread> threads(num_threads-1);  // 13
  std::vector<std::promise<value_type> >
    end_values(num_threads-1);  // 14
  std::vector<std::future<value_type> >
    previous_end_values;  // 15
  previous_end_values.reserve(num_threads-1);  // 16
  join_threads joiner(threads);

  Iterator block_start=first;
  for(unsigned long i=0;i<(num_threads-1);++i)
  {
    Iterator block_last=block_start;
    std::advance(block_last,block_size-1);  // 17
    threads[i]=std::thread(process_chunk(),  // 18
                           block_start,block_last,
                           (i!=0)?&previous_end_values[i-1]:0,
                           &end_values[i]);
    block_start=block_last;
    ++block_start;  // 19
    previous_end_values.push_back(end_values[i].get_future());  // 20
  }
  Iterator final_element=block_start;
  std::advance(final_element,std::distance(block_start,last)-1);  // 21
  process_chunk()(block_start,final_element,  // 22
                  (num_threads>1)?&previous_end_values.back():0,
                  0);
}
```

這個實現中，使用的結構體和之前算法中的一樣，將問題進行分塊解決，每個線程處理最小的數據塊⑫。其中，有一組線程⑬和一組promise⑭，用來存儲每塊中的最後一個值；並且實現中還有一組future⑮，用來對前一塊中的最後一個值進行檢索。可以為future⑯做些儲備，以避免生成新線程時，再分配內存。

主循環和之前一樣，不過這次是讓迭代器指向了每個數據塊的最後一個元素，而不是作為一個普通值傳遞到最後⑰，這樣就方便向其他塊傳遞當前塊的最後一個元素了。實際處理是在process_chunk函數對象中完成的，這個結構體看上去不是很長；當前塊的開始和結束迭代器和前塊中最後一個值的future一起，作為參數進行傳遞，並且promise用來保留當前範圍內最後一個值的原始值⑱。

生成新的線程後，就對開始塊的ID進行更新，別忘了傳遞最後一個元素⑲，並且將當前塊的最後一個元素存儲到future，上面的數據將在循環中再次使用到⑳。

在處理最後一個數據塊前，需要獲取之前數據塊中最後一個元素的迭代器(21)，這樣就可以將其作為參數傳入process_chunk(22)中了。`std::partial_sum`不會返回一個值，所以在最後一個數據塊被處理後，就不用再做任何事情了。當所有線程的操作完成時，求部分和的操作也就算完成了。

OK，現在來看一下process_chunk函數對象①。對於整塊的處理是始於對`std::partial_sum`的調用，包括對於最後一個值的處理②，不過得要知道當前塊是否是第一塊③。如果當前塊不是第一塊，就會有一個previous_end_value值從前面的塊傳過來，所以這裡需要等待這個值的產生④。為了將算法最大程度的並行，首先需要對最後一個元素進行更新⑤，這樣你就能將這個值傳遞給下一個數據塊(如果有下一個數據塊的話)⑥。當完成這個操作，就可以使用`std::for_each`和簡單的lambda函數⑦對剩餘的數據項進行更新。

如果previous_end_value值為空，當前數據塊就是第一個數據塊，所以只需要為下一個數據塊更新end_value⑧(如果有下一個數據塊的話——當前數據塊可能是唯一的數據塊)。

最後，如果有任意一個操作拋出異常，就可以將其捕獲⑨，並且存入promise⑩，如果下一個數據塊嘗試獲取前一個數據塊的最後一個值④時，異常會再次拋出。處理最後一個數據塊時，異常會全部重新拋出⑪，因為拋出動作一定會在主線程上進行。

因為線程間需要同步，這裡的代碼就不容易使用`std::async`重寫。任務等待會讓線程中途去執行其他的任務，所以所有的任務必須同時執行。

基於塊，以傳遞末尾元素值的方法就介紹到這裡，讓我們來看一下第二種計算方式。

**實現以2的冪級數為距離部分和算法**

第二種算法通過增加距離的方式，讓更多的處理器充分發揮作用。在這種情況下，沒有進一步同步的必要了，因為所有中間結果都直接傳遞到下一個處理器上去了。不過，在實際中我們很少見到，單個處理器處理對一定數量的元素執行同一條指令，這種方式成為*單指令-多數據流*(SIMD)。因此，代碼必須能處理通用情況，並且需要在每步上對線程進行顯式同步。

完成這種功能的一種方式是使用*柵欄*(barrier)——一種同步機制：只有所有線程都到達柵欄處，才能進行之後的操作；先到達的線程必須等待未到達的線程。`C++`11標準庫沒有直接提供這樣的工具，所以你得自行設計一個。

試想遊樂場中的過山車。如果有適量的遊客在等待，那麼過山車管理員就要保證，在過山車啟動前，每一個位置都得坐一個遊客。柵欄的工作原理也一樣：你已經知道了“座位”的數量，線程就是要等待所有“座位”都坐滿。當等待線程夠數，那麼它們可以繼續運行；這時，柵欄會重置，並且會讓下一撥線程開始扥帶。通常，會在循環中這樣做，當同一個線程再次到達柵欄處，它會再次等待。這種方法是為了讓線程同步，所以不會有線程在其他未完成的情況下，就去完成下一個任務。如果有線程提前執行，對於這樣一個算法，就是一場災難，因為提前出發的線程可能會修改要被其他線程使用到的數據，後面線程獲取到的數據就不是正確數據了。

下面的代碼就簡單的實現了一個柵欄。

清單8.12 簡單的柵欄類

```
class barrier
{
  unsigned const count;
  std::atomic<unsigned> spaces;
  std::atomic<unsigned> generation;
public:
  explicit barrier(unsigned count_):  // 1
    count(count_),spaces(count),generation(0)
  {}

  void wait()
  {
    unsigned const my_generation=generation;  // 2
    if(!--spaces)  // 3
    {
      spaces=count;  // 4
      ++generation;  // 5
    }
    else
    {
      while(generation==my_generation)  // 6
        std::this_thread::yield();  // 7
    }
  }
};
```

這個實現中，用一定數量的“座位”構造了一個barrier①，這個數量將會存儲count變量中。起初，柵欄中的spaces與count數量相當。當有線程都在等待時，spaces的數量就會減少③。當spaces的數量減到0時，spaces的值將會重置為count④，並且generation變量會增加，以向線程發出信號，讓這些等待線程能夠繼續運行⑤。如果spaces沒有到達0，那麼線程會繼續等待。這個實現使用了一個簡單的自旋鎖⑥，對generation的檢查會在wait()開始的時候進行②。因為generation只會在所有線程都到達柵欄的時候更新⑤，在等待的時候使用yield()⑦就不會讓CPU處於忙等待的狀態。

這個實現比較“簡單”的真實意義：使用自旋等待的情況下，如果讓線程等待很長時間就不會很理想，並且如果超過count數量的線程對wait()進行調用，這個實現就沒有辦法工作了。如果想要很好的處理這樣的情況，必須使用一個更加健壯(更加複雜)的實現。我依舊堅持對原子變量操作順序的一致性，因為這會讓事情更加簡單，不過有時還是需要放鬆這樣的約束。全局同步對於大規模並行架構來說是消耗巨大的，因為相關處理器會穿梭於存儲柵欄狀態的緩存行中(可見8.2.2中對乒乓緩存的討論)，所以需要格外的小心，來確保使用的是最佳同步方法。

不論怎麼樣，這些都需要你考慮到；需要有固定數量的線程執行同步循環。好吧，大多數情況下線程數量都是固定的。你可能還記得，代碼起始部分的幾個數據項，只需要幾步就能得到其最終值。這就意味著，無論是讓所有線程循環處理範圍內的所有元素，還是讓柵欄來同步線程，都會遞減count的值。我會選擇後者，因為其能避免線程做不必要的工作，僅僅是等待最終步驟完成。

這意味著你要將count改為一個原子變量，這樣在多線程對其進行更新的時候，就不需要添加額外的同步：

```
std::atomic<unsigned> count;
```

初始化保持不變，不過當spaces的值被重置後，你需要顯式的對count進行load()操作：

```
spaces=count.load();
```

這就是要對wait()函數的改動；現在需要一個新的成員函數來遞減count。這個函數命名為done_waiting()，因為當一個線程完成其工作，並在等待的時候，才能對其進行調用它：

```
void done_waiting()
{
  --count;  // 1
  if(!--spaces)  // 2
  {
    spaces=count.load();  // 3
    ++generation;
  }
}
```

實現中，首先要減少count①，所以下一次spaces將會被重置為一個較小的數。然後，需要遞減spaces的值②。如果不做這些操作，有些線程將會持續等待，因為spaces被舊的count初始化，大於期望值。一組當中最後一個線程需要對計數器進行重置，並且遞增generation的值③，就像在wait()裡面做的那樣。最重要的區別：最後一個線程不需要等待。當最後一個線程結束，整個等待也就隨之結束！

現在就準備開始寫部分和的第二個實現吧。在每一步中，每一個線程都在柵欄出調用wait()，來保證線程所處步驟一致，並且當所有線程都結束，那麼最後一個線程會調用done_waiting()來減少count的值。如果使用兩個緩存對原始數據進行保存，柵欄也可以提供你所需要的同步。每一步中，線程都會從原始數據或是緩存中讀取數據，並且將新值寫入對應位置。如果有線程先從原始數據處獲取數據，那下一步就從緩存上獲取數據(或相反)。這就能保證在讀與寫都是由獨立線程完成，並不存在條件競爭。當線程結束等待循環，就能保證正確的值最終被寫入到原始數據當中。下面的代碼就是這樣的實現。

清單8.13 通過兩兩更新對的方式實現partial_sum

```
struct barrier
{
  std::atomic<unsigned> count;
  std::atomic<unsigned> spaces;
  std::atomic<unsigned> generation;

  barrier(unsigned count_):
    count(count_),spaces(count_),generation(0)
  {}

  void wait()
  {
    unsigned const gen=generation.load();
    if(!--spaces)
    {
      spaces=count.load();
      ++generation;
    }
    else
    {
      while(generation.load()==gen)
      {
        std::this_thread::yield();
      }
    }
  }

  void done_waiting()
  {
    --count;
    if(!--spaces)
    {
      spaces=count.load();
      ++generation;
    }
  }
};

template<typename Iterator>
void parallel_partial_sum(Iterator first,Iterator last)
{
  typedef typename Iterator::value_type value_type;

  struct process_element  // 1
  {
    void operator()(Iterator first,Iterator last,
                    std::vector<value_type>& buffer,
                    unsigned i,barrier& b)
    {
      value_type& ith_element=*(first+i);
      bool update_source=false;

      for(unsigned step=0,stride=1;stride<=i;++step,stride*=2)
      {
        value_type const& source=(step%2)?  // 2
          buffer[i]:ith_element;

        value_type& dest=(step%2)?
          ith_element:buffer[i];

        value_type const& addend=(step%2)?  // 3
          buffer[i-stride]:*(first+i-stride);

        dest=source+addend;  // 4
        update_source=!(step%2);
        b.wait();  // 5
      }
      if(update_source)  // 6
      {
        ith_element=buffer[i];
      }
      b.done_waiting();  // 7
    }
  };

  unsigned long const length=std::distance(first,last);
  
  if(length<=1)
    return;

  std::vector<value_type> buffer(length);
  barrier b(length);

  std::vector<std::thread> threads(length-1);  // 8
  join_threads joiner(threads);

  Iterator block_start=first;
  for(unsigned long i=0;i<(length-1);++i)
  {
    threads[i]=std::thread(process_element(),first,last,  // 9
                           std::ref(buffer),i,std::ref(b));
  }
  process_element()(first,last,buffer,length-1,b);  // 10
}
```

代碼的整體結構應該不用說了。process_element類有函數調用操作可以用來做具體的工作①，就是運行一組線程⑨，並將線程存儲到vector中⑧，同樣還需要在主線程中對其進行調用⑩。這裡與之前最大的區別就是，線程的數量是根據列表中的數據量來定的，而非根據`std::thread::hardware_concurrency`。如我之前所說，除非你使用的是一個大規模並行的機器，因為這上面的線程都十分廉價(雖然這樣的方式並不是很好)，還能為我們展示了其整體結構。這個結構在有較少線程的時候，每一個線程只能處理源數據中的部分數據，當沒有足夠的線程支持該結構時，效率要比傳遞算法低。

不管怎樣，主要的工作都是調用process_element的函數操作符來完成的。每一步，都會從原始數據或緩存中獲取第i個元素②，並且將獲取到的元素加到指定stride的元素中去③，如果從原始數據開始讀取的元素，加和後的數需要存儲在緩存中④。然後，在開始下一步前，會在柵欄處等待⑤。當stride超出了給定數據的範圍，當最終結果已經存在緩存中時，就需要更新原始數據中的數據，同樣這也意味著本次加和結束。最後，在調用柵欄中的done_waiting()函數⑦。

注意這個解決方案並不是異常安全的。如果某個線程在process_element執行時拋出一個異常，其就會終止整個應用。這裡可以使用一個`std::promise`來存儲異常，就像在清單8.9中parallel_find的實現，或僅使用一個被互斥量保護的`std::exception_ptr`即可。

總結下這三個例子。希望其能保證我們瞭解8.1、8.2、8.3和8.4節中提到的設計考量，並且證明了這些技術在真實的代碼中，需要承擔些什麼責任。

---------

[4] http://threadingbuildingblocks.org/