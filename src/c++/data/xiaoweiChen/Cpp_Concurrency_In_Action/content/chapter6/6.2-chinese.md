# 6.2 基於鎖的併發數據結構

基於鎖的併發數據結構設計，需要確保訪問線程持有鎖的時間最短。對於只有一個互斥量的數據結構來說，這十分困難。需要保證數據不被鎖之外的操作所訪問到，並且還要保證不會在固有結構上產生條件競爭(如第3章所述)。當你使用多個互斥量來保護數據結構中不同的區域時，問題會暴露的更加明顯，當操作需要獲取多個互斥鎖時，就有可能產生死鎖。所以，在設計時，使用多個互斥量時需要格外小心。

在本節中，你將使用6.1.1節中的指導建議，來設計一些簡單的數據結構——使用互斥量和鎖的方式來保護數據。每一個例子中，都是在保證數據結構是線程安全的前提下，對數據結構併發訪問的概率(機會)進行提高。

我們先來看看在第3章中*棧*的實現，這個實現就是一個十分簡單的數據結構，它只使用了一個互斥量。但是，這個結構是線程安全的嗎？它離真正的併發訪問又有多遠呢？

## 6.2.1 線程安全棧——使用鎖

我們先把第3章中線程安全的棧拿過來看看：(這裡試圖實現一個線程安全版的`std:stack<>`)

清單6.1 線程安全棧的類定義

```
#include <exception>

struct empty_stack: std::exception
{
  const char* what() const throw();
};

template<typename T>
class threadsafe_stack
{
private:
  std::stack<T> data;
  mutable std::mutex m;
public:
  threadsafe_stack(){}
  threadsafe_stack(const threadsafe_stack& other)
  {
    std::lock_guard<std::mutex> lock(other.m);
    data=other.data;
  }

  threadsafe_stack& operator=(const threadsafe_stack&) = delete;

  void push(T new_value)
  {
    std::lock_guard<std::mutex> lock(m);
    data.push(std::move(new_value));  // 1
  }
  std::shared_ptr<T> pop()
  {
    std::lock_guard<std::mutex> lock(m);
    if(data.empty()) throw empty_stack();  // 2
    std::shared_ptr<T> const res(
      std::make_shared<T>(std::move(data.top())));  // 3
    data.pop();  // 4
    return res;
  }
  void pop(T& value)
  {
    std::lock_guard<std::mutex> lock(m);
    if(data.empty()) throw empty_stack();
    value=std::move(data.top());  // 5
    data.pop();  // 6
  }
  bool empty() const
  {
    std::lock_guard<std::mutex> lock(m);
    return data.empty();
  }
};
```

來看看指導意見是如何應用的。

首先，互斥量m能保證基本的線程安全，那就是對每個成員函數進行加鎖保護。這就保證在同一時間內，只有一個線程可以訪問到數據，所以能夠保證，數據結構的“不變量”被破壞時，不會被其他線程看到。

其次，在empty()和pop()成員函數之間會存在潛在的競爭，不過代碼會在pop()函數上鎖時，顯式的查詢棧是否為空，所以這裡的競爭是非惡性的。pop()通過對彈出值的直接返回，就可避免`std::stack<>`中top()和pop()兩成員函數之間的潛在競爭。

再次，這個類中也有一些異常源。對互斥量上鎖可能會拋出異常，因為上鎖操作是每個成員函數所做的第一個操作，所以這是極其罕見的(因為這意味這問題不在鎖上，就是在系統資源上)。因無數據修改，所以其是安全的。因解鎖一個互斥量是不會失敗的，所以段代碼很安全，並且使用`std::lock_guard<>`也能保證互斥量上鎖的狀態。

對data.push()①的調用可能會拋出一個異常，不是拷貝/移動數據值時，就是內存不足的時候。不管是哪種，`std::stack<>`都能保證其實安全的，所以這裡也沒有問題。

在第一個重載pop()中，代碼可能會拋出一個empty_stack的異常②，不過數據沒有被修改，所以其是安全的。對於res的創建③，也可能會拋出一個異常，這有兩方面的原因：對`std::make_shared`的調用，可能無法分配出足夠的內存去創建新的對象，並且內部數據需要對新對象進行引用；或者，在拷貝或移動構造到新分配的內存中返回時拋出異常。兩種情況下，c++運行庫和標準庫能確保這裡不會出現內存洩露，並且新創建的對象(如果有的話)都能被正確銷燬。因為沒有對棧進行任何修改，所以這裡也不會有問題。當調用data.pop()④時，其能確保不拋出異常，並且返回結果，所以這個重載pop()函數“異常-安全”。

第二個重載pop()類似，除了在拷貝賦值或移動賦值的時候會拋出異常⑤，當構造一個新對象和一個`std::shared_ptr`實例時都不會拋出異常。同樣，在調用data.pop()⑥（這個成員函數保證不會拋出異常）之前，依舊沒有對數據結構進行修改，所以這個函數也為“異常-安全”。

最後，empty()也不會修改任何數據，所以也是“異常-安全”函數。

當調用持有一個鎖的用戶代碼時，這裡有兩個地方可能會產生死鎖：進行拷貝構造或移動構造(①，③)和在對數據項進行拷貝賦值或移動賦值操作⑤的時候；還有一個潛在死鎖的地方在於用戶定義的操作符new。當這些函數，無論是以直接調用棧的成員函數的方式，還是在成員函數進行操作時，對已經插入或刪除的數據進行操作的方式，對鎖進行獲取，都可能造成死鎖。不過，用戶要對棧負責，當棧未對一個數據進行拷貝或分配時，用戶就不能想當然的將其添加到棧中。

所有成員函數都使用`st::lock_guard<>`來保護數據，所以棧的成員函數能有“線程安全”的表現。當然，構造與析構函數不是“線程安全”的，不過這也不成問題，因為對實例的構造與析構只能有一次。調用一個不完全構造對象或是已銷燬對象的成員函數，無論在那種編程方式下，都不可取。所以，用戶就要保證在棧對象完成構建前，其他線程無法對其進行訪問；並且，一定要保證在棧對象銷燬後，所有線程都要停止對其進行訪問。

即使在多線程情況下，併發的調用成員函數是安全的(因為使用鎖)，也要保證在單線程的情況下，數據結構做出正確反應。序列化線程會隱性的限制程序性能，這就是棧爭議聲最大的地方：當一個線程在等待鎖時，它就會無所事事。同樣的，對於棧來說，等待添加元素也是沒有意義的，所以當一個線程需要等待時，其會定期檢查empty()或pop()，以及對empty_stack異常進行關注。這樣的現實會限制棧的實現的方式，在線程等待的時候，會浪費寶貴的資源去檢查數據，或是要求用戶寫寫外部等待和提示代碼(例如，使用條件變量)，這就使內部鎖失去存在的意義——這就意味著資源的浪費。第4章中的隊列，就是一種使用條件內部變量進行等待的數據結構，接下來我們就來了解一下。

## 6.2.2 線程安全隊列——使用鎖和條件變量

第4章中的線程安全隊列，在清單6.2中重現一下。和使用仿`std::stack<>`建立的棧很像，這裡隊列的建立也是參照了`std::queue<>`。不過，與標準容器的接口不同，我們要設計的是能在多線程下安全併發訪問的數據結構。

清單6.2 使用條件變量實現的線程安全隊列

```
template<typename T>
class threadsafe_queue
{
private:
  mutable std::mutex mut;
  std::queue<T> data_queue;
  std::condition_variable data_cond;

public:
  threadsafe_queue()
  {}

  void push(T new_value)
  {
    std::lock_guard<std::mutex> lk(mut);
    data_queue.push(std::move(data));
    data_cond.notify_one();  // 1
  }

  void wait_and_pop(T& value)  // 2
  {
    std::unique_lock<std::mutex> lk(mut);
    data_cond.wait(lk,[this]{return !data_queue.empty();});
    value=std::move(data_queue.front());
    data_queue.pop();
  }

  std::shared_ptr<T> wait_and_pop()  // 3
  {
    std::unique_lock<std::mutex> lk(mut);
    data_cond.wait(lk,[this]{return !data_queue.empty();});  // 4
    std::shared_ptr<T> res(
      std::make_shared<T>(std::move(data_queue.front())));
    data_queue.pop();
    return res;
  }

  bool try_pop(T& value)
  {
    std::lock_guard<std::mutex> lk(mut);
    if(data_queue.empty())
      return false;
    value=std::move(data_queue.front());
    data_queue.pop();
    return true;
  }

  std::shared_ptr<T> try_pop()
  {
    std::lock_guard<std::mutex> lk(mut);
    if(data_queue.empty())
      return std::shared_ptr<T>();  // 5
    std::shared_ptr<T> res(
      std::make_shared<T>(std::move(data_queue.front())));
    data_queue.pop();
    return res;
  }

  bool empty() const
  {
    std::lock_guard<std::mutex> lk(mut);
    return data_queue.empty();
  }
};
```

除了在push()①中調用data_cond.notify_one()，以及wait_and_pop()②③，6.2中對隊列的實現與6.1中對棧的實現十分相近。兩個重載try_pop()除了在隊列為空時拋出異常，其他的與6.1中pop()函數完全一樣。不同的是，在6.1中對值的檢索會返回一個bool值，而在6.2中，當指針指向空值的時候會返回NULL指針⑤，這同樣也是實現棧的一個有效途徑。所以，即使排除掉wait_and_pop()函數，之前對棧的分析依舊適用於這裡。

wiat_and_pop()函數是等待隊列向棧進行輸入的一個解決方案；比起持續調用empty()，等待線程調用wait_and_pop()函數和數據結構處理等待中的條件變量的方式要好很多。對於data_cond.wait()的調用，直到隊列中有一個元素的時候，才會返回，所以你就不用擔心會出現一個空隊列的情況了，還有，數據會一直被互斥鎖保護。因為不變量這裡並未發生變化，所以函數不會添加新的條件競爭或是死鎖的可能。

異常安全在這裡的會有一些變化，當不止一個線程等待對隊列進行推送操作是，只會有一個線程，因得到data_cond.notify_one()，而繼續工作著。但是，如果這個工作線程在wait_and_pop()中拋出一個異常，例如：構造新的`std::shared_ptr<>`對象④時拋出異常，那麼其他線程則會永世長眠。當這種情況是不可接受時，這裡的調用就需要改成data_cond.notify_all()，這個函數將喚醒所有的工作線程，不過，當大多線程發現隊列依舊是空時，又會耗費很多資源讓線程重新進入睡眠狀態。第二種替代方案是，當有異常拋出的時候，讓wait_and_pop()函數調用notify_one()，從而讓個另一個線程可以去嘗試索引存儲的值。第三種替代方案就是，將`std::shared_ptr<>`的初始化過程移到push()中，並且存儲`std::shared_ptr<>`實例，而非直接使用數據的值。將`std::shared_ptr<>`拷貝到內部`std::queue<>`中，就不會拋出異常了，這樣wait_and_pop()又是安全的了。下面的程序清單，就是根據第三種方案進行修改的。

清單6.3 持有`std::shared_ptr<>`實例的線程安全隊列

```
template<typename T>
class threadsafe_queue
{
private:
  mutable std::mutex mut;
  std::queue<std::shared_ptr<T> > data_queue;
  std::condition_variable data_cond;
public:
  threadsafe_queue()
  {}

  void wait_and_pop(T& value)
  {
    std::unique_lock<std::mutex> lk(mut);
    data_cond.wait(lk,[this]{return !data_queue.empty();});
    value=std::move(*data_queue.front());  // 1
    data_queue.pop();
  }

  bool try_pop(T& value)
  {
    std::lock_guard<std::mutex> lk(mut);
    if(data_queue.empty())
      return false;
    value=std::move(*data_queue.front());  // 2
    data_queue.pop();
    return true;
  }

  std::shared_ptr<T> wait_and_pop()
  {
    std::unique_lock<std::mutex> lk(mut);
    data_cond.wait(lk,[this]{return !data_queue.empty();});
    std::shared_ptr<T> res=data_queue.front();  // 3
    data_queue.pop();
    return res;
  }

  std::shared_ptr<T> try_pop()
  {
    std::lock_guard<std::mutex> lk(mut);
    if(data_queue.empty())
      return std::shared_ptr<T>();
    std::shared_ptr<T> res=data_queue.front();  // 4
    data_queue.pop();
    return res;
  }

  void push(T new_value)
  {
    std::shared_ptr<T> data(
    std::make_shared<T>(std::move(new_value)));  // 5
    std::lock_guard<std::mutex> lk(mut);
    data_queue.push(data);
    data_cond.notify_one();
  }

  bool empty() const
  {
    std::lock_guard<std::mutex> lk(mut);
    return data_queue.empty();
  }
};
```

為讓`std::shared_ptr<>`持有數據的結果顯而易見：彈出函數會持有一個變量的引用，為了接收這個新值，必須對存儲的指針進行解引用①，②；並且，在返回到調用函數前，彈出函數都會返回一個`std::shared_ptr<>`實例，這裡實例可以在隊列中做檢索③，④。

`std::shared_ptr<>`持有數據的好處：新的實例分配結束時，不會被鎖在push()⑤當中(而在清單6.2中，只能在pop()持有鎖時完成)。因為內存分配操作的需要在性能上付出很高的代價(性能較低)，所以使用`std::shared_ptr<>`的方式對隊列的性能有很大的提升，其減少了互斥量持有的時間，允許其他線程在分配內存的同時，對隊列進行其他的操作。

如同棧的例子，使用互斥量保護整個數據結構，不過會限制隊列對併發的支持；雖然，多線程可能被隊列中的各種成員函數所阻塞，但是仍有一個線程能在任意時間內進行工作。不過，這種限制的部分來源是因為在實現中使用了`std::queue<>`；因為使用標準容器的原因，數據處於保護中。要對數據結構實現進行具體的控制，需要提供更多細粒度鎖，來完成更高級的併發。

## 6.2.3 線程安全隊列——使用細粒度鎖和條件變量

在清單6.2和6.3中，使用一個互斥量對一個*數據隊列*(data_queue)進行保護。為了使用細粒度鎖，需要看一下隊列內部的組成結構，並且將一個互斥量與每個數據相關聯。

對於隊列來說，最簡單的數據結構就是單鏈表了，就如圖6.1那樣。隊列裡包含一個頭指針，其指向鏈表中的第一個元素，並且每一個元素都會指向下一個元素。從隊列中刪除數據，其實就是將頭指針指向下一個元素，並將之前頭指針指向的值進行返回。

向隊列中添加元素是要從結尾進行的。為了做到這點，隊列裡還有一個尾指針，其指向鏈表中的最後一個元素。新節點的加入將會改變尾指針的next指針，之前最後一個元素將會指向新添加進來的元素，新添加進來的元素的next將會使新的尾指針。當鏈表為空時，頭/尾指針皆為NULL。

![](../../images/chapter6/6-1.png)

圖6.1 用單鏈表表示的隊列

下面的清單中的代碼，是一個簡單隊列的實現，基於清單6.2代碼的精簡版本；因為這個隊列僅供單線程使用，所以這實現中只有一個try_pop()函數；並且，沒有wait_and_pop()函數。

清單6.4 隊列實現——單線程版

```
template<typename T>
class queue
{
private:
  struct node
  {
    T data;
    std::unique_ptr<node> next;

    node(T data_):
    data(std::move(data_))
    {}
  };

  std::unique_ptr<node> head;  // 1
  node* tail;  // 2

public:
  queue()
  {}
  queue(const queue& other)=delete;
  queue& operator=(const queue& other)=delete;
  std::shared_ptr<T> try_pop()
  {
    if(!head)
    {
      return std::shared_ptr<T>();
    }
    std::shared_ptr<T> const res(
      std::make_shared<T>(std::move(head->data)));
    std::unique_ptr<node> const old_head=std::move(head);
    head=std::move(old_head->next);  // 3
    return res;
  }

  void push(T new_value)
  {
    std::unique_ptr<node> p(new node(std::move(new_value)));
    node* const new_tail=p.get();
    if(tail)
    {
      tail->next=std::move(p);  // 4
    }
    else
    {
      head=std::move(p);  // 5
    }
    tail=new_tail;  // 6
  }
};
```

首先，注意在清單呢6.4中使用了`std::unique_ptr<node>`來管理節點，因為其能保證節點(其引用數據的值)在刪除時候，不需要使用delete操作顯式刪除。這樣的關係鏈表，管理著從頭結點到尾節點的每一個原始指針。

雖然，這種實現對於單線程來說沒什麼問題，但是，當你在多線程情況下，嘗試使用細粒度鎖時，就會出現問題。因為在給定的實現中有兩個數據項(head①和tail②)；即使，使用兩個互斥量，來保護頭指針和尾指針，也會出現問題。

顯而易見的問題就是push()可以同時修改頭指針⑤和尾指針⑥，所以push()函數會同時獲取兩個互斥量。雖然會將兩個互斥量都上鎖，但這還不是太糟糕的問題。糟糕的問題是push()和pop()都能訪問next指針指向的節點：push()可更新tail->next④，而後try_pop()讀取read->next③。當隊列中只有一個元素時，head==tail，所以head->next和tail->next是同一個對象，並且這個對象需要保護。不過，“在同一個對象在未被head和tail同時訪問時，push()和try_pop()鎖住的是同一個鎖”，就不對了。所以，你就沒有比之間實現更好的選擇了。這裡會“柳暗花明又一村”嗎？

**通過分離數據實現併發**

你可以使用“預分配一個虛擬節點(無數據)，確保這個節點永遠在隊列的最後，用來分離頭尾指針能訪問的節點”的辦法，走出這個困境。對於一個空隊列來說，head和tail都屬於虛擬指針，而非空指針。這個辦法挺好，因為當隊列為空時，try_pop()不能訪問head->next了。當添加一個節點入隊列時(這時有真實節點了)，head和tail現在指向不同的節點，所以就不會在head->next和tail->next上產生競爭。這裡的缺點是，你必須額外添加一個間接層次的指針數據，來做虛擬節點。下面的代碼描述了這個方案如何實現。

清單6.5 帶有虛擬節點的隊列

```
template<typename T>
class queue
{
private:
  struct node
  {
    std::shared_ptr<T> data;  // 1
    std::unique_ptr<node> next;
  };

  std::unique_ptr<node> head;
  node* tail;

public:
  queue():
    head(new node),tail(head.get())  // 2
  {}
  queue(const queue& other)=delete;
  queue& operator=(const queue& other)=delete;

  std::shared_ptr<T> try_pop()
  {
    if(head.get()==tail)  // 3
    {
      return std::shared_ptr<T>();
    }
    std::shared_ptr<T> const res(head->data);  // 4
    std::unique_ptr<node> old_head=std::move(head);
    head=std::move(old_head->next);  // 5
    return res;  // 6
  }

  void push(T new_value)
  {
    std::shared_ptr<T> new_data(
      std::make_shared<T>(std::move(new_value)));  // 7
    std::unique_ptr<node> p(new node);  //8
    tail->data=new_data;  // 9
    node* const new_tail=p.get();
    tail->next=std::move(p);
    tail=new_tail;
  }
};
```

try_pop()不需要太多的修改。首先，你可以拿head和tail③進行比較，這就要比檢查指針是否為空的好，因為虛擬節點意味著head不可能是空指針。head是一個`std::unique_ptr<node>`對象，你需要使用head.get()來做比較。其次，因為node現在存在數據指針中①，你就可以對指針進行直接檢索④，而非構造一個T類型的新實例。push()函數改動最大：首先，你必須在堆上創建一個T類型的實例，並且讓其與一個`std::shared_ptr<>`對象相關聯⑦(節點使用`std::make_shared`就是為了避免內存二次分配，避免增加引用次數)。創建的新節點就成為了虛擬節點，所以你不需要為new_value提供構造函數⑧。反而這裡你需要將new_value的副本賦給之前的虛擬節點⑨。最終，為了讓虛擬節點存在在隊列中，你不得不使用構造函數來創建它②。

那麼現在，我確信你會對如何對如何修改隊列，讓其變成一個線程安全的隊列感到驚訝。好吧，現在的push()只能訪問tail，而不能訪問head，這就是一個進步try_pop()可以訪問head和tail，但是tail只需在最初進行比較，所以所存在的時間很短。重大的提升在於，虛擬節點意味著try_pop()和push()不能對同一節點進行操作，所以這裡已經不再需要互斥了。那麼，你只需要使用一個互斥量來保護head和tail就夠了。那麼，現在應該鎖哪裡？

我們的目的是為了最大程度的併發化，所以你需要上鎖的時間，要儘可能的小。push()很簡單：互斥量需要對tail的訪問進行上鎖，這就意味著你需要對每一個新分配的節點進行上鎖⑧，還有在你對當前尾節點進行賦值的時候⑨也需要上鎖。鎖需要持續到函數結束時才能解開。

try_pop()就不簡單了。首先，你需要使用互斥量鎖住head，一直到head彈出。實際上，互斥量決定了哪一個線程來進行彈出操作。一旦head被改變⑤，你才能解鎖互斥量；當在返回結果時，互斥量就不需要進行上鎖了⑥。這使得訪問tail需要一個尾互斥量。因為，你需要只需要訪問tail一次，且只有在訪問時才需要互斥量。這個操作最好是通過函數進行包裝。事實上，因為代碼只有在成員需要head時，互斥量才上鎖，這項也需要包含在包裝函數中。最終代碼如下所示。

清單6.6 線程安全隊列——細粒度鎖版

```
template<typename T>
class threadsafe_queue
{
private:
  struct node
  {
    std::shared_ptr<T> data;
    std::unique_ptr<node> next;
  };
  std::mutex head_mutex;
  std::unique_ptr<node> head;
  std::mutex tail_mutex;
  node* tail;

  node* get_tail()
  {
    std::lock_guard<std::mutex> tail_lock(tail_mutex);
    return tail;
  }

  std::unique_ptr<node> pop_head()
  {
    std::lock_guard<std::mutex> head_lock(head_mutex);
    if(head.get()==get_tail())
    {
      return nullptr;
    }
    std::unique_ptr<node> old_head=std::move(head);
    head=std::move(old_head->next);
    return old_head;
  }
public:
  threadsafe_queue():
  head(new node),tail(head.get())
  {}
  threadsafe_queue(const threadsafe_queue& other)=delete;
  threadsafe_queue& operator=(const threadsafe_queue& other)=delete;

  std::shared_ptr<T> try_pop()
  {
     std::unique_ptr<node> old_head=pop_head();
     return old_head?old_head->data:std::shared_ptr<T>();
  }

  void push(T new_value)
  {
    std::shared_ptr<T> new_data(
      std::make_shared<T>(std::move(new_value)));
    std::unique_ptr<node> p(new node);
    node* const new_tail=p.get();
    std::lock_guard<std::mutex> tail_lock(tail_mutex);
    tail->data=new_data;
    tail->next=std::move(p);
    tail=new_tail;
  }
};
```

讓我們用挑剔的目光來看一下上面的代碼，並考慮6.1.1節中給出的指導意見。在你觀察不變量前，你需要確定的狀態有：

- tail->next == nullptr

- tail->data == nullptr

- head == taill(意味著空列表)

- 單元素列表 head->next = tail

- 在列表中的每一個節點x，x!=tail且x->data指向一個T類型的實例，並且x->next指向列表中下一個節點。x->next == tail意味著x就是列表中最後一個節點

- 順著head的next節點找下去，最終會找到tail

這裡的push()很簡單：僅修改了被tail_mutex的數據，因為新的尾節點是一個空節點，並且其data和next都為舊的尾節點(實際上的尾節點)設置好，所以其能維持不變量的狀態。

有趣的部分在於try_pop()上。事實證明，不僅需要對tail_mutex上鎖，來保護對tail的讀取；還要保證在從頭讀取數據時，不會產生數據競爭。如果沒有這些互斥量，當一個線程調用try_pop()的同時，另一個線程調用push()，那麼這裡操作順序將不可預測。儘管，每一個成員函數都持有一個互斥量，這些互斥量能保護數據不會同時被多個線程訪問到；並且，隊列中的所有數據來源，都是通過調用push()得到的。因為線程可能會無序的方位同一數據，所以這裡就會有數據競爭(正如你在第5章看到的那樣)，以及未定義行為。幸運的是，在get_tail()中的tail_mutex解決了所有的問題。因為調用get_tail()將會鎖住同名鎖，就像push()一樣，這就為兩個操作規定好了順序。要不就是get_tail()在push()之前被調用，這種情況下，線程可以看到舊的尾節點，要不就是在push()之後完成，這種情況下，線程就能看到tail的新值，以及新數據前的真正tail的值。

當get_tail()調用前，head_mutex已經上鎖，這一步也是很重要的哦。如果不這樣，調用pop_head()時就會被get_tail()和head_mutex所卡住，因為其他線程調用try_pop()(以及pop_head())時，都需要先獲取鎖，然後阻止從下面的過程中初始化線程：

```
std::unique_ptr<node> pop_head() // 這是個有缺陷的實現
{
  node* const old_tail=get_tail();  // ① 在head_mutex範圍外獲取舊尾節點的值
  std::lock_guard<std::mutex> head_lock(head_mutex);

  if(head.get()==old_tail)  // ②
  {
    return nullptr;
  }
  std::unique_ptr<node> old_head=std::move(head);
  head=std::move(old_head->next);  // ③
  return old_head;
}
```

這是一個有缺陷的實現，調用get_tail()是在鎖的範圍之外，你可能也許會發現head和tail，在你初始化線程，並獲取head_mutex時，發生了改變。並且，不只是返回尾節點時，返回的不是尾節點了，其值甚至都不列表中的值了。即使head是最後一個節點，這也意味著head和old_tail②比較失敗。因此，當你更新head③時，可能會將head移到tail之後，這樣的話就意味著數據結構遭到了破壞。在正確實現中(清單6.6)，需要保證在head_mutex保護的範圍內調用get_tail()。這就能保證沒有其他線程能對head進行修改，並且tail會向正確的方向移動(當有新節點添加進來時)，這樣就很安全了。head不會傳遞給get_tail()的返回值，所以不變量的狀態時穩定的。

當使用pop_head()更新head時(從隊列中刪除節點)，互斥量就已經上鎖了，並且try_pop()可以提取數據，並在確實有個數據的時候刪除一個節點(若沒有數據，則返回`std::shared_ptr<>`的空實例)，因為只有一個線程可以訪問這個節點，所以根據我們所掌握的知識，認為這個操作是安全的。

接下來，外部接口就相當於清單6.2代碼中的子集了，所以同樣的分析結果：對於固有接口來說，不存在條件競爭。

異常是很有趣的東西。雖然，你已經改變了數據的分配模式，但是異常可能從別的地方襲來。try_pop()中的對鎖的操作會產生異常，並直到鎖獲取才能對數據進行修改。因此，try_pop()是異常安全的。另一方面，push()可以在堆上新分配出一個T的實例，以及一個node的新實例，這裡可能會拋出異常。但是，所有分配的對象都賦給了智能指針，那麼當異常發生時，他們就會被釋放掉。一旦鎖被獲取，push()中的操作就不會拋出異常，所以push()也是異常安全的。

因為沒有修改任何接口，所以不會死鎖。在實現內部也不會有死鎖；唯一需要獲取兩個鎖的是pop_head()，這個函數需要獲取head_mutex和tail_mutex，所以不會產生死鎖。

那麼剩下的問題就都在實際併發的可行性上了。這個結構對併發訪問的考慮要多於清單6.2中的代碼，因為這裡鎖粒度更加的小，並且更多的數據不在鎖的保護範圍內。比如，在push()中，新節點和新數據的分配都不需要鎖來保護。這就意味著多線程情況下，節點及數據的分配是“安全”併發的。同一時間內，只有一個線程可以將它的節點和數據添加到隊列中，所以代碼中只是簡單使用了指針賦值的形式，相較於基於`std::queue<>`的實現中，對於`std::queue<>`的內部操作進行上鎖，這個結構中就不需要了。

同樣，try_pop()持有tail_mutex也只有很短的時間，只為保護對tail的讀取。因此，當有數據push進隊列後，try_pop()幾乎及可以完全併發調用了。同樣在執行中，對head_mutex的持有時間也是極短的。當併發訪問時，這就會增加對try_pop()的訪問次數；且只有一個線程，在同一時間內可以訪問pop_head()，且多線程情況下可以刪除隊列中的舊節點，並且安全的返回數據。

**等待數據彈出**

OK，所以清單6.6提供了一個使用細粒度鎖的線程安全隊列，不過只有try_pop()可以併發訪問(且只有一個重載存在)。那麼在清單6.2中方便的wait_and_pop()呢？你能通過細粒度鎖實現一個相同功能的接口嗎？

當然，答案是“是的”，不過的確有些困難，困難在哪裡？修改push()是相對簡單的：只需要在函數體末尾添加data_cond.notify_ont()函數的調用即可(如同清單6.2中那樣)。當然，事實並沒有那麼簡單：你使用細粒度鎖，是為了保證最大程度的併發。當將互斥量和notify_one()混用的時，如果被通知的線程在互斥量解鎖後被喚醒，那麼這個線程就不得不等待互斥量上鎖。另一方面，當解鎖操作在notify_one()之前調用，那麼互斥量可能會等待線程醒來，來獲取互斥鎖(假設沒有其他線程對互斥量上鎖)。這可能是一個微小的改動，但是對於一些情況來說，就顯的很重要了。

wait_and_pop()就有些複雜了，因為需要確定在哪裡等待，也就是函數在哪裡執行，並且需要確定哪些互斥量需要上鎖。等待的條件是“隊列非空”，這就意味著head!=tail。這樣寫的話，就需要同時獲取head_mutex和tail_mutex，並對其進行上鎖，不過在清單6.6中已經使用tail_mutex來保護對tail的讀取，以及不用和自身記性比較，所以這種邏輯也同樣適用於這裡。如果有函數讓head!=get_tail()，你只需要持有head_mutex，然後你就可以使用鎖，對data_cond.wait()的調用進行保護。當你將等待邏輯添加入結構當中，那麼實現的方式與try_pop()基本上是一樣的。

對於try_pop()和wait_and_pop()的重載都需要深思熟慮。當你將返回`std::shared_ptr<>`替換為從“old_head後索引出的值，並且拷貝賦值給value參數”進行返回時，那麼這裡將會存在異常安全問題。數據項在互斥鎖未上鎖的情況下被刪除，將剩下的數據返回給調用者。不過，當拷貝賦值拋出異常(可能性很大)時，數據項將會丟失，因為它沒有被返回隊列原來的位置上。

當T類型有無異常拋出的移動賦值操作，或無異常拋出的交換操作時，你可以使用它，不過，你肯定更喜歡一種通用的解決方案，無論T是什麼類型，這個方案都能使用。在這種情況下，在節點從列表中刪除前，你就不得不將有可能拋出異常的代碼，放在鎖保護的範圍內，來保證異常安全性。這也就意味著你需要對pop_head()進行重載，查找索引值在列表改動前的位置。

相比之下，empty()就更加的簡單:只需要鎖住head_mutex，並且檢查head==get_tail()(詳見清單6.10)就可以了。最終的代碼，在清單6.7，6.8，6.9和6.10中。

清單6.7 可上鎖和等待的線程安全隊列——內部機構及接口

```
template<typename T>
class threadsafe_queue
{
private:
  struct node
  {
    std::shared_ptr<T> data;
    std::unique_ptr<node> next;
  };

  std::mutex head_mutex;
  std::unique_ptr<node> head;
  std::mutex tail_mutex;
  node* tail;
  std::condition_variable data_cond;
public:
  threadsafe_queue():
    head(new node),tail(head.get())
  {}
  threadsafe_queue(const threadsafe_queue& other)=delete;
  threadsafe_queue& operator=(const threadsafe_queue& other)=delete;

  std::shared_ptr<T> try_pop();
  bool try_pop(T& value);
  std::shared_ptr<T> wait_and_pop();
  void wait_and_pop(T& value);
  void push(T new_value);
  bool empty();
};
```

向隊列中添加新節點是相當簡單的——下面的實現與上面的代碼差不多。

清單6.8 可上鎖和等待的線程安全隊列——推入新節點

```
template<typename T>
void threadsafe_queue<T>::push(T new_value)
{
  std::shared_ptr<T> new_data(
  std::make_shared<T>(std::move(new_value)));
  std::unique_ptr<node> p(new node);
  {
    std::lock_guard<std::mutex> tail_lock(tail_mutex);
    tail->data=new_data;
    node* const new_tail=p.get();
    tail->next=std::move(p);
    tail=new_tail;
  }
  data_cond.notify_one();
}
```

如同之前所提到的，複雜部分都在pop那邊，所以提供幫助性函數去簡化這部分就很重要了。下一個清單中將展示wait_and_pop()的實現，以及先關的幫助函數。

清單6.9 可上鎖和等待的線程安全隊列——wait_and_pop()

```
template<typename T>
class threadsafe_queue
{
private:
  node* get_tail()
  {
    std::lock_guard<std::mutex> tail_lock(tail_mutex);
    return tail;
  }

  std::unique_ptr<node> pop_head()  // 1
  {
    std::unique_ptr<node> old_head=std::move(head);
    head=std::move(old_head->next);
    return old_head;
  }

  std::unique_lock<std::mutex> wait_for_data()  // 2
  {
    std::unique_lock<std::mutex> head_lock(head_mutex);
    data_cond.wait(head_lock,[&]{return head.get()!=get_tail();});
    return std::move(head_lock);  // 3
  }

  std::unique_ptr<node> wait_pop_head()
  {
    std::unique_lock<std::mutex> head_lock(wait_for_data());  // 4
    return pop_head();
  }

  std::unique_ptr<node> wait_pop_head(T& value)
  {
    std::unique_lock<std::mutex> head_lock(wait_for_data());  // 5
    value=std::move(*head->data);
    return pop_head();
  }
public:
  std::shared_ptr<T> wait_and_pop()
  {
    std::unique_ptr<node> const old_head=wait_pop_head();
    return old_head->data;
  }

  void wait_and_pop(T& value)
  {
    std::unique_ptr<node> const old_head=wait_pop_head(value);
  }
};
```

清單6.9中所示的pop部分的實現中有一些幫助函數來降低代碼的複雜度，例如pop_head()①和wait_for_data()②，這些函數分別是刪除頭結點和等待隊列中有數據彈出的。wait_for_data()特別值得關注，因為其不僅等待使用lambda函數對條件變量進行等待，而且它還會將鎖的實例返回給調用者③。這就需要確保同一個鎖在執行與wait_pop_head()重載④⑤的相關操作時，已持有鎖。pop_head()是對try_pop()代碼的複用，將在下面進行展示：

清單6.10 可上鎖和等待的線程安全隊列——try_pop()和empty()

```
template<typename T>
class threadsafe_queue
{
private:
  std::unique_ptr<node> try_pop_head()
  {
    std::lock_guard<std::mutex> head_lock(head_mutex);
    if(head.get()==get_tail())
    {
      return std::unique_ptr<node>();
    }
    return pop_head();
  }

  std::unique_ptr<node> try_pop_head(T& value)
  {
    std::lock_guard<std::mutex> head_lock(head_mutex);
    if(head.get()==get_tail())
    {
      return std::unique_ptr<node>();
    }
    value=std::move(*head->data);
    return pop_head();
  }
public:
  std::shared_ptr<T> try_pop()
  {
    std::unique_ptr<node> old_head=try_pop_head();
    return old_head?old_head->data:std::shared_ptr<T>();
  }

  bool try_pop(T& value)
  {
    std::unique_ptr<node> const old_head=try_pop_head(value);
    return old_head;
  }

  bool empty()
  {
    std::lock_guard<std::mutex> head_lock(head_mutex);
    return (head.get()==get_tail());
  }
};
```

這個隊列的實現將作為第7章無鎖隊列的基礎。這是一個無界隊列;線程可以持續向隊列中添加數據項，即使沒有元素被刪除。與之相反的就是有界隊列，在有界隊列中，隊列在創建的時候最大長度就已經是固定的了。當有界隊列滿載時，嘗試在向其添加元素的操作將會失敗或者阻塞，直到有元素從隊列中彈出。在任務執行時(詳見第8章)，有界隊列對於線程間的工作花費是很有幫助的。其會阻止線程對隊列進行填充，並且可以避免線程從較遠的地方對數據項進行索引。

無界隊列的實現，很容易擴展成，可在push()中等待跳進變量的定長隊列。相對於等待隊列中具有數據項(pop()執行完成後)，你就需要等待隊列中數據項小於最大值就可以了。對於有界隊列更多的討論，已經超出了本書的範圍，就不再多說；現在越過隊列，向更加複雜的數據結構進發。
