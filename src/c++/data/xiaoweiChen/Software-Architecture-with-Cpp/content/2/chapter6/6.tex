

即使机器的内存资源很丰富，了解如何使用它的也是个好主意。通常，内存吞吐量是现代系统的性能瓶颈，因此充分利用它很重要。执行太多的动态分配可能会降低程序的速度，并导致内存碎片。让我们来了解一些缓解这些问题的方法。

\subsubsubsection{6.6.1\hspace{0.2cm}使用SSO/SOO减少动态分配}

动态分配有时会给带来其他麻烦，而不仅仅是在没有足够内存的情况下构造对象时抛出问题。它们通常会占用CPU周期，并可能导致内存碎片。幸运的是，有一种方法可以避免这种情况。若使用过\texttt{std::string}(GCC 5.0之后)，可以使用小字符优化(Small string optimization，SSO)的策略。这是一个名为小对象优化(Small Object optimization, SSO)的更通用的优化示例，可以在Abseil的\texttt{InlinedVector}类型中看到。主要思想很简单:如果动态分配的对象足够小，就应该存储在拥有它的类中，而不是动态分配。在\texttt{std::string}中，通常有容量、长度和存储的实际字符串。如果字符串足够短(对于GCC来说，在64位平台上是15字节)，将存储在其中的一些成员中。

就地存储对象，而不是进行分配，只存储指针还有一个好处:更少的指针跟踪。每次需要访问存储在指针后面的数据时，都会增加CPU缓存的压力，并面临从主存获取数据的风险。如果这是一个常见的模式，会影响应用程序的整体性能，特别是指向的地址没有被CPU的预取器猜到。使用SSO和SOO等技术对于减少这些问题十分有用。

\subsubsubsection{6.6.2\hspace{0.2cm}通过COW来节省内存}

若在GCC 5.0之前使用了GCC的\texttt{std::string}，可以使用Copy-On-Write(COW)优化。当使用相同的底层字符数组创建多个实例时，COW字符串实现实际上共享相同的内存地址。将字符串写入时，将复制存储的数据——因此有了名称。

这种技术有助于节省内存并保持缓存热度，通常在单个线程上提供稳定的性能。但要注意不要在多线程上下文中使用它，锁是真正的性能杀手。与任何与性能相关的主题一样，最好只确定它是否匹配目前的工作。

现在来讨论C++17的一个特性，可以通过动态分配实现良好的性能。

\subsubsubsection{6.6.3\hspace{0.2cm}使用多态分配器}

这里讨论的特性是多态分配器。具体来说，是分配程序用来分配内存的\texttt{std::pmr::polymorphic\_allocator}和多态的\texttt{std::pmr::memory\_resource}类。

本质上，可以轻松地链接内存资源，以最大限度地利用内存。链的实现可以很简单，比如将资源保留一个大块并分发，然后回到另一个资源，如果耗尽了，则使用\texttt{new}和\texttt{delete}。实现也可以更复杂:可以构建一个处理不同大小的池的长内存资源链，只在需要时提供线程安全，绕过堆并直接获取系统内存，返回最后释放的内存块以提供缓存热度，以及做其他有趣的事情。所有这些功能都是由标准的多态内存资源提供的，因为它们的设计很容易进行扩展。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{存储区}

存储区，可以在有限时间内存在的大块内存。可以用分配在存储区生命周期中使用的较小的对象。存储区中的对象也可以释放，也可以在清空内存的过程中删除。

与通常的分配和释放方式相比，存储区有几大优势——因为限制了需要获取上游资源的内存分配，可以提高性能。因为可能发生的碎片化都将发生在区域内部，还减少了内存的碎片化。当区域内存释放后，也就不存在碎片化了。一个好的方式是为每个线程创建独立的存储区，若只有一个线程使用存储区，那么不需要使用锁或其他线程安全的机制，从而可以减少线程争用，并在性能上带来重大的提升。

如果程序是单线程的，提高其性能的低成本解决方案可以这样:

\begin{lstlisting}[style=styleCXX]
auto single_threaded_pool = std::pmr::unsynchronized_pool_resource();
std::pmr::set_default_resource(&single_threaded_pool);
\end{lstlisting}

如果不显式设置任何资源，默认资源将是\texttt{new\_delete\_resource}，会像常规的\texttt{std::allocator}一样每次调用\texttt{new}和\texttt{delete}，并保证线程的安全性(和成本)。

如果使用前面的代码，那么使用pmr分配器完成的所有分配都不需要锁，但仍需要使用pmr类型。想要在标准容器中这样使用，就需要简单地传递\texttt{std::pmr::polymorphic\_allocator<T>}作为\texttt{allocator}模板参数。许多标准容器都有启用pmr的类型别名。下面创建的两个变量是相同类型的，都使用默认的内存资源:

\begin{lstlisting}[style=styleCXX]
auto ints = std::vector<int,
std::pmr::polymorphic_allocator<int>>(std::pmr::get_default_resource());
auto also_ints = std::pmr::vector<int>{};
\end{lstlisting}

但第一个函数会显式传递资源。现在了解一下pmr中可用的资源。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{单调内存}

第一个是\texttt{std::pmr::monotonic\_buffer\_resource}，一个只分配内存，不做关于回收的事情，只会在内存销毁或显式调用\texttt{release()}时释放内存。由于不保证线程安全，使得这种类型具有极高的性能。如果应用程序偶尔需要在给定线程上执行大量分配资源的任务，然后释放之后一次使用的所有对象，使用单调的内存会有性能上的很大收益。这也是构建资源链的重要基础模块。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{资源池}

两种资源的常见组合是在单调内存上使用资源池。标准资源池可以创建不同大小的块的池。在\texttt{std::pmr}中有两种类型，\texttt{unsynchronized\_pool\_resource}只在一个线程上分配和释放时使用，\texttt{synchronized\_pool\_resource}适用于多线程使用。两者都能提供比全局分配器更好的性能，特别是在使用单调内存区作为其上游资源时。如果想知道如何锁住它们，可以参考以下代码:

\begin{lstlisting}[style=styleCXX]
auto buffer = std::array<std::byte, 1 * 1024 * 1024>{};
auto monotonic_resource =
std::pmr::monotonic_buffer_resource{buffer.data(), buffer.size()};
auto pool_options = std::pmr::pool_options{.max_blocks_per_chunk = 0,
	.largest_required_pool_block = 512};
auto arena =
std::pmr::unsynchronized_pool_resource{pool_options,
	&monotonic_resource};
\end{lstlisting}

创建了一个1MB的缓冲区供区域重用。这里将其传递给一个单调内存，然后将其传递给一个不同步的资源池，并创建一个简单而有效的分配器链，在所有初始内存用完之前不会调用\texttt{new}。

可以传递\texttt{std::pmr::pool\_options}对象给这两种池类型，以限制给定块的最大数量(\texttt{max\_blocks\_per\_chunk})或最大块的大小(\texttt{max\_required\_pool\_block})。传递0将使用实现的默认值。在GCC的情况下，每个块的实际块取决于块的大小。如果超过了最大的内存大小，资源池将直接从其上游资源分配。如果初始内存耗尽，也会转到上游资源。在这种情况下，会分配以几何倍数增长的内存块。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{编写自己的内存资源}

如果标准内存资源不能满足需求，可以简单地创建一个自定义内存资源，并不是所有的标准库实现都会提供很好的优化，即跟踪最后释放的大小给定的内存块，并在给定大小的下一个分配中进行返回。最近使用的缓存可以增加数据缓存的热度，这有助于应用的性能。可以将它看作一组块的后进先出队列。

有时，可能还想调试分配和释放。下面的代码段中，我写了一个简单的资源器，可以完成这个任务:

\begin{lstlisting}[style=styleCXX]
class verbose_resource : public std::pmr::memory_resource {
	std::pmr::memory_resource *upstream_resource_;
public:
	explicit verbose_resource(std::pmr::memory_resource *upstream_resource)
		: upstream_resource_(upstream_resource) {}
\end{lstlisting}

\texttt{verbose\_resource}继承\texttt{memory\_resourc}，可以接受上游资源，用于实际的分配。其必须实现三个私有函数——一个用于分配，一个用于释放，一个用于比较资源本身的实例。先是第一个:

\begin{lstlisting}[style=styleCXX]
private:
void *do_allocate(size_t bytes, size_t alignment) override {
	std::cout << "Allocating " << bytes << " bytes\n";
	return upstream_resource_->allocate(bytes, alignment);
}
\end{lstlisting}

确实是在标准输出上打印分配大小，然后使用上游资源来分配内存。下一个类似:

\begin{lstlisting}[style=styleCXX]
	void do_deallocate(void *p, size_t bytes, size_t alignment) override {
		std::cout << "Deallocating " << bytes << " bytes\n";
		upstream_resource_->deallocate(p, bytes, alignment);
	}
\end{lstlisting}

记录释放和使用上游执行任务的内存数量。下面是最后一个必需的函数:

\begin{lstlisting}[style=styleCXX]
	[[nodiscard]] bool
	do_is_equal(const memory_resource &other) const noexcept override {
		return this == &other;
	}
\end{lstlisting}

只要比较实例的地址就可以知道是否相等。\texttt{[[nodiscard]]}属性可以确保调用者实际上使用了返回的值，这可以避免函数的滥用。

就是这样。对于像pmr分配器这样强大的特性，API现在还不怎么复杂，不是吗？

除了跟踪分配之外，还可以使用pmr来避免在不应该分配时进行分配。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{确保没有意外的分配}

\texttt{std::pmr::null\_memory\_resource()}将在试图使用它分配内存时抛出异常。通过将pmr设置为默认资源，从而避免使用pmr进行任何分配，如下所示:

\begin{lstlisting}[style=styleCXX]
std::pmr::set_default_resource(null_memory_resource());
\end{lstlisting}

还可以用来限制不应该发生的上游分配。检查以下代码:

\begin{lstlisting}[style=styleCXX]
auto buffer = std::array<std::byte, 640 * 1024>{}; // 640K ought to be
enough for anybody
auto resource = std::pmr::monotonic_buffer_resource{
	buffer.data(), buffer.size(), std::pmr::null_memory_resource()};
\end{lstlisting}

若试图分配超过设置的缓冲区大小，将抛出\texttt{std::bad\_alloc}异常。

接着讨论本章的最后一项内容。

\hspace*{\fill} \\ %插入空行
\noindent
\textbf{闪烁清理内存}

有时，不必释放内存(如单调内存)仍然不足以提高性能。一种叫做“闪烁清理”的技术可以解决这个问题。其意味着不会逐个释放，而且构造函数也不会调用。对象只是蒸发，节省了在内存区中为每个对象及其成员(及其成员…)调用析构函数的时间。

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black, title=Note]
\hspace*{0.75cm}这是一个高级话题。使用这个技巧时要小心，只有在可能有性能收益的时候使用。
\end{tcolorbox}

这种技术可以节省宝贵的CPU周期，但并不总可以使用。如果对象处理的是内存以外的资源，则需要避免闪烁清理内存。否则，就会出现资源泄漏。如果依赖于对象的析构函数有副作用，情况也是如此。

现在让看看“闪烁”的动作:

\begin{lstlisting}[style=styleCXX]
auto verbose = verbose_resource(std::pmr::get_default_resource());
auto monotonic = std::pmr::monotonic_buffer_resource(&verbose);
std::pmr::set_default_resource(&monotonic);

auto alloc = std::pmr::polymorphic_allocator{};
auto *vector = alloc.new_object<std::pmr::vector<std::pmr::string>>();
vector->push_back("first one");
vector->emplace_back("long second one that must allocate");
\end{lstlisting}

这里，手工创建了一个多态分配器，将使用默认资源——单调内存资源，每次它到达上游时都会在日志中记录。为了创建对象，这里使用一个在C++20的pmr中新加入的函数，即\texttt{new\_object}函数。这里创建了一个字符串向量，可以使用\texttt{push\_back}传递第一个字符串，因为它足够小，可以放入SSO提供的小字符串缓冲区中。第二个字符串需要使用默认资源分配一个字符串，只有在使用\texttt{push\_back}时才将它传递给\texttt{vector}。绑定会导致字符串在\texttt{vector}函数中构造(而不是在调用之前)，所以这里会使用\texttt{vector}的分配器。最后，不会在其他地方调用已分配对象的析构函数，而是在退出作用域时立即释放所有对象。这将带来非常可观的性能。















 