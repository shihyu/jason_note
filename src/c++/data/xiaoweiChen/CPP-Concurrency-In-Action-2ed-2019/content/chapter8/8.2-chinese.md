# 8.2 併發代碼的性能

多處理系統中使用併發來提高代碼的效率時，需要了解影響併發的效率的因素。即使使用多線程對關注點進行分離，還需要確定是否會對性能造成負面影響。在16核機器上應用的速度與單核機器相當時，用戶一定會抱怨。

多線程代碼中有很多因素會影響性能——對線程處理的數據做一些簡單的改動，都可能對性能產生戲劇性的效果。所以，多言無益，讓我們來看一下這些因素吧。

## 8.2.1 處理器數量

處理器數量是影響多線程應用的首要因素。當對目標硬件很熟悉，並且能針對硬件進行軟件設計，並在目標系統或副本上進行性能測試。那很幸運，可以在類似的平臺上進行開發。不過，當所使用的平臺與目標平臺的差異很大，比如：可能會在一個雙芯或四芯的系統上做開發，而用戶系統可能就只有單個處理器(可能有很多芯)，或多個單芯處理器，亦或是多核多芯的處理器。併發程序在不同平臺上的行為和性能特點可能完全不同，需要在不同平臺上進行測試。

一個單核16芯的處理器和四核雙芯或十六核單芯的處理器相同：任何系統上，都能開啟16個併發線程。線程數量少於16個時，會有處理器處於空閒狀態(除非系統同時需要運行其他應用，不過我們暫時忽略這種可能性)。另一方面，當多於16個線程在運行時(都沒有阻塞或等待)，應用將會浪費處理器的運算時間在線程間進行切換，稱其為*超額申請*(oversubscription)。

為了擴展線程的數量，且與硬件所支持的併發線程數一致，C++標準線程庫提供`std::thread::hardware_concurrency()`，使用這個函數就能知道在給定硬件上可以擴展的線程數量了。

使用`std::thread::hardware_concurrency()`需要謹慎，因為不會考慮其他應用已使用的線程數量(除非已經將系統信息進行共享)。`std::async()`可以避免這個問題，標準庫會對所有調用進行安排。同樣，謹慎的使用線程池也可以避免這個問題。

不過，即使考慮到在應用中運行的線程，還是會受其他運行程序的影響。雖然，單用戶系統中使用多個CPU密集型應用很罕見，但在某些領域就很常見了。系統能提供選擇線程數量的機制，這種機制超出了C++標準的範圍。一種選擇是使用與`std::async()`類似的工具，為所有執行異步任務線程的數量做考慮，另一種選擇是限制每個應用使用的處理芯數量。我是希望這種限制可以反映到`std::thread::hardware_concurrency()`上(不能保證)。如果需要處理這種情況，可以看一下系統說明，瞭解一下是否有相關選項可供使用。

理想算法可能會取決於問題規模與處理單元的比值。大規模並行系統中有很多的處理單元，為了讓應用盡快結束，算法可能就會同時執行很多操作。

隨著處理器數量的增加，另一個問題就會來影響性能：多個處理器嘗試訪問同一個數據。

## 8.2.2 數據爭用與乒乓緩存

當兩個線程在不同處理器上時，對同一數據進行讀取，通常不會出現問題。因為數據會拷貝到每個線程的緩存中，並讓兩個處理器同時進行處理。當有線程對數據進行修改，並且需要更新到其他核芯的緩存中去，就要耗費一定的時間。這樣的修改可能會讓第二個處理器停下來，等待硬件內存更新緩存中的數據。根據CPU指令，這是一個特別特別慢的操作。

思考下面的代碼段：

```c++
std::atomic<unsigned long> counter(0);
void processing_loop()
{
  while(counter.fetch_add(1,std::memory_order_relaxed)<100000000)
  {
    do_something();
  }
}
```

counter變量是全局的，任何線程都能調用processing_loop()。因此，每次對counter進行增量操作時，處理器必須確保緩存中的counter是最新值，然後進行修改，再告知其他處理器。編譯器不會為任何數據做同步操作，fetch_add是一個“讀-改-寫”操作，因此要對最新的值進行檢索。如果另一個線程在另一個處理器上執行同樣的代碼，counter的數據需要在兩個處理器之間進行傳遞，這兩個處理器的緩存中間就存有counter的最新值(當counter的值增加時)。如果do_something()足夠短，或有很多處理器來對這段代碼進行處理時，處理器會互相等待。一個處理器準備更新這個值，另一個處理器在修改這個值，所以該處理器就需要等待第二個處理器更新完成，並且完成更新傳遞時才能執行更新，這種情況被稱為*高競爭*(high contention)。如果處理器很少需要互相等待就是*低競爭*(low contention)。

循環中counter的數據將在每個緩存中傳遞若干次，這就是*乒乓緩存*(cache ping-pong)，這會對應用的性能有著重大的影響。當處理器因為等待緩存轉移而停止運行時，這個處理器就不能做任何事情，所以對於整個應用來說這是一個壞消息。

你可能會想，這種情況不會發生在你身上，因為你沒有使用任何循環。那麼互斥鎖呢？如果在循環中放置一個互斥量，就和之前從數據訪問的方式差不多了。為了鎖住互斥量，另一個線程必須將數據進行轉移，並且對數據進行修改。當這個過程完成時，會再次對互斥量進行解鎖，之後互斥數據將會傳遞到下一個需要互斥量的線程上去。轉移耗費的時間，就是第二個線程等待第一個線程釋放互斥量的時間：

```c++
std::mutex m;
my_data data;
void processing_loop_with_mutex()
{
  while(true)
  {
    std::lock_guard<std::mutex> lk(m);
    if(done_processing(data)) break;
  }
}
```

接下來看看最糟糕的部分：數據和互斥量已經準備好讓多個線程進訪問後，當系統中的核心數和處理器數量增加時，很可能看到高競爭，以及處理器互相等待的情況。如果在多線程情況下，能更快的對同樣級別的數據進行處理，線程就會對數據和互斥量進行競爭。這樣的情況有很多，很多線程會同時嘗試對互斥量進行獲取，或者同時訪問變量等等。

互斥量的競爭通常不同於原子操作，互斥量通常使用操作系統級別的序列化線程。如果有足夠的線程去執行任務，有線程在等待互斥量時，操作系統會安排其他線程來執行任務，而處理器只會在其他線程運行在目標處理器上時，讓該處理器停止工作。對互斥量的競爭，將會影響線程的性能。

回顧第3章，一個很少更新的數據結構可以使用一個“單作者，多讀者”互斥量(詳見3.3.2)保護。乒乓緩存可以抵消互斥所帶來的性能收益，因為所有線程(即使是讀者線程)都會對互斥量進行修改。隨著處理器對數據訪問次數的增加，對於互斥量的競爭就會增加，並且持有互斥量的緩存行會在核芯中進行轉移，因此會增加不良的鎖獲取和釋放次數。有些方法可以改善這個問題，就是讓互斥量對多行緩存進行保護，不過這樣的互斥量需要自己去實現。

如何避免乒乓緩存呢？答案就是：減少兩個線程對同一個內存位置的競爭。

雖然，要實現起來並不簡單。即使給定內存位置，因為*偽共享*(false sharing)可能還是會有乒乓緩存。

## 8.2.3 偽共享

處理器緩存通常不會用來處理單個存儲點，而是會用來處理稱為*緩存行*(cache lines)的內存塊。內存塊通常大小為32或64字節，實際大小需要由處理器來決定。因為硬件緩存可確定處理緩存行的大小，較小的數據項就在同一內存行的相鄰位置上。有時這樣的設定還不錯：當線程訪問的一組數據是在同一數據行中，對於應用的性能來說就要好於對多個緩存行進行傳播。不過，同一緩存行存儲的是無關數據時，且需要被不同線程訪問，這就會造成性能問題。

假設一個int類型的數組，並且有一組線程可以訪問數組中的元素，且對數組的訪問很頻繁。通常int的大小要小於一個緩存行，同一個緩存行中可以存儲多個數據項。因此，即使每個線程都能對數據中的成員進行訪問，硬件還是會產生乒乓緩存。每當線程訪問0號數據項，並對其值進行更新時，緩存行的所有權就需要轉移給執行該線程的處理器，這僅是為了更新1號數據項的線程獲取1號線程的所有權。緩存行是共享的(即使沒有數據存在)，因此使用*偽共享*來描述這種方式。這個問題的解決辦法就是對數據進行構造，讓同一線程訪問的數據項存在臨近的地址中(就像是放在同一緩存行中)，這樣那些能被獨立線程訪問的數據將分佈在相距很遠的地方，並且可能是存儲在不同的緩存行中。本章接下來的內容中可以看到，這種思路對代碼和數據設計的影響。C++17標準在頭文件`<new>`中定義了`std::hardware_destructive_interference_size`它指定了當前編譯目標可能共享的連續字節的最大數目。如果確保數據間隔大於等於這個字節數，就不會有錯誤的共享存在了。

如果多線程訪問同一內存行是一種糟糕的情況，那麼單線程下的內存佈局會有哪些影響呢？

## 8.2.4 讓數據緊湊

偽共享發生的原因：某個線程所要訪問的數據過於接近另一線程的數據，另一個是與數據佈局相關的陷阱會直接影響單線程的性能。問題在於數據過於接近：單線程訪問數據時，數據就已在內存中展開，分佈在不同的緩存行上。另一方面，當內存中有緊湊數據時，數據就分佈在同一緩存行上。因此，當數據已傳播，將會有更多的緩存行從處理器的緩存上加載數據，這會增加訪問內存的延遲，以及降低數據的性能(與緊湊的數據存儲地址相比較)。

同樣的，如果數據已傳播，給定緩存行上就包含與當前線程有關和無關的數據。極端情況下，有更多的數據存在於緩存中，就會對數據以更多的關注，而非這些數據去做了什麼。這就會浪費寶貴的緩存空間，增加處理器緩存缺失的情況，從而因為其他數據已經佔有緩存中的位置，所以需要再從主存中添加對應數據項到緩存中。

現在，對於單線程代碼來說*任務切換*(task switching)就很關鍵了。如果系統中的線程數量要比核芯多，每個核上都要運行多個線程。這就會增加緩存的壓力，為了避免偽共享，努力讓不同線程訪問不同緩存行。當處理器切換線程時，要對不同內存行上的數據進行加載(當不同線程使用的數據跨越了多個緩存行時)，而非對緩存中的數據保持原樣(當線程中的數據都在同一緩存行時)。C++17在頭文件`<new>`中指定了一個常數`std::hardware_constructive_interference_size`，這是同一高速緩存行上的連續字節的最大數目(需要對齊)。將所需的數據大小控制在這個字節數內，就能提高緩存命中率。

如果線程數量多於內核或處理器數量，操作系統可能會選擇將線程安排給這個核芯一段時間，之後再安排給另一個核芯一段時間。就需要將緩存行從一個內核上，轉移到另一個內核上，也意味著要耗費很多時間。雖然，操作系統通常會避免這樣的情況發生，不過當其發生的時候，對性能會有很大影響。

當有超級多的線程準備運行時(非等待狀態)，任務切換就會頻繁發生。這個問題我們之前也接觸過：超額申請。

## 8.2.5 超額申請和頻繁的任務切換

多線程系統中，通常線程的數量要多於處理器的數量，除非在*大規模並行*(massively parallel)硬件上運行。不過，線程會花費時間來等待外部I/O完成，或被互斥量阻塞，或等待條件變量等等，所以等待不是問題。使用額外的線程來完成有用的工作，而非讓線程在處理器處以閒置狀態時持續等待。

不過，這也並非長久之計，如果有很多額外線程，就會有很多線程準備執行。不過，當線程數遠遠大於可用處理器數量時，操作系統就會忙於切換任務，以確保每個任務都有時間運行，這將增加切換任務的時間開銷，和緩存問題造成同一結果。當無限制的產生新線程，超額申請就會加劇，或者在通過任務類型對任務進行劃分的時候，線程數量大於處理器數量。這時，對性能影響的因素是CPU的能力，而非I/O。

如果只是簡單的通過數據劃分生成多個線程，可以限定工作線程的數量，如8.1.2節中那樣。如果超額申請是對工作的劃分而產生，那麼不同的劃分方式對性能就沒有太多益處了。

其他因素也會影響多線程代碼的性能，即使CPU類型和時鐘週期相同，乒乓緩存的開銷也可以讓程序在兩個單核處理器和在一個雙核處理器上，產生不明顯的性能差。接下來，讓我們看一下這些因素是如何影響代碼與數據結構設計的。