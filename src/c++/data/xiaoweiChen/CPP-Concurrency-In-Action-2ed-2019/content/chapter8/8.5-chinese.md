# 8.5 在實踐中設計併發代碼

為特殊的任務設計併發代碼時，需要根據任務來考慮之前提到的問題。為了展示以上的注意事項如何應用，我們將看一下在C++標準庫中三個標準函數的並行實現。

這裡主要演示這些技術的實現，不過可能這些技術並不是最前沿的。更多優秀的實現可以更好的利用硬件併發，這可能需要到與並行算法相關的學術文獻，或者是多線程的專家庫中(比如：Inter的TBB[4])才能看到。

並行版的`std::for_each`最能體現並行的概念，就讓我們從它開始吧！

## 8.5.1 並行版`std::for_each`

`std::for_each`的原理很簡單：其對某個範圍中的元素，依次使用用戶提供的函數。並行和串行的最大區別就是函數的調用順序。`std::for_each`是對範圍中的第一個元素調用用戶函數，接著是第二個，以此類推。在並行實現中對於每個元素的處理順序就不能保證了。

為了實現這個函數的並行版本，需要對每個線程所處理的元素進行劃分。事先知道元素數量，所以可以在處理前對數據進行劃分(詳見8.1.1節)。假設只有並行任務運行，就可以使用`std::thread::hardware_concurrency()`來決定線程的數量。同樣，這些元素都能獨立的處理，可以使用連續的數據塊來避免偽共享(詳見8.2.3節)。

這裡的算法類似於並行版的`std::accumulate`(詳見8.4.1節)，不過比起計算每一個元素的加和，這裡對每個元素僅僅使用了指定功能的函數。因為不需要返回結果，要將異常傳遞給調用者，就需要使用`std::packaged_task`和`std::future`對線程中的異常進行轉移。

代碼8.7 並行版`std::for_each`

```c++
template<typename Iterator,typename Func>
void parallel_for_each(Iterator first,Iterator last,Func f)
{
  unsigned long const length=std::distance(first,last);
  
  if(!length)
    return;

  unsigned long const min_per_thread=25;
  unsigned long const max_threads=
    (length+min_per_thread-1)/min_per_thread;

  unsigned long const hardware_threads=
    std::thread::hardware_concurrency();

  unsigned long const num_threads=
    std::min(hardware_threads!=0?hardware_threads:2,max_threads);

  unsigned long const block_size=length/num_threads;

  std::vector<std::future<void> > futures(num_threads-1);  // 1
  std::vector<std::thread> threads(num_threads-1);
  join_threads joiner(threads);

  Iterator block_start=first;
  for(unsigned long i=0;i<(num_threads-1);++i)
  {
    Iterator block_end=block_start;
    std::advance(block_end,block_size);
    std::packaged_task<void(void)> task(  // 2
      [=]()
      {
        std::for_each(block_start,block_end,f);
      });
    futures[i]=task.get_future();
    threads[i]=std::thread(std::move(task));  // 3
    block_start=block_end;
  }
  std::for_each(block_start,last,f);
  for(unsigned long i=0;i<(num_threads-1);++i)
  {
    futures[i].get();  // 4
  }
}
```

代碼結構與代碼8.4差不多，不同在於future向量對`std::future<void>`類型①變量進行存儲，因為工作線程不會返回值，並且Lambda函數會對block_start到block_end上的任務②執行f函數(為了避免傳入線程的構造函數③)。工作線程不需要返回值時，調用futures[i].get()④只為了檢索工作線程的異常。如果不想把異常傳遞出去，可以省略這一步。

實現並行`std::accumulate`時，使用`std::async`會簡化代碼。同樣，parallel_for_each也可以使用`std::async`。

代碼8.8 使用`std::async`實現`std::for_each`

```c++
template<typename Iterator,typename Func>
void parallel_for_each(Iterator first,Iterator last,Func f)
{
  unsigned long const length=std::distance(first,last);

  if(!length)
    return;

  unsigned long const min_per_thread=25;

  if(length<(2*min_per_thread))
  {
    std::for_each(first,last,f);  // 1
  }
  else
  {
    Iterator const mid_point=first+length/2;
    std::future<void> first_half=  // 2
      std::async(&parallel_for_each<Iterator,Func>,
                 first,mid_point,f);
    parallel_for_each(mid_point,last,f);  // 3
    first_half.get();  // 4
  }
}
```

和基於`std::async`的parallel_accumulate(代碼8.5)一樣，因為不知道需要使用多少個線程，所以在運行時對數據進行迭代劃分。像之前一樣，將每一級的數據分成兩部分，異步執行另外一部分②，剩下的部分就不能再進行劃分了，所以直接運行這一部分③；這樣就可以直接對`std::for_each`①進行使用了。再次使用`std::async`和`std::future`的get()④對異常進行傳播。

回到算法，函數需要對每一個元素執行同樣的操作(這樣的操作有很多種，初學者可能會想到`std::count`和`std::replace`)，一個稍微複雜一些的例子就是使用`std::find`。

## 8.5.2 並行版`std::find`

接下來是`std::find`，因為不需要對數據元素做處理，所以當第一個元素就滿足查找標準時，就沒有必要對剩餘元素進行搜索了。所以，算法屬性對於性能具有很大的影響，並且對並行實現有著直接的影響。這個算法是個很特別的例子，數據訪問模式都會對代碼的設計產生影響(詳見8.3.2節)。該類中的另一些算法包括`std::equal`和`std::any_of`。

當你和妻子或搭檔，在一個紀念盒中找尋一張老照片，當找到這張照片時，就不會再看另外的照片了。不過，你需要讓其他人知道你已經找到照片了(比如，大喊一聲“找到了！”)，這樣其他人就會停止搜索了。很多算法的特性就是要對每一個元素進行處理，所以沒有辦法像`std::find`一樣，一旦找到合適數據就停止執行。因此，需要設計代碼對其進行使用——當得到想要的答案時，就中斷其他任務的執行。

如果不中斷其他線程，串行版本的性能可能會超越並行版，因為串行算法可以在找到匹配元素的時候停止搜索。如果系統能支持四個併發線程，那麼每個線程就可以對總數據量的1/4進行檢查，並且在我們的實現只需要單核完成的1/4的時間，就能完成對所有元素的查找。如果匹配的元素在第一個1/4塊中，串行算法將會返回第一個。

中斷其他線程的一個辦法就是使用原子變量作為標識，處理過每一個元素後就對這個標識進行檢查。如果標識設置了，就意味有線程找到了匹配元素，算法就可以停止並返回。用這種方式來中斷線程就可以將沒有處理的數據保持原樣，並在更多的情況下，比串行運行性能上能提升很多。缺點就是，加載原子變量是一個很慢的操作，會阻礙線程的運行。

如何獲取返回值和異常呢？有兩個選擇。可以使用一個future數組，使用`std::packaged_task`來轉移值和異常，主線程上對返回值和異常進行處理，或者使用`std::promise`對工作線程上的最終結果直接進行設置，這完全依賴於怎麼樣處理工作線程上的異常。如果想停止第一個異常(即使還沒有對所有元素進行處理)，就可以使用`std::promise`對異常和最終值進行設置。另外，如果想讓其他工作線程繼續查找，可以使用`std::packaged_task`來存儲異常，當線程沒有找到匹配元素時異常將再次拋出。

這種情況下，我會選擇`std::promise`，因為其行為和`std::find`更為接近。這裡需要注意一下搜索的元素是不是在提供的搜索範圍內。因此，在所有線程結束前，獲取future上的結果。如果所要查找的值不在範圍內，就會持續的等待下去。

代碼8.9 並行find算法實現

```c++
template<typename Iterator,typename MatchType>
Iterator parallel_find(Iterator first,Iterator last,MatchType match)
{
  struct find_element  // 1
  {
    void operator()(Iterator begin,Iterator end,
                    MatchType match,
                    std::promise<Iterator>* result,
                    std::atomic<bool>* done_flag)
    {
      try
      {
        for(;(begin!=end) && !done_flag->load();++begin)  // 2
        {
          if(*begin==match)
          {
            result->set_value(begin);  // 3
            done_flag->store(true);  // 4
            return;
          }
        }
      }
      catch(...)  // 5
      {
        try
        {
          result->set_exception(std::current_exception());  // 6
          done_flag->store(true);
        }
        catch(...)  // 7
        {}
      }
    }
  };

  unsigned long const length=std::distance(first,last);

  if(!length)
    return last;

  unsigned long const min_per_thread=25;
  unsigned long const max_threads=
    (length+min_per_thread-1)/min_per_thread;

  unsigned long const hardware_threads=
    std::thread::hardware_concurrency();

  unsigned long const num_threads=
    std::min(hardware_threads!=0?hardware_threads:2,max_threads);

  unsigned long const block_size=length/num_threads;

  std::promise<Iterator> result;  // 8
  std::atomic<bool> done_flag(false);  // 9
  std::vector<std::thread> threads(num_threads-1);
  {  // 10
    join_threads joiner(threads);
    
    Iterator block_start=first;
    for(unsigned long i=0;i<(num_threads-1);++i)
    {
      Iterator block_end=block_start;
      std::advance(block_end,block_size);
      threads[i]=std::thread(find_element(),  // 11
                             block_start,block_end,match,
                             &result,&done_flag);
      block_start=block_end;
    }
    find_element()(block_start,last,match,&result,&done_flag);  // 12
  }
  if(!done_flag.load())  //13
  {
    return last;
  }
  return result.get_future().get();  // 14
}
```

代碼8.9中的函數體與之前的例子相似。這次，由find_element類①的函數調用操作實現，循環通過在給定數據塊中的元素，檢查每一步的標識②。如果匹配的元素被找到，就將最終的結果設置到promise③當中，並且在返回前對done_flag④進行設置。

如果有異常拋出，通用處理代碼⑤就會將其捕獲，並且在promise⑥嘗試存儲前對done_flag進行設置。如果對應promise已設置，可能會拋出一個異常，所以這裡⑦發生的任何異常都可以捕獲並丟棄。

當線程調用find_element查詢一個值，或者拋出一個異常時，如果其他線程看到done_flag已設置，其他線程會終止。如果多線程同時找到匹配值或拋出異常，將會產生競爭。不過，這是良性的條件競爭，成功的競爭者會作為“第一個”返回線程。

回到parallel_find函數本身，其擁有用來停止搜索的promise⑧和標識⑨。隨著對元素的查找⑪，promise和標識會傳遞到新線程中。主線程也使用find_element對剩下的元素進行查找⑫。像之前提到的，需要在全部線程結束前，對結果進行檢查，因為結果可能是任意位置上的匹配元素。將“啟動-匯入”代碼放在一個塊中⑩，所有線程都會在找到匹配元素時⑬進行匯入。如果找到匹配元素，就可以調用`std::future<Iterator>`(來自promise⑭)的成員函數get()來獲取返回值或異常。

不過，假設使用硬件上所有可用的的線程，或使用其他機制對線程上的任務進行提前劃分，可以使用`std::async`，以及遞歸數據劃分的方式來簡化實現(同時使用C++標準庫中提供的自動縮放工具)。使用`std::async`的parallel_find實現如下所示。

代碼8.10 使用`std::async`實現的並行find算法

```c++
template<typename Iterator,typename MatchType>  // 1
Iterator parallel_find_impl(Iterator first,Iterator last,MatchType match,
                            std::atomic<bool>& done)
{
  try
  {
    unsigned long const length=std::distance(first,last);
    unsigned long const min_per_thread=25;  // 2
    if(length<(2*min_per_thread))  // 3
    {
      for(;(first!=last) && !done.load();++first)  // 4
      {
        if(*first==match)
        {
          done=true;  // 5
          return first;
        }
      }
      return last;  // 6
    }
    else
    { 
      Iterator const mid_point=first+(length/2);  // 7
      std::future<Iterator> async_result=
        std::async(&parallel_find_impl<Iterator,MatchType>,  // 8
                   mid_point,last,match,std::ref(done));
      Iterator const direct_result=
        parallel_find_impl(first,mid_point,match,done);  // 9
      return (direct_result==mid_point)?
        async_result.get():direct_result;  // 10
    }
  }
  catch(...)
  {
    done=true;  // 11
    throw;
  }
}

template<typename Iterator,typename MatchType>
Iterator parallel_find(Iterator first,Iterator last,MatchType match)
{
  std::atomic<bool> done(false);
  return parallel_find_impl(first,last,match,done);  // 12
}
```

如果想要在找到匹配項時結束，就需要在線程間設置標識，來表明匹配項已找到。因此，需要將這個標識遞歸傳遞。通過函數①的方式來實現，只需要增加一個參數done標識的引用，用來表示通過主入口點傳入⑫。

核心實現和之前的代碼一樣。函數的實現中，會讓單個線程處理最少的數據項②。如果數據塊大小不足以分成兩半，就要讓當前線程完成所有的工作③。實際算法在一個簡單的循環中，直到在循環到指定範圍中的最後一個，或找到匹配項，並對標識進行設置④。如果找到匹配項，標識done就會在返回前進行設置⑤。無論是因為已經查找到最後一個，還是因為其他線程對done進行了設置，查找都會停止。如果沒有找到，會將最後一個元素進行返回⑥。

如果給定範圍可以進行劃分，首先要在`st::async`在對第二部分進行查找⑧前，要找數據中點⑦，而且需要使用`std::ref`將done以引用的方式傳遞。同時，可以通過對第一部分直接進行遞歸查找。兩部分都為異步，並且在原始範圍過大時，直接遞歸查找的部分可能會再細化。

如果查找返回的是mid_point，這就意味著沒有找到匹配項，所以就要從異步查找中獲取結果。如果在另一半中沒有匹配項的話，返回的結果就一定是last，這個值的返回就代表了沒有找到匹配的元素⑩。如果“異步”調用延遲(非真正的異步)，實際上這裡會運行get()。這種情況下，如果對下半部分的元素搜索成功，就不會執行對上半部分元素的搜索了。如果異步查找真實的運行在其他線程上，那麼async_result的析構函數將會等待該線程完成，所以這裡不會有線程洩露。

`std::async`可以用來提供“異常-安全”和“異常-傳播”特性。如果直接遞歸拋出異常，future的析構函數就能讓異步執行的線程提前結束。如果異步調用拋出異常，這個異常將會通過對get()成員函數的調用進行傳播⑩。使用*try/catch*塊只能捕捉在done時發生的異常，並且有異常拋出⑪時，所有線程都能很快的終止。不過，不使用*try/catch*的實現依舊沒問題，就是要等待所有線程的工作完成。

實現中一個重要的特性，就是不能保證`std::find`能串行處理所有數據。其他並行算法可以借鑑這個特性，因為讓一個算法並行起來這是必須的特性。如果有順序問題，元素就不能併發了。如果每個元素獨立，雖然對於parallel_for_each不是很重要，不過對於parallel_find，即使在開始部分已經找到了匹配元素，也有可能返回範圍中最後一個元素。

OK，現在已經使用了並行化的`std::find`。如在本節開始說的那樣，其他相似算法不需要對每一個數據元素進行處理，並且同樣的技術可以使用到這些類似的算法上去。

為了完成並行“三重奏”，我們將換一個角度來看一下`std::partial_sum`。對於這個算法，沒有太多的文獻可參考，不過讓這個算法並行起來是一件很有趣的事。

## 8.5.3 並行版`std::partial_sum`

`std::partial_sum`會計算給定範圍中的每個元素，並用計算後的結果將原始序列中的值替換掉。比如，有一個序列[1，2，3，4，5]，執行該算法後會成為：[1，3(1+2)，6(1+2+3)，10(1+2+3+4)，15(1+2+3+4+5)]。讓這樣一個算法並行起來會很有趣，因為這裡不能講任務分塊，對每一塊進行獨立的計算。比如，原始序列中的第一個元素需要加到後面的一個元素中去。

確定某個範圍部分和的一種的方式，就是在獨立塊中計算部分和，然後將第一塊中最後的元素的值，與下一塊中的所有元素進行相加，依次類推。如果有個序列[1，2，3，4，5，6，7，8，9]，然後將其分為三塊，那麼在第一次計算後就能得到[{1，3，6}，{4，9，15}，{7，15，24}]。然後將6(第一塊的最後一個元素)加到第二個塊中，那麼就得到[{1，3，6}，{10，15，21}，{7，15，24}]。然後再將第二塊的最後一個元素21加到第三塊中去，就得到[{1，3，6}，{10，15，21}，{28，36，55}]。

將原始數據分割成塊，加上之前塊的部分和就能夠並行了。如果每個塊中的末尾元素都是第一個被更新的，那麼塊中其他的元素就能被其他線程所更新，同時另一個線程對下一塊進行更新，等等。當處理的元素比處理核心的個數多的時候，這樣完成工作沒問題，因為每一個核芯在每一個階段都有合適的數據可以進行處理。

如果有很多的處理器(比處理的元素個數多)，之前的方式就無法正常工作了。如果還是將工作劃分給每個處理器，第一步就沒必要去做了。這種情況下，傳遞結果就意味著讓處理器進行等待，這時需要給這些處於等待中的處理器一些工作。所以，可以採用完全不同的方式來處理這個問題。比起將數據塊中的最後一個元素的結果向後面的元素塊傳遞，可以對部分結果進行傳播：第一次與相鄰的元素(距離為1)相加和(和之前一樣)，之後和距離為2的元素相加，後來和距離為4的元素相加，以此類推。比如：初始序列為[1，2，3，4，5，6，7，8，9]，第一次後為[1，3，5，7，9，11，13，15，17]，第二次後為[1，3，6，10，14，18, 22，26，30]，下一次就要隔4個元素了。第三次後[1, 3, 6, 10, 15, 21, 28, 36, 44]，下一次就要隔8個元素了。第四次後[1, 3, 6, 10, 15, 21, 28, 36, 45]，這就是最終的結果。比起第一種方法多了很多步驟，不過在可併發平臺下，這種方法提高了並行的可行性，每個處理器可在每一步中處理一個數據項。

總體來說，當有N個操作時(每步使用一個處理器)第二種方法需要log(N)[底為2]步。在本節中，N就相當於數據鏈表的長度。比起第一種，每個線程對分配塊做N/k個操作，然後在做N/k次結果傳遞(這裡的k是線程的數量)。因此，第一種方法的時間複雜度為O(N)，不過第二種方法的時間複雜度為Q(Nlog(N))。當數據量和處理器數量相近時，第二種方法需要每個處理器上log(N)個操作，因為需要對結果進行傳遞，第一種方法中每個處理器上執行的操作數會隨著k的增加而增多。對於處理單元較少的情況，第一種方法會比較合適。對於大規模並行系統，第二種方法比較合適。

不管怎麼樣，先將效率問題放一邊，讓我們來看一些代碼。下面的代碼實現的，就是第一種方法。

代碼8.11 使用劃分的方式進行並行求和

```c++
template<typename Iterator>
void parallel_partial_sum(Iterator first,Iterator last)
{
  typedef typename Iterator::value_type value_type;
  
  struct process_chunk  // 1
  {
    void operator()(Iterator begin,Iterator last,
                    std::future<value_type>* previous_end_value,
                    std::promise<value_type>* end_value)
    {
      try
      {
        Iterator end=last;
        ++end;
        std::partial_sum(begin,end,begin);  // 2
        if(previous_end_value)  // 3
        {
          value_type& addend=previous_end_value->get();  // 4
          *last+=addend;  // 5
          if(end_value)
          {
            end_value->set_value(*last);  // 6
          }
          std::for_each(begin,last,[addend](value_type& item)  // 7
                        {
                          item+=addend;
                        });
         }
         else if(end_value)
         {
           end_value->set_value(*last);  // 8
         }
       }
       catch(...)  // 9
       {
         if(end_value)
         {
           end_value->set_exception(std::current_exception());  // 10
         }
         else
         {
           throw;  // 11
         }
       }
     }
   };

  unsigned long const length=std::distance(first,last);

  if(!length)
    return last;

  unsigned long const min_per_thread=25;  // 12
  unsigned long const max_threads=
    (length+min_per_thread-1)/min_per_thread;

  unsigned long const hardware_threads=
    std::thread::hardware_concurrency();

  unsigned long const num_threads=
    std::min(hardware_threads!=0?hardware_threads:2,max_threads);

  unsigned long const block_size=length/num_threads;

  typedef typename Iterator::value_type value_type;

  std::vector<std::thread> threads(num_threads-1);  // 13
  std::vector<std::promise<value_type> >
    end_values(num_threads-1);  // 14
  std::vector<std::future<value_type> >
    previous_end_values;  // 15
  previous_end_values.reserve(num_threads-1);  // 16
  join_threads joiner(threads);

  Iterator block_start=first;
  for(unsigned long i=0;i<(num_threads-1);++i)
  {
    Iterator block_last=block_start;
    std::advance(block_last,block_size-1);  // 17
    threads[i]=std::thread(process_chunk(),  // 18
                           block_start,block_last,
                           (i!=0)?&previous_end_values[i-1]:0,
                           &end_values[i]);
    block_start=block_last;
    ++block_start;  // 19
    previous_end_values.push_back(end_values[i].get_future());  // 20
  }
  Iterator final_element=block_start;
  std::advance(final_element,std::distance(block_start,last)-1);  // 21
  process_chunk()(block_start,final_element,  // 22
                  (num_threads>1)?&previous_end_values.back():0,
                  0);
}
```

這個實現中使用的結構體和之前一樣，將問題進行分塊解決，每個線程處理最小的數據塊⑫。其中，有一組線程⑬和一組promise⑭用來存儲每塊中的最後一個值，並且實現中還有一組future⑮，用來對前一塊中的最後一個值進行檢索。可以為future⑯進行存儲，以避免生成新線程時再分配。

主循環和之前一樣，不過這次是讓迭代器指向了每個數據塊的最後一個元素，而不是作為普通值傳遞到最後⑰，這樣就方便向其他塊傳遞當前塊的最後一個元素了。實際處理是在process_chunk函數對象中完成，這個結構體看上去不是很長。當前塊的開始和結束迭代器和前塊中最後一個值的future一起，作為參數進行傳遞，並且promise用來保留當前範圍內最後一個值的原始值⑱。

生成新線程後，就對開始塊ID進行更新，別忘了傳遞最後一個元素⑲，並且將當前塊的最後一個元素存儲到future，上面的數據將在循環中再次使用到⑳。

處理最後一個數據塊前，需要獲取之前數據塊中最後一個元素的迭代器(21)，這樣就可以將其作為參數傳入process_chunk(22)中了。`std::partial_sum`不會返回一個值，所以在最後一個數據塊被處理後，就不用再做任何事情了。當所有線程的操作完成時，求部分和的操作也就算完成了。

來看一下process_chunk函數對象①。對於整塊的處理始於對`std::partial_sum`的調用，包括對於最後一個值的處理②，需要了解當前塊是否是第一塊③。如果不是第一塊，就會有previous_end_value值從前面的塊傳過來，所以需要等待這個值的產生④。為了將算法的並行最大化，需要對最後一個元素進行更新⑤，這就能將值傳遞給下一個數據塊(如果有下一個數據塊的話)⑥。當完成這個操作，就可以使用`std::for_each`和簡單的Lambda函數⑦對剩餘的數據項進行更新。

如果previous_end_value值為空，當前數據塊就是第一個數據塊，所以只需要為下一個數據塊更新end_value⑧。

最後，如果有操作拋出異常可以將其捕獲⑨，並且存入promise⑩，在下一個數據塊嘗試獲取前一個數據塊的最後一個值④時，異常會再次拋出。處理最後一個數據塊時，異常會重新拋出⑪，因為拋出動作會在主線程上進行。

因為線程間需要同步，這裡就不容易使用`std::async`重寫了。任務等待會讓線程中途去執行其他任務，所以所有的任務必須同時執行。

基於塊的方法就介紹到這裡，讓我們來看一下第二種計算方式。

**實現以2的冪級數為距離的算法**

第二種算法通過增加距離的方式，讓更多的處理器充分發揮作用。這種情況下，沒有同步的必要了，因為所有中間結果都直接傳遞到下一個處理器上去了。實際中我們很少見到單個處理器處理對一定數量的元素執行同一條指令，這種方式稱為*單指令-多數據流*(SIMD)。因此，代碼必須能處理通用情況，並且需要對線程進行顯式同步。

完成這種功能的一種方式是使用*柵欄*(barrier)：只有所有線程都到達柵欄處，才能進行之後的操作，先到達的線程必須等待未到達的線程。C++11標準庫沒有直接提供這樣的工具，所以需要自行設計。

試想遊樂場中的過山車。如果有適量的遊客在等待，過山車管理員就要保證，在過山車啟動前，每一個位置都得坐一個遊客。柵欄的工作原理也一樣：已知了“座位”的數量，線程就是要等待所有“座位”都坐滿。當等待線程夠數，它們可以繼續運行。這時，柵欄會重置，並且會讓下一撥線程等待。通常會在循環中這樣做，當同一個線程再次到達柵欄處，它會再次等待。這種方法是為了讓線程同步，所以不會有線程在其他未完成的情況下，去完成下一個任務。如果有線程提前執行，這樣的算法就是一場災難，因為提前出發的線程可能會修改要被其他線程使用到的數據，後面線程獲取到的數據就不正確了。

下面的代碼就簡單的實現了一個柵欄。

代碼8.12 簡單的柵欄類

```c++
class barrier
{
  unsigned const count;
  std::atomic<unsigned> spaces;
  std::atomic<unsigned> generation;
public:
  explicit barrier(unsigned count_):  // 1
    count(count_),spaces(count),generation(0)
  {}

  void wait()
  {
    unsigned const my_generation=generation;  // 2
    if(!--spaces)  // 3
    {
      spaces=count;  // 4
      ++generation;  // 5
    }
    else
    {
      while(generation==my_generation)  // 6
        std::this_thread::yield();  // 7
    }
  }
};
```

這個實現中，用一定數量的“座位”構造了barrier①，這個數量將會存儲count變量中。起初，柵欄中的spaces與count數量相當。當有線程都在等待時，spaces的數量就會減少③。當spaces的數量減到0時，spaces的值將會重置為count④，並且generation變量會增加，向線程發出信號，讓這些等待線程能夠繼續運行⑤。如果spaces沒有到達0，則線程會繼續等待。這個實現使用了簡單的自旋鎖⑥，對generation的檢查會在wait()開始時進行②。因為generation只會在所有線程都到達柵欄的時候更新⑤，所以在等待的時候使用yield()⑦就不會讓CPU處於忙等待。

這個實現比較“簡單”：使用自旋等待的情況下，如果讓線程等待很長時間就不會很理想，並且如果超過count數量的線程對wait()進行調用，這個實現就沒有辦法工作了。如果想要很好的處理這樣的情況，必須使用一個更加健壯(更加複雜)的實現。我依舊堅持對原子變量操作順序的一致性，因為這會讓事情更加簡單，有時還是需要放鬆這樣的約束。全局同步對於大規模並行架構來說消耗巨大，因為相關處理器會穿梭於存儲柵欄狀態的緩存行中(可見8.2.2中對乒乓緩存的討論)，所以需要格外小心，來確保使用的是最佳同步方法。如果支持併發技術規範擴展，這裡就可以使用`std::experimental::barrier`(如第4章所述)。

不論怎麼樣，都需要有固定數量的線程執行同步循環，大多數情況下線程數量都是固定的。代碼起始部分的幾個數據項，只需要幾步就能得到其最終值。這就意味著，無論是讓所有線程循環處理範圍內的所有元素，還是讓柵欄來同步線程，都會遞減count的值。我會選擇後者(柵欄)，能避免線程做不必要的工作，並且僅僅需要等待最終步驟完成。

要將count改為一個原子變量，這樣在多線程對其進行更新的時候，就不需要添加額外的同步：

```c++
std::atomic<unsigned> count;
```

初始化保持不變，不過當spaces的值被重置後，需要顯式的對count進行load()操作：

```c++
spaces=count.load();
```

這就是要對wait()函數的改動。現在需要一個新的成員函數來遞減count，這個函數命名為done_waiting()，當一個線程完成其工作並在等待時才能調用它：

```c++
void done_waiting()
{
  --count;  // 1
  if(!--spaces)  // 2
  {
    spaces=count.load();  // 3
    ++generation;
  }
}
```

實現中，首先要減少count①，所以spaces下一次將會置為一個較小的數。然後，需要遞減spaces的值②。如果不做這些操作，有些線程將會持續等待，因為spaces被舊的count初始化，從而大於期望值。一組當中最後一個線程需要對計數器進行重置，並且遞增generation的值③，就像在wait()裡面做的那樣。最重要的區別：最後一個線程不需要等待。當最後一個線程結束，整個等待也就隨之結束！

現在就準備開始寫部分和的第二個實現吧。每一步中的每一個線程都在柵欄處調用wait()，從而保證線程所處步驟的一致性，並且當所有線程都結束，最後一個線程會調用done_waiting()來減少count的值。如果使用兩個緩存對原始數據進行保存，柵欄也可以提供所需要的同步。每一步中線程都會從原始數據或緩存中讀取數據，並且將新值寫入對應位置。如果線程先從原始數據處獲取數據，下一步就從緩存上獲取數據(或相反)。這就能保證讀與寫都是由獨立線程完成，並不存在條件競爭。當線程結束等待循環，就能保證正確的值寫入到原始數據當中。

代碼8.13 通過兩兩更新的方式實現partial_sum

```c++
struct barrier
{
  std::atomic<unsigned> count;
  std::atomic<unsigned> spaces;
  std::atomic<unsigned> generation;

  barrier(unsigned count_):
    count(count_),spaces(count_),generation(0)
  {}

  void wait()
  {
    unsigned const gen=generation.load();
    if(!--spaces)
    {
      spaces=count.load();
      ++generation;
    }
    else
    {
      while(generation.load()==gen)
      {
        std::this_thread::yield();
      }
    }
  }

  void done_waiting()
  {
    --count;
    if(!--spaces)
    {
      spaces=count.load();
      ++generation;
    }
  }
};

template<typename Iterator>
void parallel_partial_sum(Iterator first,Iterator last)
{
  typedef typename Iterator::value_type value_type;

  struct process_element  // 1
  {
    void operator()(Iterator first,Iterator last,
                    std::vector<value_type>& buffer,
                    unsigned i,barrier& b)
    {
      value_type& ith_element=*(first+i);
      bool update_source=false;

      for(unsigned step=0,stride=1;stride<=i;++step,stride*=2)
      {
        value_type const& source=(step%2)?  // 2
          buffer[i]:ith_element;

        value_type& dest=(step%2)?
          ith_element:buffer[i];

        value_type const& addend=(step%2)?  // 3
          buffer[i-stride]:*(first+i-stride);

        dest=source+addend;  // 4
        update_source=!(step%2);
        b.wait();  // 5
      }
      if(update_source)  // 6
      {
        ith_element=buffer[i];
      }
      b.done_waiting();  // 7
    }
  };

  unsigned long const length=std::distance(first,last);
  
  if(length<=1)
    return;

  std::vector<value_type> buffer(length);
  barrier b(length);

  std::vector<std::thread> threads(length-1);  // 8
  join_threads joiner(threads);

  Iterator block_start=first;
  for(unsigned long i=0;i<(length-1);++i)
  {
    threads[i]=std::thread(process_element(),first,last,  // 9
                           std::ref(buffer),i,std::ref(b));
  }
  process_element()(first,last,buffer,length-1,b);  // 10
}
```

代碼的整體結構應該不用說了。process_element類有函數調用操作可以用來做具體的工作①，就是運行一組線程⑨，並將線程存儲到vector中⑧，同樣還需要在主線程中對其進行調用⑩。這裡與之前最大的區別就是，線程的數量是根據列表中的數據量來定的，而不是根據`std::thread::hardware_concurrency`。如之前所說，除非使用的是一個大規模並行的機器，因為這上面的線程都十分廉價(雖然這樣的方式並不是很好)，還能為我們展示了其整體結構。這個結構在有較少線程的時候，每一個線程只能處理源數據中的部分數據。

不管怎樣，主要的工作都是調用process_element的函數操作符來完成的。每一步，都會從原始數據或緩存中獲取第i個元素②，並且將獲取到的元素加到指定stride的元素中去③，如果從原始數據開始讀取的元素，加和後的數需要存儲在緩存中④，在開始下一步前會在柵欄處等待⑤。當stride超出了給定數據的範圍，最終結果已經存在緩存中時，就需要更新原始數據中的數據，同樣這也意味著本次加和結束。最後，再調用柵欄中的done_waiting()函數⑦。

注意這個解決方案並不是異常安全的。如果某個線程在process_element執行時拋出一個異常，就會終止整個應用。可以使用一個`std::promise`來存儲異常，就像在代碼8.9中parallel_find的實現，或僅使用互斥量保護的`std::exception_ptr`即可。

總結下這三個例子。希望其能讓我們瞭解8.1、8.2、8.3和8.4節中提到的設計考量，並且證明瞭這些技術在真實的代碼中需要承擔哪些責任。

---------

[4] http://threadingbuildingblocks.org/