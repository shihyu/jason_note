# ClickHouse Docker å®Œæ•´éƒ¨ç½²æŒ‡å—

## ğŸ“‹ ç›®éŒ„
- [ç³»çµ±éœ€æ±‚](#ç³»çµ±éœ€æ±‚)
- [å¿«é€Ÿå®‰è£](#å¿«é€Ÿå®‰è£)
- [ç”Ÿç”¢ç’°å¢ƒé…ç½®](#ç”Ÿç”¢ç’°å¢ƒé…ç½®)
- [è‡ªå‹•å‚™ä»½è¨­ç½®](#è‡ªå‹•å‚™ä»½è¨­ç½®)
- [æ¸¬è©¦ç¯„ä¾‹](#æ¸¬è©¦ç¯„ä¾‹)
- [ç›£æ§èˆ‡ç¶­è­·](#ç›£æ§èˆ‡ç¶­è­·)
- [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)

## ç³»çµ±éœ€æ±‚

### æœ€ä½é…ç½®
- CPU: 4 æ ¸å¿ƒ
- RAM: 8 GB
- Storage: 100 GB SSD
- OS: Linux (Ubuntu 20.04+ / CentOS 7+)
- Docker: 20.10+
- Docker Compose: 2.0+

### å»ºè­°é…ç½®
- CPU: 8+ æ ¸å¿ƒ
- RAM: 32+ GB
- Storage: NVMe SSD (è¶Šå¿«è¶Šå¥½)
- Network: 1 Gbps+

## å¿«é€Ÿå®‰è£

### 1. å®‰è£ Docker (Ubuntu ç‚ºä¾‹)
```bash
# æ›´æ–°ç³»çµ±
sudo apt-get update
sudo apt-get upgrade -y

# å®‰è£ Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# å®‰è£ Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# å°‡ç•¶å‰ç”¨æˆ¶åŠ å…¥ docker ç¾¤çµ„
sudo usermod -aG docker $USER
newgrp docker

# é©—è­‰å®‰è£
docker --version
docker-compose --version
```

### 2. å»ºç«‹å°ˆæ¡ˆç›®éŒ„çµæ§‹
```bash
# å»ºç«‹ç›®éŒ„
mkdir -p ~/clickhouse-docker/{config,data,logs,backup,scripts}
cd ~/clickhouse-docker

# å»ºç«‹å¿…è¦çš„ç›®éŒ„æ¬Šé™
sudo mkdir -p /data/clickhouse
sudo chown -R $USER:$USER /data/clickhouse
```

## ç”Ÿç”¢ç’°å¢ƒé…ç½®

### 3. å‰µå»ºå„ªåŒ–çš„ docker-compose.yml
```yaml
# ~/clickhouse-docker/docker-compose.yml
version: '3.8'

services:
  clickhouse:
    image: clickhouse/clickhouse-server:24.8-alpine
    container_name: clickhouse-server
    hostname: clickhouse-server
    
    # æ•ˆèƒ½å„ªåŒ–ï¼šä½¿ç”¨ host ç¶²è·¯æ¨¡å¼
    network_mode: host
    
    # ç’°å¢ƒè®Šæ•¸
    environment:
      # åˆå§‹è³‡æ–™åº«è¨­ç½®
      CLICKHOUSE_DB: market_data
      CLICKHOUSE_USER: trader
      CLICKHOUSE_PASSWORD: SecurePass123!
      CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT: 1
      # æ•ˆèƒ½ç›¸é—œ
      CLICKHOUSE_MAX_MEMORY_USAGE: 10000000000  # 10GB
      CLICKHOUSE_MAX_MEMORY_USAGE_FOR_USER: 10000000000
      
    # è³‡æºé™åˆ¶
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 16G
        reservations:
          cpus: '2'
          memory: 8G
    
    # æ›è¼‰è¨­å®š
    volumes:
      # è³‡æ–™ç›®éŒ„ - ä½¿ç”¨æœ¬åœ° SSD
      - type: bind
        source: /data/clickhouse
        target: /var/lib/clickhouse
      # æ—¥èªŒç›®éŒ„
      - type: bind
        source: ./logs
        target: /var/log/clickhouse-server
      # è‡ªå®šç¾©é…ç½®
      - type: bind
        source: ./config
        target: /etc/clickhouse-server/config.d
        read_only: true
      # å‚™ä»½ç›®éŒ„
      - type: bind
        source: ./backup
        target: /backups
    
    # ç³»çµ±é™åˆ¶å„ªåŒ–
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
      memlock:
        soft: -1
        hard: -1
      nproc:
        soft: 131072
        hard: 131072
    
    # å¥åº·æª¢æŸ¥
    healthcheck:
      test: ["CMD", "clickhouse-client", "--host", "localhost", "--query", "SELECT 1"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 30s
    
    # è‡ªå‹•é‡å•Ÿ
    restart: unless-stopped
    
    # æ—¥èªŒè¨­ç½®
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"
```

### 4. å‰µå»ºè‡ªå®šç¾©é…ç½®æ–‡ä»¶

#### å„²å­˜å„ªåŒ–é…ç½®
```xml
<!-- ~/clickhouse-docker/config/storage.xml -->
<?xml version="1.0"?>
<clickhouse>
    <storage_configuration>
        <disks>
            <default>
                <path>/var/lib/clickhouse/</path>
            </default>
            <fast_ssd>
                <path>/var/lib/clickhouse/fast/</path>
            </fast_ssd>
        </disks>
        <policies>
            <tiered>
                <volumes>
                    <hot>
                        <disk>fast_ssd</disk>
                        <max_data_part_size_bytes>10737418240</max_data_part_size_bytes>
                    </hot>
                    <cold>
                        <disk>default</disk>
                    </cold>
                </volumes>
                <move_factor>0.2</move_factor>
            </tiered>
        </policies>
    </storage_configuration>
    
    <!-- å£“ç¸®è¨­ç½® -->
    <compression>
        <case>
            <method>lz4hc</method>
            <level>12</level>
        </case>
    </compression>
</clickhouse>
```

#### æ•ˆèƒ½å„ªåŒ–é…ç½®
```xml
<!-- ~/clickhouse-docker/config/performance.xml -->
<?xml version="1.0"?>
<clickhouse>
    <!-- æŸ¥è©¢æ•ˆèƒ½å„ªåŒ– -->
    <max_threads>8</max_threads>
    <max_memory_usage>10000000000</max_memory_usage>
    <max_memory_usage_for_user>10000000000</max_memory_usage_for_user>
    <max_bytes_before_external_group_by>5000000000</max_bytes_before_external_group_by>
    
    <!-- ç¶²è·¯å„ªåŒ– -->
    <max_concurrent_queries>100</max_concurrent_queries>
    <max_connections>4096</max_connections>
    
    <!-- èƒŒæ™¯ä»»å‹™å„ªåŒ– -->
    <background_pool_size>16</background_pool_size>
    <background_schedule_pool_size>16</background_schedule_pool_size>
    
    <!-- MergeTree å„ªåŒ– -->
    <merge_tree>
        <max_suspicious_broken_parts>5</max_suspicious_broken_parts>
        <max_parts_in_total>100000</max_parts_in_total>
        <max_bytes_to_merge_at_max_space_in_pool>161061273600</max_bytes_to_merge_at_max_space_in_pool>
    </merge_tree>
</clickhouse>
```

## è‡ªå‹•å‚™ä»½è¨­ç½®

### 5. å‚™ä»½è…³æœ¬

#### ä¸»å‚™ä»½è…³æœ¬
```bash
#!/bin/bash
# ~/clickhouse-docker/scripts/backup.sh

# è¨­å®šè®Šæ•¸
BACKUP_DIR="/home/$USER/clickhouse-docker/backup"
CONTAINER_NAME="clickhouse-server"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=7
LOG_FILE="$BACKUP_DIR/backup.log"

# é¡è‰²è¼¸å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# æ—¥èªŒå‡½æ•¸
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# éŒ¯èª¤è™•ç†
error_exit() {
    echo -e "${RED}[ERROR]${NC} $1" | tee -a "$LOG_FILE"
    exit 1
}

# æª¢æŸ¥å®¹å™¨æ˜¯å¦é‹è¡Œ
check_container() {
    if ! docker ps --format '{{.Names}}' | grep -q "^${CONTAINER_NAME}$"; then
        error_exit "Container ${CONTAINER_NAME} is not running!"
    fi
}

# åŸ·è¡Œå‚™ä»½
perform_backup() {
    log "Starting backup..."
    
    # æ–¹æ³• 1: ä½¿ç”¨ ClickHouse åŸç”Ÿå‚™ä»½ï¼ˆæ¨è–¦ï¼‰
    log "Creating ClickHouse native backup..."
    
    # å‰µå»ºæ‰€æœ‰è¡¨çš„å‚™ä»½
    docker exec $CONTAINER_NAME clickhouse-client --query "
        SELECT concat('BACKUP TABLE ', database, '.', name, ' TO Disk(''backups'', ''', '${DATE}/', database, '_', name, ''');')
        FROM system.tables 
        WHERE database NOT IN ('system', 'information_schema', 'INFORMATION_SCHEMA')
    " | while read backup_cmd; do
        if [ ! -z "$backup_cmd" ]; then
            docker exec $CONTAINER_NAME clickhouse-client --query "$backup_cmd" || log "Warning: Failed to backup a table"
        fi
    done
    
    # æ–¹æ³• 2: ç‰©ç†å‚™ä»½ï¼ˆå®Œæ•´å‚™ä»½ï¼‰
    log "Creating physical backup..."
    docker exec $CONTAINER_NAME bash -c "
        tar czf /backups/physical_backup_${DATE}.tar.gz \
        --exclude='/var/lib/clickhouse/preprocessed_configs' \
        --exclude='/var/lib/clickhouse/tmp' \
        /var/lib/clickhouse/data \
        /var/lib/clickhouse/metadata
    " || error_exit "Physical backup failed"
    
    # å‚™ä»½é…ç½®æ–‡ä»¶
    log "Backing up configuration..."
    tar czf "$BACKUP_DIR/config_backup_${DATE}.tar.gz" \
        -C ~/clickhouse-docker config/ docker-compose.yml \
        || error_exit "Config backup failed"
    
    log "Backup completed successfully!"
}

# æ¸…ç†èˆŠå‚™ä»½
cleanup_old_backups() {
    log "Cleaning up old backups (older than $RETENTION_DAYS days)..."
    
    # æ¸…ç†æœ¬åœ°å‚™ä»½
    find "$BACKUP_DIR" -name "*.tar.gz" -type f -mtime +$RETENTION_DAYS -delete
    
    # æ¸…ç†å®¹å™¨å…§å‚™ä»½
    docker exec $CONTAINER_NAME bash -c "
        find /backups -name '*.tar.gz' -type f -mtime +$RETENTION_DAYS -delete
    "
    
    log "Cleanup completed"
}

# é¡¯ç¤ºå‚™ä»½è³‡è¨Š
show_backup_info() {
    echo -e "${GREEN}=== Backup Information ===${NC}"
    echo "Backup Location: $BACKUP_DIR"
    echo "Latest Backups:"
    ls -lah "$BACKUP_DIR" | grep -E "*.tar.gz" | tail -5
    
    # é¡¯ç¤ºå‚™ä»½å¤§å°çµ±è¨ˆ
    total_size=$(du -sh "$BACKUP_DIR" 2>/dev/null | cut -f1)
    echo -e "\nTotal backup size: ${YELLOW}$total_size${NC}"
}

# ä¸»ç¨‹åº
main() {
    echo -e "${GREEN}=== ClickHouse Backup Script ===${NC}"
    
    # å‰µå»ºå‚™ä»½ç›®éŒ„
    mkdir -p "$BACKUP_DIR"
    
    # åŸ·è¡Œå‚™ä»½æµç¨‹
    check_container
    perform_backup
    cleanup_old_backups
    show_backup_info
    
    echo -e "${GREEN}âœ… Backup process completed!${NC}"
}

# åŸ·è¡Œä¸»ç¨‹åº
main
```

#### é‚„åŸè…³æœ¬
```bash
#!/bin/bash
# ~/clickhouse-docker/scripts/restore.sh

# è¨­å®šè®Šæ•¸
BACKUP_DIR="/home/$USER/clickhouse-docker/backup"
CONTAINER_NAME="clickhouse-server"

# é¡è‰²è¼¸å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

# åˆ—å‡ºå¯ç”¨å‚™ä»½
list_backups() {
    echo -e "${GREEN}=== Available Backups ===${NC}"
    ls -la "$BACKUP_DIR" | grep -E "physical_backup.*tar.gz" | nl
}

# é‚„åŸå‚™ä»½
restore_backup() {
    list_backups
    
    echo -e "${YELLOW}Enter the number of backup to restore:${NC}"
    read backup_num
    
    backup_file=$(ls "$BACKUP_DIR" | grep -E "physical_backup.*tar.gz" | sed -n "${backup_num}p")
    
    if [ -z "$backup_file" ]; then
        echo -e "${RED}Invalid selection!${NC}"
        exit 1
    fi
    
    echo -e "${YELLOW}âš ï¸  WARNING: This will stop ClickHouse and restore data!${NC}"
    echo "Restore from: $backup_file"
    echo "Continue? (yes/no)"
    read confirm
    
    if [ "$confirm" != "yes" ]; then
        echo "Restore cancelled"
        exit 0
    fi
    
    # åœæ­¢å®¹å™¨
    echo "Stopping ClickHouse..."
    docker-compose -f ~/clickhouse-docker/docker-compose.yml down
    
    # å‚™ä»½ç•¶å‰æ•¸æ“šï¼ˆå®‰å…¨èµ·è¦‹ï¼‰
    echo "Backing up current data..."
    sudo mv /data/clickhouse /data/clickhouse.old.$(date +%Y%m%d_%H%M%S)
    sudo mkdir -p /data/clickhouse
    
    # è§£å£“å‚™ä»½
    echo "Restoring backup..."
    sudo tar xzf "$BACKUP_DIR/$backup_file" -C / --strip-components=2
    
    # ä¿®æ­£æ¬Šé™
    sudo chown -R 101:101 /data/clickhouse
    
    # é‡å•Ÿå®¹å™¨
    echo "Starting ClickHouse..."
    docker-compose -f ~/clickhouse-docker/docker-compose.yml up -d
    
    # ç­‰å¾…æœå‹™å•Ÿå‹•
    sleep 10
    
    # æª¢æŸ¥æœå‹™ç‹€æ…‹
    docker exec $CONTAINER_NAME clickhouse-client --query "SELECT 'Restore completed successfully!'"
    
    echo -e "${GREEN}âœ… Restore completed!${NC}"
}

# ä¸»ç¨‹åº
restore_backup
```

### 6. è¨­ç½® Crontab è‡ªå‹•å‚™ä»½
```bash
# ä½¿è…³æœ¬å¯åŸ·è¡Œ
chmod +x ~/clickhouse-docker/scripts/*.sh

# è¨­ç½®æ¯æ—¥è‡ªå‹•å‚™ä»½ (æ¯å¤©å‡Œæ™¨ 2 é»)
crontab -e

# æ·»åŠ ä»¥ä¸‹è¡Œ
0 2 * * * /home/$USER/clickhouse-docker/scripts/backup.sh >> /home/$USER/clickhouse-docker/backup/cron.log 2>&1
```

## æ¸¬è©¦ç¯„ä¾‹

### 7. å•Ÿå‹•æœå‹™
```bash
cd ~/clickhouse-docker
docker-compose up -d

# æª¢æŸ¥ç‹€æ…‹
docker-compose ps
docker logs clickhouse-server --tail 50
```

### 8. å‰µå»ºæ¸¬è©¦è¡¨ä¸¦å°å…¥æ•¸æ“š

#### å‰µå»ºå¸‚å ´æ•¸æ“šè¡¨
```sql
# é€£æ¥åˆ° ClickHouse
docker exec -it clickhouse-server clickhouse-client --user trader --password SecurePass123!

-- å‰µå»ºè³‡æ–™åº«
CREATE DATABASE IF NOT EXISTS market_data;
USE market_data;

-- å‰µå»ºå„ªåŒ–çš„ tick æ•¸æ“šè¡¨
CREATE TABLE market_ticks (
    ts DateTime64(3) CODEC(DoubleDelta, LZ4),
    symbol LowCardinality(String),
    close Decimal32(2) CODEC(Gorilla, LZ4),
    volume UInt32 CODEC(T64, LZ4),
    bid_price Decimal32(2) CODEC(Gorilla, LZ4),
    bid_volume UInt32 CODEC(T64, LZ4),
    ask_price Decimal32(2) CODEC(Gorilla, LZ4),
    ask_volume UInt32 CODEC(T64, LZ4),
    tick_type UInt8
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(ts)
ORDER BY (symbol, ts)
SETTINGS index_granularity = 8192;

-- æŸ¥çœ‹è¡¨çµæ§‹
DESCRIBE TABLE market_ticks;
```

#### å°å…¥æ¸¬è©¦æ•¸æ“š
```bash
# å‰µå»ºæ¸¬è©¦ CSV æ–‡ä»¶
cat > ~/clickhouse-docker/test_data.csv << 'EOF'
ts,symbol,close,volume,bid_price,bid_volume,ask_price,ask_volume,tick_type
2025-09-25 17:25:00.044,AAPL,1325.0,7,1320.0,160,1325.0,22,1
2025-09-25 17:25:02.207,AAPL,1325.0,1,1320.0,160,1325.0,22,1
2025-09-25 17:25:03.125,AAPL,1325.0,1,1320.0,161,1325.0,21,1
2025-09-25 17:25:47.863,AAPL,1325.0,1,1320.0,162,1325.0,21,1
2025-09-25 17:26:14.894,TSLA,1325.0,1,1320.0,181,1325.0,18,1
2025-09-25 17:26:51.365,TSLA,1325.0,1,1320.0,181,1325.0,27,1
2025-09-25 17:29:59.655,TSLA,1325.0,3,1320.0,177,1325.0,31,1
2025-09-25 17:30:06.262,NVDA,1325.0,1,1320.0,180,1325.0,28,1
2025-09-25 17:30:14.542,NVDA,1325.0,3,1320.0,183,1325.0,27,1
2025-09-25 17:30:52.600,NVDA,1320.0,2,1320.0,185,1325.0,22,2
EOF

# å°å…¥æ•¸æ“š
docker exec -i clickhouse-server clickhouse-client \
    --user trader --password SecurePass123! \
    --query "INSERT INTO market_data.market_ticks FORMAT CSVWithNames" \
    < ~/clickhouse-docker/test_data.csv
```

### 9. æ¸¬è©¦æŸ¥è©¢

#### åŸºæœ¬æŸ¥è©¢æ¸¬è©¦
```sql
-- é€£æ¥åˆ°è³‡æ–™åº«
docker exec -it clickhouse-server clickhouse-client \
    --user trader --password SecurePass123! \
    --database market_data

-- æŸ¥è©¢è¨˜éŒ„æ•¸
SELECT count(*) FROM market_ticks;

-- æŸ¥çœ‹æœ€æ–°æ•¸æ“š
SELECT * FROM market_ticks ORDER BY ts DESC LIMIT 5;

-- æŒ‰ symbol èšåˆ
SELECT 
    symbol,
    count(*) as tick_count,
    avg(close) as avg_price,
    max(volume) as max_volume
FROM market_ticks
GROUP BY symbol;

-- æ™‚é–“ç¯„åœæŸ¥è©¢
SELECT *
FROM market_ticks
WHERE ts >= '2025-09-25 17:25:00'
  AND ts <= '2025-09-25 17:30:00'
ORDER BY ts;

-- æŸ¥çœ‹å£“ç¸®æ•ˆæœ
SELECT 
    formatReadableSize(sum(data_compressed_bytes)) as compressed,
    formatReadableSize(sum(data_uncompressed_bytes)) as uncompressed,
    round(sum(data_uncompressed_bytes) / sum(data_compressed_bytes), 2) as ratio
FROM system.parts
WHERE database = 'market_data' AND table = 'market_ticks';
```

#### æ•ˆèƒ½æ¸¬è©¦
```sql
-- æ’å…¥å¤§é‡æ¸¬è©¦æ•¸æ“š
INSERT INTO market_ticks 
SELECT 
    now() - randUniform(0, 86400) as ts,
    arrayElement(['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'NVDA'], randUniform(1, 5)) as symbol,
    1000 + randNormal(0, 50) as close,
    randUniform(1, 1000) as volume,
    1000 + randNormal(-5, 45) as bid_price,
    randUniform(1, 500) as bid_volume,
    1000 + randNormal(5, 55) as ask_price,
    randUniform(1, 500) as ask_volume,
    randUniform(1, 3) as tick_type
FROM numbers(1000000);

-- æ¸¬è©¦æŸ¥è©¢æ•ˆèƒ½
SELECT 
    symbol,
    toStartOfMinute(ts) as minute,
    avg(close) as avg_price,
    sum(volume) as total_volume
FROM market_ticks
WHERE ts >= now() - INTERVAL 1 DAY
GROUP BY symbol, minute
ORDER BY minute DESC, symbol
LIMIT 100
FORMAT Null;

-- é¡¯ç¤ºæŸ¥è©¢çµ±è¨ˆ
SHOW PROCESSLIST;
```

## ç›£æ§èˆ‡ç¶­è­·

### 10. ç›£æ§è…³æœ¬
```bash
#!/bin/bash
# ~/clickhouse-docker/scripts/monitor.sh

echo "=== ClickHouse Monitoring Dashboard ==="
echo "======================================="

# ç³»çµ±è³‡æºä½¿ç”¨
echo -e "\nğŸ“Š Resource Usage:"
docker stats clickhouse-server --no-stream

# è³‡æ–™åº«å¤§å°
echo -e "\nğŸ’¾ Database Size:"
docker exec clickhouse-server clickhouse-client --user trader --password SecurePass123! --query "
SELECT 
    database,
    formatReadableSize(sum(bytes_on_disk)) as size,
    formatReadableQuantity(sum(rows)) as rows,
    count() as tables
FROM system.parts
WHERE active
GROUP BY database
FORMAT Pretty"

# æŸ¥è©¢æ•ˆèƒ½
echo -e "\nâš¡ Recent Queries:"
docker exec clickhouse-server clickhouse-client --user trader --password SecurePass123! --query "
SELECT 
    substring(query, 1, 50) as query_preview,
    formatReadableSize(memory_usage) as memory,
    query_duration_ms,
    read_rows,
    written_rows
FROM system.query_log
WHERE type = 'QueryFinish'
ORDER BY event_time DESC
LIMIT 5
FORMAT Pretty"

# ç³»çµ±å¥åº·ç‹€æ…‹
echo -e "\nâœ… Health Check:"
docker exec clickhouse-server clickhouse-client --query "SELECT 'ClickHouse is running OK!'"
```

### 11. æ—¥å¸¸ç¶­è­·å‘½ä»¤
```bash
# å„ªåŒ–è¡¨ï¼ˆæ•´ç†ç¢ç‰‡ï¼‰
docker exec clickhouse-server clickhouse-client --user trader --password SecurePass123! \
    --query "OPTIMIZE TABLE market_data.market_ticks FINAL"

# æ¸…ç†èˆŠåˆ†å€
docker exec clickhouse-server clickhouse-client --user trader --password SecurePass123! \
    --query "ALTER TABLE market_data.market_ticks DROP PARTITION '202501'"

# æŸ¥çœ‹æ…¢æŸ¥è©¢
docker exec clickhouse-server clickhouse-client --user trader --password SecurePass123! \
    --query "
    SELECT 
        query,
        query_duration_ms,
        memory_usage
    FROM system.query_log
    WHERE query_duration_ms > 1000
    ORDER BY query_duration_ms DESC
    LIMIT 10"

# é‡å•Ÿæœå‹™
docker-compose restart

# å‡ç´š ClickHouse
docker-compose pull
docker-compose up -d
```

## å¸¸è¦‹å•é¡Œ

### Q1: è¨˜æ†¶é«”ä¸è¶³éŒ¯èª¤
```bash
# èª¿æ•´è¨˜æ†¶é«”é™åˆ¶
docker exec clickhouse-server clickhouse-client --query "
SET max_memory_usage = 5000000000;
SET max_memory_usage_for_user = 5000000000;"
```

### Q2: ç£ç¢Ÿç©ºé–“ä¸è¶³
```bash
# æª¢æŸ¥ç©ºé–“ä½¿ç”¨
df -h /data/clickhouse

# æ¸…ç†èˆŠæ•¸æ“š
docker exec clickhouse-server clickhouse-client --query "
ALTER TABLE market_data.market_ticks 
DROP PARTITION WHERE toYYYYMM(ts) < toYYYYMM(now() - INTERVAL 6 MONTH)"
```

### Q3: é€£æ¥è¢«æ‹’çµ•
```bash
# æª¢æŸ¥å®¹å™¨ç‹€æ…‹
docker ps | grep clickhouse

# æŸ¥çœ‹æ—¥èªŒ
docker logs clickhouse-server --tail 100

# é‡å•Ÿå®¹å™¨
docker-compose restart
```

### Q4: æŸ¥è©¢å¤ªæ…¢
```sql
-- åˆ†ææŸ¥è©¢è¨ˆç•«
EXPLAIN SELECT * FROM market_ticks WHERE symbol = 'AAPL';

-- å‰µå»ºç´¢å¼•
ALTER TABLE market_ticks ADD INDEX idx_symbol (symbol) TYPE minmax GRANULARITY 4;
```

## æ•ˆèƒ½èª¿å„ªå»ºè­°

1. **ä½¿ç”¨ SSD/NVMe** - I/O æ˜¯æœ€å¤§ç“¶é ¸
2. **é©ç•¶åˆ†å€** - æŒ‰æœˆåˆ†å€å° tick æ•¸æ“šæœ€åˆé©
3. **æ‰¹é‡æ’å…¥** - å–®ç­†æ’å…¥æ•ˆèƒ½å·®ï¼Œå»ºè­°æ‰¹é‡ 10000+ ç­†
4. **å®šæœŸ OPTIMIZE** - æ¯é€±åŸ·è¡Œä¸€æ¬¡ OPTIMIZE TABLE
5. **ç›£æ§è¨˜æ†¶é«”** - ClickHouse æ˜¯è¨˜æ†¶é«”å¯†é›†å‹è³‡æ–™åº«

## å®‰å…¨å»ºè­°

1. **ä¿®æ”¹é è¨­å¯†ç¢¼** - ç«‹å³ä¿®æ”¹ docker-compose.yml ä¸­çš„å¯†ç¢¼
2. **é™åˆ¶ç¶²è·¯å­˜å–** - ä½¿ç”¨é˜²ç«ç‰†é™åˆ¶ 8123/9000 ç«¯å£
3. **å®šæœŸå‚™ä»½** - ç¢ºä¿è‡ªå‹•å‚™ä»½æ­£å¸¸é‹è¡Œ
4. **ç›£æ§æ—¥èªŒ** - å®šæœŸæª¢æŸ¥ç•°å¸¸å­˜å–
5. **æ›´æ–°ç‰ˆæœ¬** - é—œæ³¨å®‰å…¨æ›´æ–°

## æ”¯æ´è³‡æº

- [å®˜æ–¹æ–‡æª”](https://clickhouse.com/docs)
- [Docker Hub](https://hub.docker.com/r/clickhouse/clickhouse-server)
- [GitHub Issues](https://github.com/ClickHouse/ClickHouse/issues)
- [ç¤¾ç¾¤è«–å£‡](https://clickhouse.com/community)

---

**æœ€å¾Œæ›´æ–°**: 2025-09-26  
**ç‰ˆæœ¬**: ClickHouse 24.8  
**ä½œè€…**: DevOps Team