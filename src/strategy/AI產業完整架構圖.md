# AI 產業完整供應鏈架構圖

> **文檔說明**: 本文檔詳細解析 AI 產業從上游晶片製造到下游終端應用的完整生態系統,包括各環節主要廠商、市場佔有率、技術特點和供應鏈關係。
>
> **更新日期**: 2026年1月
> **涵蓋範圍**: AI訓練與推理、數據中心、雲端運算、邊緣AI、光通訊

---

## 📑 文檔目錄

### 產業基礎層 (硬體)
1. [產業大架構總覽](#1-產業大架構總覽)
2. [第一層: AI 晶片製造](#2-第一層-ai-晶片製造)
3. [第二層: AI 散熱系統](#3-第二層-ai-散熱系統)
4. [第三層: 電源供應系統](#4-第三層-電源供應系統)
5. [第四層: 儲存與網路](#5-第四層-儲存與網路)
6. [第五層: 光通訊與高速互連](#6-第五層-光通訊與高速互連)

### 平台與應用層
7. [第六層: 雲端與數據中心](#7-第六層-雲端與數據中心)
8. [第七層: AI 軟體與應用](#8-第七層-ai-軟體與應用)
9. [第八層: 邊緣AI與端側推理](#9-第八層-邊緣ai與端側推理)

### 專題分析
10. [ASIC 客製化晶片專題](#10-asic-客製化晶片專題)
11. [中國 AI 產業鏈](#11-中國-ai-產業鏈)
12. [機器人與具身AI](#12-機器人與具身ai) ⭐ 新增
13. [AI 能源與永續發展](#13-ai-能源與永續發展) ⭐ 新增

### 數據與投資
14. [GPU 產品規格完整對比](#14-gpu-產品規格完整對比)
15. [產業風險與地緣政治](#15-產業風險與地緣政治)
16. [投資標的完整清單](#16-投資標的完整清單)
17. [市場規模與關鍵數據](#17-市場規模與關鍵數據)
18. [關鍵結論與趨勢](#18-關鍵結論與趨勢)

---

## 1. 產業大架構總覽

```
┌──────────────────────────────────────────────────────────────────────────┐
│                          AI 產業生態系統 (2026)                            │
├──────────────────────────────────────────────────────────────────────────┤
│                                                                           │
│  ┌────────────────┐  ┌────────────────┐  ┌────────────────┐            │
│  │   上游硬體層   │  │   中游平台層   │  │   下游應用層   │            │
│  │                │  │                │  │                │            │
│  │ • 晶片設計製造 │  │ • 雲端運算     │  │ • AI 大模型    │            │
│  │ • 先進封裝     │  │ • 數據中心     │  │ • 生成式AI     │            │
│  │ • HBM記憶體    │  │ • 儲存系統     │  │ • 企業AI應用   │            │
│  │ • 散熱系統     │──▶│ • 光通訊互連   │──▶│ • 邊緣AI/端側  │            │
│  │ • 電源供應     │  │ • 高速網路     │  │ • 垂直產業AI   │            │
│  │ • 設備材料     │  │ • 運算平台     │  │ • AI Agent     │            │
│  │                │  │                │  │                │            │
│  └────────────────┘  └────────────────┘  └────────────────┘            │
│                                                                           │
│  ┌──────────────────────────────────────────────────────────────────┐   │
│  │                        關鍵供應鏈節點                              │   │
│  │  NVIDIA(設計) → 台積電(製造) → 日月光(封裝) → SK Hynix(HBM)     │   │
│  │  → 鴻海/廣達(組裝) → Azure/AWS(雲端) → OpenAI/Anthropic(模型)    │   │
│  └──────────────────────────────────────────────────────────────────┘   │
│                                                                           │
└──────────────────────────────────────────────────────────────────────────┘
```

### 1.1 產業演進時間軸

```
2020        2022        2023        2024        2025        2026
  │           │           │           │           │           │
  ▼           ▼           ▼           ▼           ▼           ▼
A100        H100       H100量產    B200發布    B200量產    GB300
300W        700W       ChatGPT     Blackwell   HBM3E普及   下一代
CoWoS       HBM3       GPT-4       Claude 3    GPT-5?      HBM4
            液冷起步   AI爆發      開源崛起    Agent時代   CPO普及
```

---

## 2. 第一層: AI 晶片製造

### 2.1 晶片設計層

#### 🏆 NVIDIA - GPU 絕對霸主

| 世代 | 產品 | 製程 | 功耗 | HBM | 記憶體頻寬 | 量產時間 |
|------|------|------|------|-----|-----------|---------|
| Ampere | A100 | 7nm | 400W | HBM2e 80GB | 2 TB/s | 2020 |
| Hopper | H100 | 4nm | 700W | HBM3 80GB | 3.35 TB/s | 2022 |
| Hopper | H200 | 4nm | 700W | HBM3e 141GB | 4.8 TB/s | 2024 |
| Blackwell | B100 | 4nm | 700W | HBM3e 192GB | 8 TB/s | 2024 |
| Blackwell | B200 | 4nm | 1000W | HBM3e 192GB | 8 TB/s | 2025 |
| Blackwell | GB200 NVL72 | 4nm | 72GPU機櫃 | HBM3e | 超級電腦級 | 2025 |

- **市佔率**: 80-90% (AI訓練晶片)
- **2025營收預估**: $120B+
- **護城河**: CUDA 生態系 (400萬開發者, 15年積累)
- **核心客戶**: OpenAI, Meta, Microsoft, Google, Tesla, xAI

**Blackwell 架構亮點**:
- 2080億電晶體 (H100的2.5倍)
- 第二代 Transformer Engine
- 支援 FP4 精度訓練
- NVLink 5.0: 1.8 TB/s 雙向頻寬

#### AMD - 積極追趕者

| 產品 | 製程 | HBM | 記憶體頻寬 | 定位 |
|------|------|-----|-----------|------|
| MI250X | 6nm | HBM2e 128GB | 3.2 TB/s | 2022 |
| MI300X | 5nm | HBM3 192GB | 5.3 TB/s | 2023 |
| MI300A | 5nm | APU整合 | 5.3 TB/s | 2024 |
| MI325X | 3nm | HBM3e 256GB | 6 TB/s | 2024 |
| MI350 | 3nm | HBM3e | 預計2025 | 2025 |

- **市佔率**: 10-15% (快速成長)
- **2025營收目標**: $5B+ (AI晶片)
- **優勢**: ROCm 開源生態, 價格競爭力, 更大記憶體容量
- **主要客戶**: Microsoft Azure, Meta, Oracle

#### Intel - 重返戰場

| 產品 | 定位 | 狀態 |
|------|------|------|
| Gaudi 2 | AI訓練 | 量產中 |
| Gaudi 3 | AI訓練 | 2024發布 |
| Falcon Shores | 下一代 | 2025 |

- **市佔率**: <5%
- **策略**: 代工 + 自研雙線並進
- **優勢**: x86生態, 企業關係
- **挑戰**: 軟體生態落後

### 2.2 晶圓製造 - 台積電絕對主導

#### 台積電 TSMC

| 製程節點 | 應用產品 | 客戶 | 產能狀態 |
|---------|---------|------|---------|
| 3nm (N3E) | A17 Pro, M3 | Apple | 量產 |
| 4nm (N4P) | H100, B200 | NVIDIA | 滿載 |
| 5nm (N5) | MI300X | AMD | 量產 |
| 2nm (N2) | 下一代AI晶片 | 預訂中 | 2025試產 |

- **市佔率**: >90% (先進製程)
- **AI晶片營收佔比**: 40%+ (2025)
- **良率**: 80-90% (先進製程)
- **CoWoS產能**: 月產能3.5萬片 (2025), 持續擴充
- **核心客戶**: NVIDIA, AMD, Apple, Qualcomm, MediaTek

**2025-2026 關鍵發展**:
- 2nm 製程 2025年量產
- A16 (1.6nm) 預計 2026
- CoWoS 產能擴充至月產5萬片
- 美國亞利桑那廠投產

#### 台積電供應鏈

**半導體設備商** (關鍵瓶頸):

| 公司 | 領域 | 市佔率 | 重要性 |
|------|------|--------|--------|
| ASML | EUV光刻機 | 100% | 不可替代 |
| Applied Materials | 蝕刻/沉積 | 25% | 關鍵 |
| Lam Research | 蝕刻 | 20% | 關鍵 |
| KLA | 檢測設備 | 50% | 關鍵 |
| Tokyo Electron | 塗佈/顯影 | 30% | 關鍵 |

**EUV光刻機關鍵數據**:
- 單價: $1.5-2億美元
- 交期: 18-24個月
- 年產能: ~50台
- High-NA EUV: $3.5億美元 (2025開始交付)

**材料商**:
- 信越化學 (矽晶圓) - 30%
- SUMCO (矽晶圓) - 25%
- JSR (光阻劑) - 30%
- Air Liquide (特殊氣體) - 25%

### 2.3 先進封裝 - 新瓶頸

#### 封裝技術演進

```
傳統封裝 → 2.5D封裝 → 3D封裝 → 異質整合
   ↓          ↓          ↓          ↓
 Wire Bond   CoWoS     SoIC      Chiplet
             InFO     HBM堆疊    多晶片整合
```

#### CoWoS 封裝 (AI晶片核心)

```
NVIDIA B200 封裝結構 (CoWoS-L):
┌─────────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────┐  ┌─────────┐
│  GPU    │  │ HBM │  │ HBM │  │ HBM │  │ HBM │  │  GPU    │
│  Die    │  │  1  │  │  2  │  │  3  │  │  4  │  │  Die    │
└─────────┘  └─────┘  └─────┘  └─────┘  └─────┘  └─────────┘
═══════════════════════════════════════════════════════════
            Silicon Interposer (矽中介層) - 更大尺寸
═══════════════════════════════════════════════════════════
                   Organic Substrate
═══════════════════════════════════════════════════════════

B200 vs H100 封裝比較:
• 中介層尺寸: B200 (3x reticle) vs H100 (2x reticle)
• HBM 數量: B200 (8顆) vs H100 (6顆)
• 頻寬: B200 (8TB/s) vs H100 (3.35TB/s)
```

#### 封裝廠商

| 公司 | 市佔率 | 技術 | 主要客戶 |
|------|--------|------|---------|
| 台積電 | 60%+ | CoWoS, InFO, SoIC | NVIDIA, AMD |
| 日月光 ASE | 20% | 先進封裝, 測試 | 多家 |
| Amkor | 10% | FC-BGA | Intel, AMD |
| 力成 | 5% | 記憶體封裝 | HBM相關 |

**CoWoS 產能瓶頸**:
- 2024產能: 月產2.5萬片
- 2025產能: 月產3.5萬片 (仍供不應求)
- 良率要求: >95%
- 交期: 4-6個月

---

## 3. 第二層: AI 散熱系統

### 3.1 散熱需求演進 (指數級成長)

```
GPU功耗演進:
                                          ┌─────┐
                                          │1200W│ GB200
                                    ┌─────┤     │
                              ┌─────┤1000W│     │ B200
                        ┌─────┤ 700W│     │     │
                  ┌─────┤ 400W│     │     │     │
            ┌─────┤ 300W│     │     │     │     │
      ──────┴─────┴─────┴─────┴─────┴─────┴─────┘
      V100   A100   H100   B200  GB200  未來
      2017   2020   2022   2025  2025   2026+
```

| GPU | 功耗 | 散熱方案 | 機架密度 |
|-----|------|---------|---------|
| V100 | 300W | 氣冷 | 8-10 kW/rack |
| A100 | 400W | 氣冷/液冷 | 15-20 kW/rack |
| H100 | 700W | 液冷必須 | 40-60 kW/rack |
| B200 | 1000W | 液冷/浸沒 | 100+ kW/rack |
| GB200 NVL72 | 72顆GPU | 浸沒式 | 120+ kW/rack |

### 3.2 散熱技術分類

```
散熱技術演進:
┌────────────────┐  ┌────────────────┐  ┌────────────────┐
│    傳統氣冷    │  │    直接液冷    │  │    浸沒式冷卻  │
│   (Air Cool)   │  │  (Direct LC)   │  │   (Immersion)  │
├────────────────┤  ├────────────────┤  ├────────────────┤
│ • 風扇+散熱片  │  │ • 冷板貼合GPU  │  │ • 整機浸入液體 │
│ • PUE: 1.5-2.0 │→ │ • PUE: 1.2-1.3 │→ │ • PUE: 1.02-1.1│
│ • <20kW/rack   │  │ • 40-80kW/rack │  │ • 100+kW/rack  │
│ • 成本低       │  │ • 主流方案     │  │ • 最佳效率     │
└────────────────┘  └────────────────┘  └────────────────┘
```

### 3.3 液冷散熱廠商

#### Vertiv - 全球龍頭
- **市佔率**: 25%
- **2024營收**: $7.5B
- **技術**: Liebert XD (直接液冷), CDU
- **客戶**: Meta, Microsoft, Google, AWS
- **優勢**: 完整數據中心解決方案

#### Schneider Electric
- **市佔率**: 20%
- **產品**: EcoStruxure, InRow Cooling
- **特色**: PUE <1.2, 智慧管理
- **客戶**: 企業數據中心

#### Cooler Master / 雙鴻 (台灣)
- **市佔率**: 液冷模組 15%
- **產品**: 伺服器液冷模組, 冷板
- **客戶**: 鴻海, 廣達代工鏈
- **優勢**: 成本優勢, 快速交付

#### 奇鋐 (台灣)
- **定位**: 散熱模組專家
- **產品**: 均熱板, 散熱片, 液冷模組
- **客戶**: NVIDIA DGX供應鏈

### 3.4 浸沒式冷卻 (未來主流)

#### GRC (Green Revolution Cooling)
- **技術**: CarnotJet 單相浸沒
- **PUE**: 1.02-1.03 (極致能效)
- **應用**: 超高密度AI叢集
- **客戶**: xAI, 超算中心

#### LiquidCool Solutions
- **技術**: 兩相浸沒式
- **優勢**: 更高散熱效率

#### Asetek
- **市佔率**: 液冷OEM 20%+
- **產品**: 數據中心液冷, Gaming液冷
- **客戶**: Dell, HP, Lenovo

### 3.5 冷卻液供應

| 公司 | 市佔率 | 產品 | 特性 |
|------|--------|------|------|
| 3M | 40% | Novec 7100, 649 | 不導電, 環保 |
| Solvay | 25% | Galden系列 | 高介電強度 |
| Chemours | 20% | Opteon系列 | 低GWP |

**冷卻液關鍵指標**:
- 介電強度: >40 kV/mm
- 沸點: 34-174°C (可調)
- GWP (全球暖化潛勢): <10

---

## 4. 第三層: 電源供應系統

### 4.1 AI伺服器電源需求演進

| 系統 | 電源需求 | PSU規格 | 備註 |
|------|---------|---------|------|
| DGX A100 | 6.5 kW | 2x 3000W | 8x A100 |
| DGX H100 | 10.2 kW | 4x 3000W | 8x H100 |
| DGX B200 | 14.3 kW | 6x 3000W | 8x B200 |
| GB200 NVL72 | 120 kW | 機櫃級供電 | 72x GPU |

### 4.2 UPS 不斷電系統

#### Schneider Electric - 龍頭
- **市佔率**: 30%
- **產品**: Galaxy VX (250-1500 kVA), Galaxy VL
- **效率**: >97% (ECOnversion模式)
- **客戶**: 大型數據中心

#### Eaton
- **市佔率**: 25%
- **產品**: 93PM/PR系列, 9PXM
- **特色**: 模組化設計

#### Vertiv
- **市佔率**: 20%
- **產品**: Liebert APM, EXL S1
- **整合**: 搭配自家冷卻系統

### 4.3 伺服器電源 (PSU) - 台灣廠商主導

#### 台達電 Delta - 全球第一

| 產品 | 功率 | 效率 | 應用 |
|------|------|------|------|
| CRPS | 2400W | 96%+ | 標準伺服器 |
| CRPS | 3000W | 96%+ | AI伺服器 |
| ORv3 | 3300W | 97%+ | 開放運算 |

- **市佔率**: 35-40% (全球第一)
- **2024營收**: $15B+
- **技術領先**: GaN/SiC 功率元件, 數位電源
- **核心客戶**: NVIDIA DGX, Dell, HP, Lenovo, 雲端大廠
- **毛利率**: 25-30%

#### 光寶 Lite-On
- **市佔率**: 20-25%
- **產品**: 2000-3000W 伺服器電源
- **客戶**: Meta, Microsoft, Google
- **特色**: 價格競爭力

#### 群光 Chicony
- **市佔率**: 10-15%
- **客戶**: Dell, HP
- **產品**: 消費/企業電源

### 4.4 功率元件供應

| 類型 | 廠商 | 應用 | 優勢 |
|------|------|------|------|
| GaN | Navitas, GaN Systems | 高頻電源 | 效率高, 體積小 |
| SiC | Wolfspeed, Infineon | 高壓應用 | 耐高溫, 低損耗 |
| MOSFET | Infineon, ON Semi | 通用 | 成熟, 低成本 |

---

## 5. 第四層: 儲存與網路

### 5.1 HBM 記憶體 (最關鍵瓶頸)

#### HBM 技術演進

| 世代 | 頻寬 | 容量/Stack | 應用GPU | 量產時間 |
|------|------|-----------|---------|---------|
| HBM2 | 1.2 TB/s | 16GB | V100 | 2018 |
| HBM2e | 1.8 TB/s | 24GB | A100 | 2020 |
| HBM3 | 3.35 TB/s | 24GB | H100 | 2022 |
| HBM3e | 4.8-5.3 TB/s | 36GB | H200, MI300X | 2024 |
| HBM4 | 6+ TB/s | 48GB | 下一代 | 2025H2 |

#### SK Hynix - 絕對龍頭

- **市佔率**: 50-55% (HBM3e: 90%+)
- **技術領先**: HBM3e 率先量產, 12層堆疊
- **產品**: HBM3 (24GB), HBM3e (36GB)
- **頻寬**: 5.3 TB/s (HBM3e)
- **核心客戶**: NVIDIA (獨家 HBM3e 供應商)
- **良率**: >85% (業界最高)
- **成本**: 80GB約$4000-6000 (持續下降)
- **產能擴充**: 2025年產能翻倍

**HBM3e 關鍵數據**:
- 單顆容量: 36GB (12層堆疊)
- H200配置: 6顆 = 141GB
- B200配置: 8顆 = 192GB

#### Samsung - 追趕中

- **市佔率**: 35-40%
- **狀態**: HBM3e 良率提升中
- **客戶**: AMD MI300X (主要), 部分NVIDIA
- **挑戰**: 良率落後SK Hynix

#### Micron - 積極擴產

- **市佔率**: 10-15%
- **產品**: HBM3e (2024量產)
- **優勢**: 美國本土供應鏈
- **客戶**: NVIDIA (次要供應商)

#### HBM 供應瓶頸分析

```
HBM供應鏈瓶頸:

原物料 → 晶圓製造 → TSV製程 → 堆疊封裝 → 測試 → 成品
                        ↑           ↑
                     良率瓶頸    產能瓶頸

瓶頸因素:
• TSV (矽穿孔) 製程複雜
• 12層堆疊良率挑戰
• 散熱要求嚴苛
• 設備產能有限
```

**2025-2026 HBM 供需**:
- 需求: 持續超過供給 30-40%
- 交期: 3-6個月 (改善中)
- ASP: 傳統DRAM的5-8倍

### 5.2 高速網路

#### NVIDIA Mellanox - InfiniBand 壟斷

| 產品 | 速度 | 應用 | 狀態 |
|------|------|------|------|
| HDR | 200 Gbps | A100叢集 | 成熟 |
| NDR | 400 Gbps | H100叢集 | 主流 |
| XDR | 800 Gbps | B200叢集 | 2024 |
| GDR | 1.6 Tbps | 下一代 | 2025+ |

- **市佔率**: 80%+ (AI InfiniBand)
- **核心產品**:
  - ConnectX-7/8 網卡
  - Quantum-2 交換機
  - BlueField-3 DPU
- **技術**: GPUDirect RDMA, SHARP
- **客戶**: OpenAI, Meta, Google, Microsoft
- **優勢**: 與NVIDIA GPU深度整合

#### Broadcom - Ethernet 霸主

- **市佔率**: 60% (Ethernet交換晶片)
- **產品**:
  - Memory 5 (51.2 Tbps)
  - Memoria 5 (51.2 Tbps)
- **客戶**: 雲端大廠

#### 網路架構趨勢

```
AI叢集網路架構:
┌─────────────────────────────────────────────┐
│              Spine Layer (骨幹層)            │
│         800G/1.6T Ethernet/InfiniBand       │
├─────────────────────────────────────────────┤
│              Leaf Layer (葉層)               │
│              400G 交換機                     │
├─────────────────────────────────────────────┤
│              GPU Nodes                       │
│    NVLink (GPU間) + InfiniBand (節點間)     │
└─────────────────────────────────────────────┘
```

### 5.3 AI 儲存系統

#### NVIDIA DGX 儲存

- **產品**: DGX Storage (與DDN合作)
- **效能**: 1TB/s+ 讀取
- **技術**: NVMe over Fabric

#### Pure Storage

- **市佔率**: 企業Flash儲存 15%
- **產品**: FlashBlade (非結構化資料)
- **客戶**: AI/ML訓練資料

#### NetApp

- **市佔率**: 企業儲存 20%
- **AI方案**: ONTAP AI (與NVIDIA整合)

---

## 6. 第五層: 光通訊與高速互連 ⭐ 新增

> 光通訊是 AI 數據中心的新瓶頸，隨著 GPU 功耗和頻寬需求暴增，800G/1.6T 光模組需求爆發。

### 6.1 光模組需求演進

```
光模組速率演進:
                                    ┌────────┐
                              ┌────┤  1.6T  │ 2025+
                        ┌────┤800G│        │
                  ┌────┤400G│    │        │
            ┌────┤200G│    │    │        │
      ──────┴────┴────┴────┴────┴────────┘
      100G  200G  400G  800G  1.6T   未來
      2018  2020  2022  2024  2025   2026+

AI數據中心光模組需求:
• H100叢集: 400G 為主
• B200叢集: 800G 為主
• GB200叢集: 800G/1.6T
```

### 6.2 光模組廠商

#### 中際旭創 (InnoLight) - 全球第一

- **市佔率**: 30%+ (800G: 40%+)
- **產品**: 400G/800G/1.6T 光模組
- **客戶**: NVIDIA, Google, Meta, Microsoft
- **優勢**: 成本領先, 產能充足
- **2024營收**: ~$3B

#### Coherent (原II-VI + Finisar)

- **市佔率**: 25%
- **產品**: 400G/800G 光收發器, 雷射晶片
- **優勢**: 垂直整合 (晶片到模組)
- **客戶**: 雲端大廠

#### Lumentum

- **市佔率**: 15%
- **產品**: 光學元件, 雷射器
- **技術**: 3D感測, 光通訊
- **客戶**: Apple, 通訊設備商

#### 光迅科技 (Accelink)

- **市佔率**: 10%
- **定位**: 中國最大光模組廠
- **產品**: 400G/800G 模組
- **優勢**: 中國市場

### 6.3 CPO 共封裝光學 (下一代技術)

```
傳統可插拔模組 vs CPO:

傳統架構:
┌─────────┐    ┌──────────┐    ┌─────────┐
│ Switch  │────│ 光模組   │────│  光纖   │
│  ASIC   │    │ (可插拔) │    │         │
└─────────┘    └──────────┘    └─────────┘
              功耗: 15-20W/400G

CPO架構:
┌──────────────────────┐    ┌─────────┐
│ Switch ASIC + 光引擎 │────│  光纖   │
│    (共封裝)          │    │         │
└──────────────────────┘    └─────────┘
              功耗: 5-8W/400G

CPO優勢:
• 功耗降低 50-70%
• 頻寬密度提升
• 延遲降低
• 成本長期下降
```

#### CPO 關鍵廠商

| 公司 | 角色 | 產品/技術 |
|------|------|----------|
| Broadcom | 交換晶片+光引擎 | Memoria系列 |
| Intel | 矽光子 | 矽光整合方案 |
| NVIDIA | CPO整合 | 下一代交換機 |
| Cisco | 系統整合 | 矽光子平台 |
| 中際旭創 | 光引擎 | CPO模組 |

### 6.4 高速互連技術

#### NVLink - NVIDIA GPU互連

| 版本 | 頻寬 | 應用 | GPU數量 |
|------|------|------|---------|
| NVLink 3.0 | 600 GB/s | A100 | 8 GPU |
| NVLink 4.0 | 900 GB/s | H100 | 8 GPU |
| NVLink 5.0 | 1.8 TB/s | B200 | 72 GPU (NVL72) |

#### NVSwitch - 大規模GPU互連

- **功能**: 連接多個GPU形成統一記憶體空間
- **NVSwitch 3.0**: 支援256個GPU互連
- **應用**: DGX SuperPOD, 超大型AI訓練

#### CXL (Compute Express Link)

- **定位**: 開放標準, 打破NVIDIA壟斷
- **功能**: CPU/GPU/記憶體 統一互連
- **支持者**: Intel, AMD, ARM, 雲端大廠
- **CXL 3.0**: 64 GT/s, 記憶體池化

#### UALink (Ultra Accelerator Link)

- **定位**: AI加速器開放互連標準
- **發起者**: AMD, Intel, Google, Meta, Microsoft
- **目標**: 挑戰NVLink壟斷
- **時程**: 2024發布規格, 2025產品

### 6.5 光通訊供應鏈 (台灣廠商)

| 公司 | 產品 | 客戶 | 地位 |
|------|------|------|------|
| 聯亞光電 | 光收發晶片 | 光模組廠 | 磊晶龍頭 |
| 穩懋 | GaAs代工 | 光通訊/RF | 代工龍頭 |
| 全新 | 光通訊零組件 | 模組廠 | 零組件 |
| 光環 | 光纖連接器 | 數據中心 | 連接器 |

---

## 7. 第六層: 雲端與數據中心

### 7.1 AI 雲端平台

#### Microsoft Azure - AI雲端龍頭

| 指標 | 數據 |
|------|------|
| AI雲端市佔 | 30%+ |
| GPU數量 | 10萬+ H100 (持續擴充) |
| OpenAI投資 | $13B+ |
| Azure AI營收 | $30B+ (2025預估) |

- **核心優勢**: OpenAI獨家合作, GPT-4/ChatGPT後端
- **AI服務**: Azure OpenAI Service, Copilot
- **基礎設施**: 60+區域, 持續建設AI超級數據中心

#### Amazon AWS

| 指標 | 數據 |
|------|------|
| 整體雲端市佔 | 32% (第一) |
| AI雲端市佔 | 25% |
| 自研晶片 | Trainium2, Inferentia2 |
| Anthropic投資 | $4B |

- **自研策略**: 減少NVIDIA依賴
- **AI服務**: Bedrock (模型市集), SageMaker
- **優勢**: 最大雲端生態系

#### Google Cloud

| 指標 | 數據 |
|------|------|
| 雲端市佔 | 10% |
| AI雲端市佔 | 20% |
| 自研晶片 | TPU v5p, v6 |
| Anthropic投資 | $2B |

- **核心優勢**: DeepMind團隊, Gemini模型
- **TPU**: AI訓練成本優勢
- **AI服務**: Vertex AI, Gemini API

#### 新興AI雲端

| 公司 | 定位 | GPU數量 | 客戶 |
|------|------|---------|------|
| CoreWeave | 專注AI | 10萬+ H100 | AI新創 |
| Lambda Labs | GPU雲端 | 數萬 | 研究機構 |
| Together AI | 開源模型 | - | 開發者 |
| Oracle Cloud | 企業AI | 大量H100 | 企業 |

### 7.2 數據中心建設

```
AI數據中心規模演進:
                                        ┌──────────┐
                                  ┌────┤ 500MW+   │ xAI等
                            ┌────┤100MW│          │
                      ┌────┤50MW│     │          │
                ┌────┤20MW│    │     │          │
          ──────┴────┴────┴────┴─────┴──────────┘
          傳統   中型   大型  超大型  AI超級DC
                              (Hyperscale)
```

#### 主要數據中心建設

| 公司 | 項目 | 規模 | 投資 |
|------|------|------|------|
| Microsoft | 全球擴建 | 100+ MW多處 | $80B+ (計劃) |
| Meta | AI研究中心 | 35萬GPU目標 | $40B+ |
| Google | TPU超級電腦 | 多處 | $30B+ |
| xAI | Memphis DC | 100,000 H100 | 數十億 |
| Amazon | 多區域擴建 | 大規模 | $70B+ |

### 7.3 AI伺服器製造 (台灣主導)

#### 鴻海 Foxconn - 最大代工廠

- **市佔率**: 35-40% (AI伺服器)
- **核心產品**: NVIDIA DGX/HGX, GB200 NVL72
- **客戶**: NVIDIA, Microsoft, Meta, Amazon
- **產能**: 墨西哥、台灣、越南多廠
- **2024營收**: AI伺服器約$300B TWD

#### 廣達 Quanta

- **市佔率**: 25-30%
- **客戶**: Google, Meta, Amazon, Microsoft
- **專長**: OCP開放標準伺服器, 液冷整合
- **優勢**: 白牌伺服器經驗深厚

#### 緯創 Wistron

- **市佔率**: 10-15%
- **客戶**: Dell, HP
- **產品**: AI伺服器, 邊緣運算

#### 英業達 Inventec

- **市佔率**: 10%
- **客戶**: HP, 雲端廠
- **專長**: 伺服器主板

### 7.4 機櫃與基礎設施

| 公司 | 產品 | 市佔 |
|------|------|------|
| 台達電 | 機櫃電源、PDU | 15% |
| Vertiv | 機櫃、電源、散熱 | 20% |
| Schneider | 整體基礎設施 | 25% |
| Rittal | 機櫃系統 | 10% |

---

## 8. 第七層: AI 軟體與應用

### 8.1 AI 框架與工具

#### 深度學習框架

| 框架 | 公司 | 市佔 | 特色 |
|------|------|------|------|
| PyTorch | Meta | 70% (研究) | 動態圖, 易用 |
| TensorFlow | Google | 20% | TPU優化, 生產部署 |
| JAX | Google | 5% | 函數式, 高效能 |
| MLX | Apple | 新興 | Apple Silicon優化 |

#### MLOps 與訓練工具

| 工具 | 功能 | 公司 |
|------|------|------|
| Weights & Biases | 實驗追蹤 | W&B |
| MLflow | ML生命週期 | Databricks |
| Ray | 分散式訓練 | Anyscale |
| DeepSpeed | 大模型訓練 | Microsoft |
| Megatron-LM | LLM訓練 | NVIDIA |

### 8.2 大語言模型 (LLM)

#### OpenAI - 領導者

| 指標 | 數據 |
|------|------|
| 估值 | $200B+ (2025) |
| ChatGPT用戶 | 3億+ |
| 營收 | $5B+ (2024) |
| 員工 | 1500+ |

- **產品線**: GPT-4o, GPT-4 Turbo, o1 (推理), Sora (影片)
- **基礎設施**: Azure獨家, 數萬H100/B200
- **訓練成本**: GPT-4約$100M+, GPT-5預計$500M+
- **護城河**: 用戶數據, 品牌, RLHF專長

#### Anthropic - 安全AI

| 指標 | 數據 |
|------|------|
| 估值 | $60B+ (2025) |
| 融資 | $10B+ |
| 員工 | 800+ |

- **產品**: Claude 3.5 Opus/Sonnet, Claude 4 (預期)
- **投資者**: Google $2B, Amazon $4B, Spark
- **特色**: Constitutional AI, 安全優先
- **客戶**: AWS Bedrock, 企業API

#### Meta - 開源王者

- **產品**: Llama 3, Llama 3.1 (405B參數)
- **策略**: 開源推動AI民主化
- **GPU**: 35萬+ H100 (全球最大私有叢集)
- **影響**: 推動開源模型生態

#### Google DeepMind

- **產品**: Gemini 1.5 Pro/Ultra, Gemini 2.0
- **技術**: AlphaFold, AlphaGo 傳承
- **優勢**: 多模態, 長上下文 (1M+ tokens)
- **整合**: Google搜尋, Workspace

#### 其他重要模型

| 公司 | 模型 | 特色 |
|------|------|------|
| Mistral | Mistral Large | 歐洲開源領導者 |
| xAI | Grok | Elon Musk, Twitter整合 |
| Cohere | Command R+ | 企業RAG優化 |
| 01.AI | Yi | 中國開源 |

### 8.3 AI Agent 與自動化

#### Agent 框架

| 框架 | 公司 | 功能 |
|------|------|------|
| AutoGPT | 開源 | 自主任務執行 |
| LangChain | LangChain | LLM應用框架 |
| CrewAI | 開源 | 多Agent協作 |
| Claude Computer Use | Anthropic | 電腦操作Agent |

#### Agent 應用趨勢

```
AI Agent 演進:
聊天機器人 → 單一任務Agent → 多Agent系統 → 自主Agent
    ↓              ↓              ↓            ↓
 ChatGPT      Copilot       CrewAI      未來願景
 問答互動      程式輔助      團隊協作    完全自主
```

### 8.4 應用市場

#### 生成式AI應用

| 領域 | 龍頭 | 市佔 | 用戶/營收 |
|------|------|------|----------|
| 圖像生成 | Midjourney | 50% | 1600萬用戶 |
| 影片生成 | Runway, Pika | 新興 | 快速成長 |
| 音樂生成 | Suno, Udio | 新興 | 病毒式成長 |
| 語音合成 | ElevenLabs | 40% | B2B/B2C |

#### 企業AI應用

| 產品 | 公司 | 用途 | 用戶 |
|------|------|------|------|
| GitHub Copilot | Microsoft | 程式碼 | 180萬+ |
| Microsoft Copilot | Microsoft | 辦公套件 | 億級 |
| Salesforce Einstein | Salesforce | CRM AI | 企業 |
| Adobe Firefly | Adobe | 創意設計 | 創作者 |

#### 垂直產業AI

| 領域 | 公司 | 應用 |
|------|------|------|
| 醫療 | PathAI, Tempus | 病理診斷 |
| 法律 | Harvey AI | 法律文件 |
| 金融 | Bloomberg GPT | 金融分析 |
| 自駕 | Tesla FSD, Waymo | 自動駕駛 |
| 教育 | Duolingo, Khan | 個人化學習 |

---

## 9. 第八層: 邊緣AI與端側推理

> 隨著大模型向端側延伸，邊緣AI成為2025-2026年的重要趨勢，實現低延遲、隱私保護的本地推理。

### 9.1 邊緣AI市場概況

```
邊緣AI部署演進:
                                          ┌─────────┐
                                    ┌────┤  全面   │ 2026+
                              ┌────┤ AI PC│ 普及   │
                        ┌────┤手機 │     │        │
                  ┌────┤IoT  │NPU │     │        │
            ──────┴────┴────┴────┴─────┴────────┘
            2020   2022  2024  2025  2026   未來
            雲端AI  邊緣起步  NPU普及  AI PC  端雲協同
```

| 市場規模 | 2024 | 2025 | 2030 |
|---------|------|------|------|
| 邊緣AI晶片 | $15B | $25B | $100B |
| AI PC | 5000萬台 | 1億台 | 3億台 |
| 端側推理 | 10% | 30% | 60% |

### 9.2 AI PC 晶片

#### Intel - Core Ultra 系列

| 產品 | NPU算力 | CPU | GPU | 定位 |
|------|---------|-----|-----|------|
| Core Ultra 100 (Meteor Lake) | 10 TOPS | P+E核 | Arc | 首代AI PC |
| Core Ultra 200 (Lunar Lake) | 48 TOPS | 低功耗 | Arc 140V | 輕薄本 |
| Core Ultra 200 (Arrow Lake) | 13 TOPS | 高效能 | Arc | 桌機/效能本 |

- **NPU技術**: 專用神經網路處理單元
- **應用場景**: Copilot+PC、本地AI助理、影像處理
- **軟體生態**: OpenVINO、Windows AI

#### AMD - Ryzen AI 系列

| 產品 | NPU算力 | 架構 | 特色 |
|------|---------|------|------|
| Ryzen 7040 (Phoenix) | 10 TOPS | XDNA | 首代整合NPU |
| Ryzen 8040 (Hawk Point) | 16 TOPS | XDNA | 效能提升 |
| Ryzen AI 300 (Strix Point) | 50 TOPS | XDNA2 | 最強NPU |

- **XDNA架構**: 可重配置AI引擎
- **優勢**: 算力領先、開放ROCm
- **客戶**: 聯想、華碩、HP

#### Apple - M系列晶片

| 產品 | Neural Engine | 統一記憶體 | 定位 |
|------|--------------|-----------|------|
| M3 | 18 TOPS | 8-128GB | 消費級 |
| M3 Pro/Max | 18 TOPS | 18-128GB | 專業級 |
| M4 | 38 TOPS | 16-64GB | 新一代 |
| M4 Pro/Max | 38 TOPS | 24-128GB | 專業級 |

- **優勢**: 統一記憶體架構、能效比極高
- **應用**: Core ML、本地LLM (7B-70B)
- **生態**: MLX框架、Apple Intelligence

#### Qualcomm - Snapdragon X 系列

| 產品 | NPU算力 | CPU | 特色 |
|------|---------|-----|------|
| Snapdragon X Elite | 45 TOPS | Oryon (ARM) | 首款ARM PC晶片 |
| Snapdragon X Plus | 45 TOPS | Oryon | 主流版 |

- **突破**: ARM架構進入Windows PC
- **優勢**: 極致能效、全天續航
- **挑戰**: x86軟體相容性

### 9.3 手機AI晶片

| 廠商 | 產品 | NPU算力 | 應用 |
|------|------|---------|------|
| Apple | A18 Pro | 35 TOPS | Apple Intelligence |
| Qualcomm | Snapdragon 8 Gen 3 | 45 TOPS | 生成式AI |
| MediaTek | Dimensity 9300 | 37 TOPS | 本地LLM |
| Google | Tensor G4 | 專用TPU | Gemini Nano |
| Samsung | Exynos 2400 | 37 TOPS | Galaxy AI |

### 9.4 端側推理框架

| 框架 | 公司 | 支援平台 | 特色 |
|------|------|---------|------|
| Core ML | Apple | iOS/macOS | Apple生態整合 |
| TensorFlow Lite | Google | 跨平台 | 廣泛相容 |
| ONNX Runtime | Microsoft | 跨平台 | 標準格式 |
| OpenVINO | Intel | Intel硬體 | 最佳化推理 |
| NCNN | 騰訊 | 移動端 | 輕量高效 |
| MLC LLM | 開源 | 跨平台 | 本地LLM |

### 9.5 邊緣AI應用場景

```
邊緣AI應用金字塔:
┌─────────────────────────────────────────┐
│         本地大語言模型                    │ ← 7B-70B 參數
│         (Llama, Phi, Gemma)              │
├─────────────────────────────────────────┤
│      AI助理/Copilot/語音辨識              │ ← 日常互動
├─────────────────────────────────────────┤
│    影像處理/物件偵測/人臉辨識              │ ← 即時處理
├─────────────────────────────────────────┤
│  IoT/工業自動化/智慧家庭/車載AI            │ ← 嵌入式
└─────────────────────────────────────────┘
```

---

## 10. ASIC 客製化晶片專題

> 面對NVIDIA GPU的高價與供應限制，科技巨頭紛紛投入自研AI晶片，開啟ASIC時代。

### 10.1 雲端巨頭自研晶片

#### Google TPU

| 世代 | 製程 | 算力 | 記憶體 | 發布 |
|------|------|------|--------|------|
| TPU v4 | 7nm | 275 TFLOPS | 32GB HBM2e | 2021 |
| TPU v5e | 7nm | 經濟版 | 16GB HBM2e | 2023 |
| TPU v5p | 5nm | 459 TFLOPS | 95GB HBM2e | 2023 |
| TPU v6 (Trillium) | 4nm | 2x v5p | HBM3 | 2024 |

- **優勢**: 為TensorFlow/JAX優化、成本效益高
- **部署**: 數十萬顆TPU (全球最大非NVIDIA叢集)
- **應用**: Gemini訓練、Google Search、YouTube

#### Amazon Trainium/Inferentia

| 產品 | 定位 | 製程 | 算力 | 發布 |
|------|------|------|------|------|
| Inferentia | 推理 | 7nm | 經濟推理 | 2019 |
| Inferentia2 | 推理 | 5nm | 3x效能 | 2022 |
| Trainium | 訓練 | 7nm | 訓練專用 | 2021 |
| Trainium2 | 訓練 | 3nm | 4x效能 | 2024 |

- **策略**: 減少NVIDIA依賴、降低AWS成本
- **生態**: Neuron SDK
- **客戶**: Anthropic (Claude訓練)

#### Microsoft Maia/Cobalt

| 產品 | 定位 | 製程 | 狀態 |
|------|------|------|------|
| Maia 100 | AI加速 | 5nm (台積電) | 2024部署 |
| Cobalt 100 | ARM CPU | 5nm | 2024 |

- **目標**: Azure AI成本優化
- **應用**: Copilot推理、Bing搜尋
- **合作**: OpenAI訓練推理

#### Meta MTIA

| 產品 | 定位 | 狀態 |
|------|------|------|
| MTIA v1 | 推理 | 2023內部部署 |
| MTIA v2 | 推理加強 | 2024 |

- **應用**: 廣告推薦、內容審核
- **策略**: 仍依賴NVIDIA GPU訓練大模型

### 10.2 ASIC 設計公司

| 公司 | 產品 | 客戶 | 技術特色 |
|------|------|------|---------|
| Broadcom | AI加速器 | Google (TPU), Apple | 客製化設計能力 |
| Marvell | 雲端ASIC | AWS, 微軟 | 網路+運算整合 |
| Cerebras | WSE-3 | 研究機構 | 世界最大晶片 |
| Graphcore | IPU | 研究/企業 | 創新架構 |
| SambaNova | DataScale | 企業 | 可重配置架構 |
| Groq | LPU | 推理加速 | 極低延遲 |

### 10.3 特殊架構晶片

#### Cerebras WSE-3 (Wafer Scale Engine)

```
傳統晶片 vs Cerebras WSE-3:
┌─────────┐          ┌─────────────────────────────┐
│  GPU    │          │                             │
│ ~800mm² │    vs    │      整片晶圓 = 晶片         │
│  Die    │          │       46,225 mm²            │
└─────────┘          │      90萬核心               │
                     │      44GB SRAM              │
                     └─────────────────────────────┘
```

- **創新**: 整片晶圓做成單一晶片
- **優勢**: 無需跨晶片通訊、超大記憶體頻寬
- **挑戰**: 良率、散熱、成本
- **應用**: 大模型訓練、科學計算

#### Groq LPU

- **定位**: 推理專用、確定性延遲
- **特色**: 無需HBM (使用SRAM)
- **效能**: Llama 70B 達 300 tokens/sec
- **應用**: 即時推理服務

### 10.4 ASIC vs GPU 比較

| 維度 | NVIDIA GPU | 雲端ASIC | 專用ASIC |
|------|-----------|---------|---------|
| 通用性 | 最高 | 中 | 低 |
| 能效比 | 中 | 高 | 最高 |
| 開發成本 | 低 | 高 | 最高 |
| 生態系統 | CUDA (完整) | 自建 | 有限 |
| 適用場景 | 通用訓練/推理 | 大規模雲端 | 特定工作負載 |
| 上市時間 | 快 | 慢 | 最慢 |

---

## 11. 中國 AI 產業鏈

> 受美國出口管制影響，中國AI產業正在建立獨立供應鏈，雖面臨先進製程限制，但國產替代加速。

### 11.1 出口管制現況

```
美國對中國AI晶片出口管制時間軸:
2022.10    2023.10    2024.01    2024.10    2025+
   │          │          │          │          │
   ▼          ▼          ▼          ▼          ▼
 A100禁令   H100禁令   加強管制   更嚴限制   持續收緊
 限制算力   限制HBM    堵漏洞    第三國限制  技術封鎖
```

**管制要點**:
- 禁止向中國出口先進AI晶片 (H100/H200/B200)
- 限制先進製程設備 (EUV光刻機)
- HBM記憶體出口限制
- 雲端服務算力限制

### 11.2 中國GPU設計公司

| 公司 | 產品 | 製程 | 算力 | 狀態 |
|------|------|------|------|------|
| 華為 | 昇騰910B/C | 7nm (中芯) | ~H100 50-60% | 量產 |
| 寒武紀 | 思元590 | 7nm | 約A100 | 量產 |
| 燧原科技 | 邃思系列 | 12nm | 訓練推理 | 量產 |
| 壁仞科技 | BR100 | 7nm | 高算力 | 受限 |
| 摩爾線程 | MTT S80 | 7nm | 遊戲/AI | 量產 |
| 天數智芯 | 天垓100 | 7nm | 通用GPU | 發展中 |

### 11.3 華為昇騰 - 國產龍頭

#### 昇騰晶片系列

| 產品 | 定位 | 製程 | 算力 (FP16) | 記憶體 |
|------|------|------|-------------|--------|
| 昇騰910 | 訓練 | 7nm+ | 320 TFLOPS | 32GB HBM2e |
| 昇騰910B | 訓練 | 7nm (SMIC) | ~H100 60% | 64GB HBM2e |
| 昇騰910C | 訓練 | 7nm | 改進版 | HBM優化 |
| 昇騰310 | 推理 | 12nm | 22 TOPS | 8GB |

#### 華為AI生態

```
華為AI技術棧:
┌─────────────────────────────────────────┐
│            應用層: 盤古大模型            │
├─────────────────────────────────────────┤
│          框架層: MindSpore              │
├─────────────────────────────────────────┤
│         工具層: CANN (AI計算框架)        │
├─────────────────────────────────────────┤
│           硬體層: 昇騰晶片               │
└─────────────────────────────────────────┘
```

- **MindSpore**: 開源深度學習框架
- **CANN**: 類CUDA的編程平台
- **客戶**: 中國雲端廠商、政府、國企

### 11.4 中國晶圓製造

#### 中芯國際 SMIC

| 製程 | 狀態 | 產品 | 限制 |
|------|------|------|------|
| 14nm | 量產 | 成熟製程晶片 | 無 |
| 7nm (N+2) | 量產 | 華為晶片 | 無EUV |
| 5nm | 發展中 | DUV多重曝光 | 良率挑戰 |

- **挑戰**: 無法取得EUV光刻機
- **策略**: DUV多重曝光實現先進製程
- **產能**: 持續擴充成熟製程

### 11.5 中國AI大模型

| 公司 | 模型 | 參數量 | 特色 |
|------|------|--------|------|
| 百度 | 文心一言 4.0 | 千億級 | 搜尋整合 |
| 阿里巴巴 | 通義千問 2.5 | 開源72B | 多模態 |
| 騰訊 | 混元 | 萬億MoE | 遊戲/社交 |
| 字節跳動 | 豆包 | 千億級 | 內容創作 |
| 智譜AI | GLM-4 | 開源 | 學術背景 |
| 月之暗面 | Kimi | 長上下文 | 200萬字上下文 |
| MiniMax | ABAB | 多模態 | 語音優勢 |

### 11.6 中國AI雲端

| 公司 | AI雲服務 | GPU數量 | 特色 |
|------|---------|---------|------|
| 阿里雲 | 靈積 | 大規模 | 最大雲端商 |
| 華為雲 | 盤古 | 昇騰為主 | 國產化 |
| 騰訊雲 | AI服務 | 混合 | 遊戲生態 |
| 百度智能雲 | 千帆 | 混合 | 模型服務 |
| 火山引擎 | 方舟 | 大規模 | 字節跳動 |

### 11.7 中國AI產業挑戰與機遇

**挑戰**:
- 先進製程落後2-3代
- HBM供應受限
- 軟體生態不成熟
- 高端人才外流風險

**機遇**:
- 國產替代政策支持
- 龐大內需市場
- 成熟製程仍可發展
- 應用創新空間大

---

## 12. 機器人與具身AI

> 2025-2026年具身智能 (Embodied AI) 成為AI下一個重要戰場，科技巨頭紛紛佈局人形機器人。

### 12.1 人形機器人市場

```
人形機器人市場預測:
                                          ┌─────────┐
                                    ┌────┤  $38B   │ 2035
                              ┌────┤$12B│         │
                        ┌────┤ $3B│    │         │
                  ┌────┤$500M│   │    │         │
            ──────┴────┴────┴────┴────┴─────────┘
            2024   2025  2027  2030  2035
            起步   商業化  規模化  普及   成熟
```

### 12.2 主要人形機器人公司

#### Tesla Optimus

| 指標 | 數據 |
|------|------|
| 目標售價 | $20,000-30,000 |
| 自由度 | 28+ |
| 電池續航 | 一整天工作 |
| 量產時間 | 2025開始 |

- **優勢**: Tesla AI團隊、FSD技術移轉、製造能力
- **應用**: 工廠自動化、家庭服務
- **AI**: 端到端神經網路控制

#### Figure 01/02

| 指標 | 數據 |
|------|------|
| 融資 | $750M+ (微軟、OpenAI、NVIDIA投資) |
| 合作 | OpenAI (多模態AI) |
| 商業化 | BMW工廠試用 |

- **特色**: OpenAI GPT-4V整合
- **能力**: 自然語言互動、任務理解

#### 1X Technologies (NEO)

- **投資者**: OpenAI
- **產品**: NEO人形機器人、EVE輪式機器人
- **定位**: 家庭與商業服務

#### Boston Dynamics (Atlas)

- **歷史**: 機器人領域先驅
- **Atlas**: 最先進運動能力
- **商業**: Spot (四足), Stretch (物流)
- **所有權**: 現代汽車集團

#### 其他重要玩家

| 公司 | 產品 | 投資者/背景 | 特色 |
|------|------|------------|------|
| Agility Robotics | Digit | Amazon | 物流機器人 |
| Apptronik | Apollo | 多家 | 通用人形 |
| Sanctuary AI | Phoenix | 多家 | 認知AI |
| Unitree | H1/G1 | 中國 | 低成本人形 |
| 小米 | CyberOne | 小米 | 消費電子背景 |
| 傅利葉 | GR-1 | 中國 | 康復起家 |

### 12.3 機器人核心零組件

#### 執行器/關節

| 類型 | 廠商 | 應用 | 特點 |
|------|------|------|------|
| 諧波減速器 | Harmonic Drive (日), 綠的諧波 (中) | 關節 | 精度高 |
| 行星減速器 | Nabtesco, 中大力德 | 重載關節 | 扭矩大 |
| 直驅電機 | 自研為主 | 高響應 | Tesla方案 |
| 液壓 | Boston Dynamics | 高爆發 | 複雜昂貴 |

#### 感測器

| 類型 | 廠商 | 功能 |
|------|------|------|
| 力矩感測器 | ATI, Kistler | 力控制 |
| 視覺相機 | Intel RealSense, 奧比中光 | 環境感知 |
| LiDAR | Velodyne, 禾賽 | 3D建圖 |
| IMU | Bosch, InvenSense | 姿態 |
| 觸覺感測 | 新興技術 | 精細操作 |

### 12.4 具身AI軟體技術

```
具身AI技術棧:
┌─────────────────────────────────────────┐
│     高層決策: LLM/VLM (GPT-4V, Gemini)  │
├─────────────────────────────────────────┤
│     任務規劃: 行為樹、強化學習           │
├─────────────────────────────────────────┤
│     運動控制: 模仿學習、Model Predictive │
├─────────────────────────────────────────┤
│     感知融合: SLAM、物體識別、場景理解   │
├─────────────────────────────────────────┤
│     底層控制: 電機驅動、力控制           │
└─────────────────────────────────────────┘
```

**關鍵技術**:
- **模仿學習**: 從人類示範學習動作
- **強化學習**: 環境互動自我優化
- **多模態AI**: 視覺+語言+動作整合
- **世界模型**: 預測環境變化

### 12.5 機器人投資機會

| 層面 | 投資標的 | 類型 |
|------|---------|------|
| 整機 | Tesla, Figure, 1X | 風險投資 |
| 減速器 | 諧波傳動, 綠的諧波 | 上市公司 |
| 電機 | 匯川技術, 鳴志電器 | 上市公司 |
| 感測器 | 奧比中光, 禾賽 | 上市公司 |
| AI晶片 | NVIDIA, Intel | 上市公司 |

---

## 13. AI 能源與永續發展

> AI數據中心能耗暴增，推動核能復興與永續能源創新。

### 13.1 AI數據中心能耗危機

```
AI訓練能耗演進:
                                          ┌─────────┐
                                    ┌────┤ 100GWh  │ GPT-5?
                              ┌────┤50GWh│         │
                        ┌────┤10GWh│    │         │
                  ┌────┤1GWh │    │    │         │
            ──────┴────┴────┴────┴────┴─────────┘
            GPT-2  GPT-3  GPT-4  GPT-4.5  GPT-5
            2019   2020   2023   2024    2025?
```

| 模型 | 訓練能耗 | 碳排放 | 等效 |
|------|---------|--------|------|
| GPT-3 | 1.3 GWh | 500噸CO2 | 100戶年用電 |
| GPT-4 | ~10 GWh | 數千噸 | 1000戶年用電 |
| Llama 3.1 405B | ~10 GWh | 數千噸 | - |
| GPT-5 (預估) | 50-100 GWh | 數萬噸 | 小城市年用電 |

### 13.2 數據中心電力需求

| 公司 | 2024電力 | 2030預估 | 成長 |
|------|---------|---------|------|
| Microsoft | 4 GW | 15 GW | 275% |
| Google | 3 GW | 10 GW | 233% |
| Amazon | 3 GW | 12 GW | 300% |
| Meta | 2 GW | 8 GW | 300% |
| 全球AI數據中心 | 20 GW | 100 GW | 400% |

### 13.3 核能復興

> 科技巨頭簽署核能協議，推動小型模組化反應爐 (SMR) 發展。

#### 主要核能合作

| 公司 | 合作對象 | 規模 | 時程 |
|------|---------|------|------|
| Microsoft | Constellation Energy | 重啟三哩島 (835 MW) | 2028 |
| Google | Kairos Power | 500 MW SMR | 2030 |
| Amazon | Talen Energy, X-energy | 多處核能 | 2030s |
| Meta | 核能探索中 | 規劃中 | - |

#### SMR 小型模組化反應爐

| 公司 | 產品 | 功率 | 狀態 |
|------|------|------|------|
| NuScale | VOYGR | 77 MW/模組 | NRC認證 |
| TerraPower | Natrium | 345 MW | 建設中 |
| X-energy | Xe-100 | 80 MW | 開發中 |
| Kairos Power | KP-FHR | 140 MW | 開發中 |

### 13.4 再生能源

#### 數據中心再生能源採購

| 公司 | 再生能源目標 | 現況 |
|------|-------------|------|
| Google | 24/7無碳 | 90%+ |
| Microsoft | 100% (2025) | 進行中 |
| Amazon | 100% (2025) | 進行中 |
| Meta | 100% | 已達成 |

#### 再生能源供應商

| 類型 | 主要廠商 | 數據中心應用 |
|------|---------|-------------|
| 太陽能 | First Solar, 隆基 | PPA長約 |
| 風能 | Vestas, GE | 大規模風場 |
| 儲能 | Tesla, CATL | 電力調度 |

### 13.5 能效技術

| 技術 | 節能效果 | 狀態 |
|------|---------|------|
| 液冷散熱 | 30-40% | 主流 |
| 浸沒式冷卻 | 50%+ | 新興 |
| 低PUE設計 | 1.1以下 | 頂級DC |
| AI優化能耗 | 10-15% | Google實踐 |
| 餘熱回收 | 供暖 | 北歐實踐 |

### 13.6 永續發展挑戰

```
AI碳排放 vs 效益權衡:
┌─────────────────────────────────────────┐
│                 能耗                     │
│         ↗                               │
│       ↗   AI效益 (生產力、創新)          │
│     ↗                                   │
├─────────────────────────────────────────┤
│     平衡點: 效益 > 碳成本                │
│     解方: 核能 + 再生能源 + 能效提升      │
└─────────────────────────────────────────┘
```

---

## 14. GPU 產品規格完整對比

### 14.1 NVIDIA 歷代GPU對比

| 規格 | V100 | A100 | H100 | H200 | B100 | B200 |
|------|------|------|------|------|------|------|
| 架構 | Volta | Ampere | Hopper | Hopper | Blackwell | Blackwell |
| 製程 | 12nm | 7nm | 4nm | 4nm | 4nm | 4nm |
| 電晶體 | 211億 | 542億 | 800億 | 800億 | 2080億 | 2080億 |
| FP64 | 7.8 TF | 9.7 TF | 34 TF | 34 TF | 45 TF | 45 TF |
| FP32 | 15.7 TF | 19.5 TF | 67 TF | 67 TF | 90 TF | 90 TF |
| FP16 | 125 TF | 312 TF | 989 TF | 989 TF | 1800 TF | 1800 TF |
| INT8 | 62 TOPS | 624 TOPS | 1979 TOPS | 1979 TOPS | 3600 TOPS | 3600 TOPS |
| FP8 | - | - | 3958 TOPS | 3958 TOPS | 7200 TOPS | 7200 TOPS |
| FP4 | - | - | - | - | 14400 TOPS | 14400 TOPS |
| 記憶體 | 16/32GB HBM2 | 40/80GB HBM2e | 80GB HBM3 | 141GB HBM3e | 192GB HBM3e | 192GB HBM3e |
| 頻寬 | 900 GB/s | 2 TB/s | 3.35 TB/s | 4.8 TB/s | 8 TB/s | 8 TB/s |
| TDP | 300W | 400W | 700W | 700W | 700W | 1000W |
| NVLink | 300 GB/s | 600 GB/s | 900 GB/s | 900 GB/s | 1.8 TB/s | 1.8 TB/s |
| 定價 (雲端) | 舊款 | $10K | $25-30K | $25-30K | $30-40K | $40-50K |

### 14.2 AMD MI系列對比

| 規格 | MI250X | MI300X | MI325X | MI350 (預計) |
|------|--------|--------|--------|--------------|
| 架構 | CDNA 2 | CDNA 3 | CDNA 3+ | CDNA 4 |
| 製程 | 6nm | 5nm | 3nm | 3nm |
| FP64 | 47.9 TF | 81.7 TF | ~100 TF | 提升 |
| FP32 | 47.9 TF | 81.7 TF | ~100 TF | 提升 |
| FP16 | 383 TF | 1307 TF | ~1500 TF | 提升 |
| FP8 | - | 2614 TF | ~3000 TF | 提升 |
| 記憶體 | 128GB HBM2e | 192GB HBM3 | 256GB HBM3e | HBM3e |
| 頻寬 | 3.2 TB/s | 5.3 TB/s | 6 TB/s | 提升 |
| TDP | 560W | 750W | 750W | TBD |

### 14.3 Google TPU對比

| 規格 | TPU v4 | TPU v5e | TPU v5p | TPU v6 |
|------|--------|---------|---------|--------|
| 定位 | 通用 | 經濟 | 高效能 | 新一代 |
| BF16 | 275 TF | 經濟版 | 459 TF | ~900 TF |
| 記憶體 | 32GB HBM2e | 16GB | 95GB HBM2e | HBM3 |
| 互連 | ICI | ICI | ICI | ICI |
| Pod規模 | 4096 TPU | 256 TPU | 8960 TPU | 擴大 |

### 14.4 效能/瓦特比較

```
效能功耗比演進 (正規化):
            H100    H200    B100    B200
FP16/W      1.0     1.0     1.8     1.3
FP8/W       1.0     1.0     1.8     1.3
記憶體/W    1.0     1.8     2.4     2.4

結論: Blackwell架構帶來80%能效提升
      B200功耗增加但總效能更高
```

---

## 15. 產業風險與地緣政治

### 15.1 地緣政治風險矩陣

| 風險 | 影響 | 可能性 | 受影響公司 |
|------|------|--------|-----------|
| 台海衝突 | 致命 | 中 | 全產業 |
| 美中科技戰升級 | 高 | 高 | NVIDIA, AMD, 雲端廠 |
| 台積電產能中斷 | 致命 | 低 | 全產業 |
| HBM供應短缺 | 高 | 中 | GPU廠商 |
| 出口管制擴大 | 中 | 高 | 設備/軟體商 |
| 人才流動限制 | 中 | 中 | 科技公司 |

### 15.2 台海風險分析

```
台灣在全球AI供應鏈角色:
┌─────────────────────────────────────────┐
│ 台積電: 90%+ AI晶片製造                  │ ← 不可替代
│ 日月光: 60%+ 先進封裝                    │ ← 高度集中
│ 台達/光寶: 50%+ 伺服器電源               │ ← 可替代性中
│ 鴻海/廣達: 60%+ AI伺服器組裝             │ ← 可轉移
└─────────────────────────────────────────┘
              ↓
       任何中斷 = 全球AI產業停擺
```

**風險緩解**:
- 台積電美國/日本/德國設廠
- Intel代工能力提升
- 三星擴大先進製程
- 供應鏈多元化

### 15.3 美中科技戰現況

#### 美國管制措施

| 時間 | 措施 | 影響 |
|------|------|------|
| 2022.10 | 禁止先進AI晶片出口 | A100禁售 |
| 2023.10 | 加強管制、堵漏洞 | H100禁售 |
| 2024.01 | 雲端算力限制 | 服務受限 |
| 2024.10 | 第三國限制 | 全面封鎖 |
| 2025+ | 持續收緊 | 待觀察 |

#### 中國反制措施

- 稀土出口管制
- 鎵、鍺出口限制
- 反制裁法律
- 加速國產替代

### 15.4 供應鏈風險

#### HBM供應風險

| 風險 | 影響 | 緩解措施 |
|------|------|---------|
| SK Hynix產能不足 | GPU交付延遲 | 三星/Micron擴產 |
| 韓國地緣風險 | HBM供應中斷 | 美國本土產能 |
| 良率問題 | 成本上升 | 技術改進 |

#### EUV設備風險

| 風險 | 影響 | 現況 |
|------|------|------|
| ASML獨家供應 | 產能瓶頸 | 持續擴產 |
| 地緣政治 (荷蘭) | 出口限制 | 已配合美國 |
| 設備交期 | 18-24個月 | 難以縮短 |

### 15.5 市場風險

| 風險 | 機率 | 影響 |
|------|------|------|
| AI泡沫破裂 | 低-中 | 估值修正 |
| NVIDIA競爭加劇 | 中 | 毛利下降 |
| 開源模型崛起 | 高 | 商業模式改變 |
| 監管加強 | 中 | 合規成本增加 |
| 經濟衰退 | 低 | IT支出減少 |

### 15.6 風險緩解策略

**投資者策略**:
1. 分散投資 (不只押NVIDIA)
2. 關注供應鏈多元化公司
3. 留意地緣政治發展
4. 評估公司護城河深度

**產業策略**:
1. 供應鏈在地化
2. 第二供應商策略
3. 庫存緩衝
4. 技術自主研發

---

## 16. 投資標的完整清單

### 16.1 核心持股 (高確定性)

| 公司 | 代號 | 領域 | 投資邏輯 | 風險 |
|------|------|------|---------|------|
| NVIDIA | NVDA | GPU設計 | 80%市佔壟斷 | 估值高、競爭 |
| 台積電 | TSM/2330 | 晶圓製造 | 90%先進製程 | 地緣政治 |
| ASML | ASML | EUV設備 | 100%壟斷 | 週期性 |
| SK Hynix | 000660.KS | HBM記憶體 | 90% HBM3e | 韓國風險 |

### 16.2 成長型標的

| 公司 | 代號 | 領域 | 投資邏輯 | 風險 |
|------|------|------|---------|------|
| AMD | AMD | GPU追趕者 | MI系列成長 | 軟體生態弱 |
| Broadcom | AVGO | 網路/ASIC | 客製化晶片 | 週期性 |
| Marvell | MRVL | 雲端ASIC | AWS/雲端合作 | 競爭 |
| Arm | ARM | IP授權 | AI晶片基礎 | 估值 |

### 16.3 台灣供應鏈

| 公司 | 代號 | 領域 | 投資邏輯 | 風險 |
|------|------|------|---------|------|
| 台達電 | 2308 | 電源 | 35%伺服器電源 | 匯率 |
| 光寶 | 2301 | 電源 | 價格競爭力 | 毛利壓力 |
| 日月光 | 3711 | 封裝 | CoWoS龍頭 | 產能 |
| 鴻海 | 2317 | 組裝 | DGX代工 | 毛利低 |
| 廣達 | 2382 | 組裝 | 雲端伺服器 | 客戶集中 |
| 緯創 | 3231 | 組裝 | AI伺服器 | 競爭 |
| 奇鋐 | 3017 | 散熱 | 液冷模組 | 規模小 |
| 雙鴻 | 3324 | 散熱 | 液冷成長 | 競爭 |

### 16.4 美國科技

| 公司 | 代號 | 領域 | 投資邏輯 | 風險 |
|------|------|------|---------|------|
| Microsoft | MSFT | 雲端/AI | Azure+OpenAI | 反壟斷 |
| Google | GOOGL | 雲端/AI | Gemini+TPU | 廣告依賴 |
| Amazon | AMZN | 雲端 | AWS龍頭 | 競爭 |
| Meta | META | AI應用 | Llama開源 | 監管 |
| Oracle | ORCL | 雲端 | AI雲成長快 | 規模小 |

### 16.5 AI應用/軟體

| 公司 | 代號 | 領域 | 投資邏輯 | 風險 |
|------|------|------|---------|------|
| Palantir | PLTR | 企業AI | 政府+企業 | 估值高 |
| ServiceNow | NOW | 企業軟體 | AI工作流 | 競爭 |
| MongoDB | MDB | 資料庫 | AI資料層 | 虧損 |
| Datadog | DDOG | 監控 | AI可觀測 | 估值 |
| Snowflake | SNOW | 資料倉儲 | AI分析 | 競爭 |

### 16.6 基礎設施

| 公司 | 代號 | 領域 | 投資邏輯 | 風險 |
|------|------|------|---------|------|
| Vertiv | VRT | 散熱/電源 | 數據中心龍頭 | 週期性 |
| Eaton | ETN | 電力 | 數據中心電力 | 成熟 |
| Schneider | SU.PA | 基礎設施 | 整體方案 | 歐洲 |
| Equinix | EQIX | 數據中心REIT | AI DC需求 | 利率敏感 |

### 16.7 光通訊

| 公司 | 代號 | 領域 | 投資邏輯 | 風險 |
|------|------|------|---------|------|
| 中際旭創 | 300308.SZ | 光模組 | 800G龍頭 | 中國風險 |
| Coherent | COHR | 光通訊 | 垂直整合 | 週期性 |
| Lumentum | LITE | 光學元件 | 雷射技術 | 週期性 |
| Ciena | CIEN | 光網路 | 網路設備 | 競爭 |

### 16.8 ETF選擇

| ETF | 代號 | 聚焦 | 費用率 |
|-----|------|------|--------|
| VanEck Semiconductor | SMH | 半導體 | 0.35% |
| iShares Semiconductor | SOXX | 半導體 | 0.35% |
| Global X Robotics & AI | BOTZ | 機器人AI | 0.68% |
| ARK Autonomous Tech | ARKQ | 自動化 | 0.75% |
| Global X AI & Tech | AIQ | AI科技 | 0.68% |

### 16.9 投資組合建議

```
AI投資組合配置建議:
┌─────────────────────────────────────────┐
│ 核心持股 (40%): NVIDIA, 台積電, ASML    │
├─────────────────────────────────────────┤
│ 成長標的 (25%): AMD, Broadcom, ARM      │
├─────────────────────────────────────────┤
│ 台灣供應鏈 (15%): 台達電, 日月光, 廣達  │
├─────────────────────────────────────────┤
│ 雲端巨頭 (15%): Microsoft, Google       │
├─────────────────────────────────────────┤
│ 新興機會 (5%): 機器人, 光通訊           │
└─────────────────────────────────────────┘

風險管理:
• 單一個股不超過15%
• 台灣曝險注意地緣風險
• 定期再平衡
• 長期持有 (3-5年)
```

---

## 17. 市場規模與關鍵數據

### 17.1 整體市場
- 2024: $200B
- 2030: $1.8T (年增42%)

### 17.2 細分市場 (2024)

**AI晶片**: $70B
- NVIDIA: $40B
- HBM: $10B (SK Hynix $6B)

**數據中心**: $40B
- 伺服器: $25B
- 散熱: $8B
- 電源網路: $7B

**雲端服務**: $50B
- Azure: $15B
- AWS: $12B
- GCP: $10B

**軟體應用**: $40B
- 生成式AI: $15B
- 企業AI: $20B

### 17.3 重點公司

**NVIDIA**:
- 市值: $2.5T
- 營收: $60B
- 毛利率: 70-75%

**台積電**:
- AI晶片營收佔比: 30-35%
- 先進製程: >50%營收

---

## 18. 關鍵結論與趨勢

### 18.1 供應鏈瓶頸 ⚠️

1. **HBM記憶體**: SK Hynix產能限制,交期6-12月
2. **CoWoS封裝**: 台積電+日月光獨家,良率要求>95%
3. **EUV光刻機**: ASML唯一供應商,每台$2億
4. **液冷散熱**: 新技術,部署經驗不足

### 18.2 台灣角色 🇹🇼

**核心地位**:
- 台積電: 90%+ AI晶片製造
- 日月光: CoWoS封裝龍頭
- 台達/光寶: 伺服器電源55%+
- 鴻海/廣達: AI伺服器組裝55%+

**結論**: 台灣是全球AI供應鏈不可或缺的核心

### 18.3 未來趨勢 📈

1. **算力需求暴增**: 2030年需求>100x
2. **散熱技術升級**: 液冷→浸沒式
3. **自研晶片興起**: TPU, Trainium挑戰NVIDIA
4. **開源模型崛起**: Llama挑戰GPT
5. **AI普及化**: 從科技到各行各業

### 18.4 投資機會總結 💡

**確定性機會**:
- 台積電 (製造壟斷)
- SK Hynix (HBM壟斷)
- NVIDIA (設計壟斷)
- 台達電/光寶 (電源龍頭)

**成長性機會**:
- 液冷散熱廠商
- AI應用開發商
- 垂直產業AI

---

## 19. 完整價值鏈流程

```
┌────────────────────────────────────────────────────────────┐
│          AI 產業價值鏈 (從晶片到應用)                       │
├────────────────────────────────────────────────────────────┤
│                                                             │
│  【上游】晶片製造                                           │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━  │
│                                                             │
│  晶片設計 → 晶圓製造 → 封裝測試 → GPU成品                  │
│  NVIDIA     台積電     日月光     H100                      │
│    ↓          ↓          ↓          ↓                       │
│  支援       支援       支援       配套                       │
│  EDA        ASML       CoWoS      HBM(SK Hynix)            │
│  IP授權     材料商     TSV技術    散熱(Vertiv)             │
│            設備商                電源(台達電)              │
│                                                             │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━  │
│                                                             │
│  【中游】系統整合                                           │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━  │
│                                                             │
│  伺服器組裝 → 數據中心 → 雲端平台                          │
│  鴻海/廣達   CoreWeave   Azure/AWS                         │
│    ↓            ↓           ↓                               │
│  配套        配套        配套                               │
│  PDU         液冷        網路(Mellanox)                     │
│  機櫃        UPS         儲存(Pure)                         │
│              電力                                           │
│                                                             │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━  │
│                                                             │
│  【下游】軟體應用                                           │
│  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━  │
│                                                             │
│  AI框架 → 模型訓練 → 應用服務 → 終端用戶                   │
│  PyTorch   GPT-4     ChatGPT    消費者/企業                 │
│    ↓         ↓          ↓           ↓                       │
│  支援     支援      應用        價值                        │
│  MLOps    資料      文字生成    提升效率                    │
│  工具鏈   算力      圖像生成    降低成本                    │
│          人才      程式開發    創新服務                     │
│                                                             │
└────────────────────────────────────────────────────────────┘
```

---

**文檔總結**:

本文檔完整梳理了AI產業從上游晶片設計製造、中游系統整合數據中心、到下游軟體應用的全鏈條,涵蓋:

- **8大產業層次** (晶片/散熱/電源/儲存網路/光通訊/雲端/軟體/邊緣AI)
- **150+ 重點企業** (市佔率/產品/技術/投資邏輯)
- **完整供應鏈關係** (台積電/NVIDIA/SK Hynix等)
- **市場規模數據** ($200B→$1.8T)
- **專題分析**: ASIC晶片、中國AI產業、機器人具身AI、能源永續
- **地緣政治風險**: 台海、美中科技戰、供應鏈風險
- **完整投資標的**: 核心持股、成長標的、台灣供應鏈、ETF
- **GPU規格對比**: NVIDIA/AMD/Google TPU完整數據

**台灣在AI供應鏈的核心地位不可替代**,掌握晶片製造(台積電)、封裝(日月光)、電源(台達/光寶)、伺服器組裝(鴻海/廣達)等關鍵環節。

**2025-2026關鍵趨勢**:
1. Blackwell架構大規模部署
2. 液冷/浸沒式冷卻成為標配
3. 邊緣AI與AI PC普及
4. 人形機器人商業化起步
5. 核能復興支撐AI能源需求

---

*文檔更新: 2026年1月*
*數據來源: 各公司財報、市場研究報告、產業分析*
*注意: 市場佔有率為估計值,實際情況可能有所差異*
*本文檔不構成投資建議,投資有風險,請謹慎評估*
