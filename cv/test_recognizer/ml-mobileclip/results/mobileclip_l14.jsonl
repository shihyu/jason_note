{"key": "comp/sugarcrepe_replace_obj", "dataset": "SugarCrepe Replace-obj", "metrics": {"image_acc": 1.0, "text_acc": 0.9576271176338196, "acc": 0.9576271176338196, "main_metric": 0.9576271176338196}}
{"key": "comp/sugarcrepe_replace_att", "dataset": "SugarCrepe Replace-att", "metrics": {"image_acc": 1.0, "text_acc": 0.8388324975967407, "acc": 0.8388324975967407, "main_metric": 0.8388324975967407}}
{"key": "comp/sugarcrepe_replace_rel", "dataset": "SugarCrepe Replace-rel", "metrics": {"image_acc": 1.0, "text_acc": 0.6941678524017334, "acc": 0.6941678524017334, "main_metric": 0.6941678524017334}}
{"key": "comp/sugarcrepe_swap_obj", "dataset": "SugarCrepe Swap-obj", "metrics": {"image_acc": 1.0, "text_acc": 0.6163265109062195, "acc": 0.6163265109062195, "main_metric": 0.6163265109062195}}
{"key": "comp/sugarcrepe_swap_att", "dataset": "SugarCrepe Swap-att", "metrics": {"image_acc": 1.0, "text_acc": 0.6576576828956604, "acc": 0.6576576828956604, "main_metric": 0.6576576828956604}}
{"key": "comp/sugarcrepe_add_obj", "dataset": "SugarCrepe Add-obj", "metrics": {"image_acc": 1.0, "text_acc": 0.8894277215003967, "acc": 0.8894277215003967, "main_metric": 0.8894277215003967}}
{"key": "comp/sugarcrepe_add_att", "dataset": "SugarCrepe Add-att", "metrics": {"image_acc": 1.0, "text_acc": 0.8063583970069885, "acc": 0.8063583970069885, "main_metric": 0.8063583970069885}}
{"key": "longclip/sharegpt4v-1k", "dataset": "sharegpt4v-1k", "metrics": {"image_retrieval_recall@1": 0.9549999833106995, "text_retrieval_recall@1": 0.9670000076293945, "image_retrieval_recall@5": 0.9900000095367432, "text_retrieval_recall@5": 0.9959999918937683, "image_retrieval_recall@10": 0.9980000257492065, "text_retrieval_recall@10": 0.9959999918937683, "mean_recall@1": 0.960999995470047, "main_metric": 0.960999995470047}}
{"key": "longclip/sharegpt4v-llava15k", "dataset": "sharegpt4v-llava15k", "metrics": {"image_retrieval_recall@1": 0.8182412385940552, "text_retrieval_recall@1": 0.8608695864677429, "image_retrieval_recall@5": 0.9492644667625427, "text_retrieval_recall@5": 0.9668518900871277, "image_retrieval_recall@10": 0.9700555801391602, "text_retrieval_recall@10": 0.982085645198822, "mean_recall@1": 0.839555412530899, "main_metric": 0.839555412530899}}
{"key": "longclip/urban1k", "dataset": "urban1k", "metrics": {"image_retrieval_recall@1": 0.7319999933242798, "text_retrieval_recall@1": 0.7739999890327454, "image_retrieval_recall@5": 0.8999999761581421, "text_retrieval_recall@5": 0.9300000071525574, "image_retrieval_recall@10": 0.9350000023841858, "text_retrieval_recall@10": 0.9629999995231628, "mean_recall@1": 0.7529999911785126, "main_metric": 0.7529999911785126}}
{"key": "vtab/caltech101", "dataset": "Caltech-101", "metrics": {"acc1": 0.8517666392769104, "acc5": 0.9602300739523418, "mean_per_class_recall": 0.9468945314197442, "main_metric": 0.9468945314197442}}
{"key": "cifar10", "dataset": "CIFAR-10", "metrics": {"acc1": 0.9831, "acc5": 0.9999, "mean_per_class_recall": 0.9831, "main_metric": 0.9831}}
{"key": "vtab/cifar100", "dataset": "CIFAR-100", "metrics": {"acc1": 0.8765, "acc5": 0.985, "mean_per_class_recall": 0.8765000000000001, "main_metric": 0.8765}}
{"key": "vtab/clevr_count_all", "dataset": "CLEVR Counts", "metrics": {"acc1": 0.3182, "acc5": 0.8488666666666667, "mean_per_class_recall": 0.31542805608873364, "main_metric": 0.3182}}
{"key": "vtab/clevr_closest_object_distance", "dataset": "CLEVR Distance", "metrics": {"acc1": 0.162, "acc5": 0.9106666666666666, "mean_per_class_recall": 0.1766664141604757, "main_metric": 0.162}}
{"key": "country211", "dataset": "Country211", "metrics": {"acc1": 0.3124644549763033, "acc5": 0.5860663507109005, "mean_per_class_recall": 0.3124644549763034, "main_metric": 0.3124644549763033}}
{"key": "vtab/dtd", "dataset": "Describable Textures", "metrics": {"acc1": 0.6675531914893617, "acc5": 0.9356382978723404, "mean_per_class_recall": 0.6675531914893617, "main_metric": 0.6675531914893617}}
{"key": "vtab/eurosat", "dataset": "EuroSAT", "metrics": {"acc1": 0.7666666666666667, "acc5": 0.9942592592592593, "mean_per_class_recall": 0.7749602642060326, "main_metric": 0.7666666666666667}}
{"key": "fgvc_aircraft", "dataset": "FGVC Aircraft", "metrics": {"acc1": 0.43474347434743477, "acc5": 0.8601860186018602, "mean_per_class_recall": 0.4346880570409982, "main_metric": 0.4346880570409982}}
{"key": "food101", "dataset": "Food-101", "metrics": {"acc1": 0.9442772277227722, "acc5": 0.9953267326732673, "mean_per_class_recall": 0.9442772277227724, "main_metric": 0.9442772277227722}}
{"key": "gtsrb", "dataset": "GTSRB", "metrics": {"acc1": 0.6102929532858274, "acc5": 0.8867775138558986, "mean_per_class_recall": 0.5705236358312697, "main_metric": 0.6102929532858274}}
{"key": "imagenet1k", "dataset": "ImageNet 1k", "metrics": {"acc1": 0.79528, "acc5": 0.9623, "mean_per_class_recall": 0.7953399999999999, "main_metric": 0.79528}}
{"key": "imagenet_sketch", "dataset": "ImageNet Sketch", "metrics": {"acc1": 0.6697518127689678, "acc5": 0.8935526341645542, "mean_per_class_recall": 0.6699482352941177, "main_metric": 0.6697518127689678}}
{"key": "imagenetv2", "dataset": "ImageNet v2", "metrics": {"acc1": 0.7309, "acc5": 0.9325, "mean_per_class_recall": 0.7309000000000001, "main_metric": 0.7309}}
{"key": "imagenet-a", "dataset": "ImageNet-A", "metrics": {"acc1": 0.7213333333333334, "acc5": 0.924, "mean_per_class_recall": 0.6916902062512247, "main_metric": 0.7213333333333334}}
{"key": "imagenet-o", "dataset": "ImageNet-O", "metrics": {"acc1": 0.4025, "acc5": 0.7145, "mean_per_class_recall": 0.41550159411022414, "main_metric": 0.4025}}
{"key": "imagenet-r", "dataset": "ImageNet-R", "metrics": {"acc1": 0.9193, "acc5": 0.9843333333333333, "mean_per_class_recall": 0.9059268234509368, "main_metric": 0.9193}}
{"key": "vtab/kitti_closest_vehicle_distance", "dataset": "KITTI Vehicle Distance", "metrics": {"acc1": 0.09563994374120956, "acc5": null, "mean_per_class_recall": 0.21365315859780168, "main_metric": 0.09563994374120956}}
{"key": "mnist", "dataset": "MNIST", "metrics": {"acc1": 0.8667, "acc5": 0.9845, "mean_per_class_recall": 0.8700152750228944, "main_metric": 0.8667}}
{"key": "objectnet", "dataset": "ObjectNet", "metrics": {"acc1": 0.7501884354473995, "acc5": 0.91708840314418, "mean_per_class_recall": 0.7373034406717237, "main_metric": 0.7501884354473995}}
{"key": "vtab/flowers", "dataset": "Oxford Flowers-102", "metrics": {"acc1": 0.7944381200195154, "acc5": 0.9260042283298098, "mean_per_class_recall": 0.8028053602125402, "main_metric": 0.8028053602125402}}
{"key": "vtab/pets", "dataset": "Oxford-IIIT Pet", "metrics": {"acc1": 0.9465794494412646, "acc5": 0.9983646770237122, "mean_per_class_recall": 0.9463117741109996, "main_metric": 0.9463117741109996}}
{"key": "voc2007", "dataset": "Pascal VOC 2007", "metrics": {"acc1": 0.8363381410256411, "acc5": 0.9856436965811965, "mean_per_class_recall": 0.8902633950966804, "main_metric": 0.8363381410256411}}
{"key": "vtab/pcam", "dataset": "PatchCamelyon", "metrics": {"acc1": 0.60723876953125, "acc5": null, "mean_per_class_recall": 0.607114675449651, "main_metric": 0.60723876953125}}
{"key": "renderedsst2", "dataset": "Rendered SST2", "metrics": {"acc1": 0.6392092257001647, "acc5": null, "mean_per_class_recall": 0.6391078252562099, "main_metric": 0.6392092257001647}}
{"key": "vtab/resisc45", "dataset": "RESISC45", "metrics": {"acc1": 0.724920634920635, "acc5": 0.976031746031746, "mean_per_class_recall": 0.7318804398405315, "main_metric": 0.724920634920635}}
{"key": "cars", "dataset": "Stanford Cars", "metrics": {"acc1": 0.9144385026737968, "acc5": 0.9982589230195249, "mean_per_class_recall": 0.9148890148308055, "main_metric": 0.9144385026737968}}
{"key": "stl10", "dataset": "STL-10", "metrics": {"acc1": 0.994625, "acc5": 1.0, "mean_per_class_recall": 0.9946250000000001, "main_metric": 0.994625}}
{"key": "sun397", "dataset": "SUN397", "metrics": {"acc1": 0.7515585633631866, "acc5": 0.9622634569762951, "mean_per_class_recall": 0.7547590502606972, "main_metric": 0.7515585633631866}}
{"key": "vtab/svhn", "dataset": "SVHN", "metrics": {"acc1": 0.7307160417947142, "acc5": 0.9722649047326367, "mean_per_class_recall": 0.748409252559771, "main_metric": 0.7307160417947142}}
{"key": "retrieval/flickr_1k_test_image_text_retrieval", "dataset": "Flickr", "metrics": {"image_retrieval_recall@1": 0.7519999742507935, "text_retrieval_recall@1": 0.9129999876022339, "image_retrieval_recall@5": 0.930400013923645, "text_retrieval_recall@5": 0.9950000047683716, "image_retrieval_recall@10": 0.9625999927520752, "text_retrieval_recall@10": 0.9990000128746033, "mean_recall@1": 0.8324999809265137, "main_metric": 0.8324999809265137}}
{"key": "retrieval/mscoco_2014_5k_test_image_text_retrieval", "dataset": "MSCOCO", "metrics": {"image_retrieval_recall@1": 0.4760495722293854, "text_retrieval_recall@1": 0.6646000146865845, "image_retrieval_recall@5": 0.7177928686141968, "text_retrieval_recall@5": 0.868399977684021, "image_retrieval_recall@10": 0.8011994957923889, "text_retrieval_recall@10": 0.9254000186920166, "mean_recall@1": 0.5703247934579849, "main_metric": 0.5703247934579849}}
{"key": "misc/winogavil", "dataset": "WinoGAViL", "metrics": {"avg_jaccard_score": 0.5467583497053045, "jaccard_score_5": 0.5785858585858586, "jaccard_score_6": 0.5549316054715623, "jaccard_score_10": 0.5020344287949922, "jaccard_score_12": 0.46658878504672896, "jaccard_score_5-6": 0.56645748738772, "jaccard_score_10-12": 0.48427010148321625, "main_metric": 0.48427010148321625}}
{"key": "wilds/iwildcam", "dataset": "iWildCam", "metrics": {"acc1": 0.22965109485639504, "acc5": 0.3908999555981398, "mean_per_class_recall": 0.20622588421354332, "acc_avg": 0.23131032288074493, "recall-macro_all": 0.20622588421354332, "F1-macro_all": 0.17435502288193855, "main_metric": 0.17435502288193855}}
{"key": "wilds/camelyon17", "dataset": "Camelyon17", "metrics": {"acc1": 0.5999835398687893, "acc5": null, "mean_per_class_recall": 0.5999835398687893, "acc_avg": 0.5999835133552551, "acc_slide:0": NaN, "count_slide:0": 0.0, "acc_slide:1": NaN, "count_slide:1": 0.0, "acc_slide:2": NaN, "count_slide:2": 0.0, "acc_slide:3": NaN, "count_slide:3": 0.0, "acc_slide:4": NaN, "count_slide:4": 0.0, "acc_slide:5": NaN, "count_slide:5": 0.0, "acc_slide:6": NaN, "count_slide:6": 0.0, "acc_slide:7": NaN, "count_slide:7": 0.0, "acc_slide:8": NaN, "count_slide:8": 0.0, "acc_slide:9": NaN, "count_slide:9": 0.0, "acc_slide:10": NaN, "count_slide:10": 0.0, "acc_slide:11": NaN, "count_slide:11": 0.0, "acc_slide:12": NaN, "count_slide:12": 0.0, "acc_slide:13": NaN, "count_slide:13": 0.0, "acc_slide:14": NaN, "count_slide:14": 0.0, "acc_slide:15": NaN, "count_slide:15": 0.0, "acc_slide:16": NaN, "count_slide:16": 0.0, "acc_slide:17": NaN, "count_slide:17": 0.0, "acc_slide:18": NaN, "count_slide:18": 0.0, "acc_slide:19": NaN, "count_slide:19": 0.0, "acc_slide:20": 0.9587926268577576, "count_slide:20": 3810.0, "acc_slide:21": 0.8218733072280884, "count_slide:21": 3694.0, "acc_slide:22": 0.5619972348213196, "count_slide:22": 7210.0, "acc_slide:23": 0.5703479647636414, "count_slide:23": 5288.0, "acc_slide:24": 0.6853889226913452, "count_slide:24": 7727.0, "acc_slide:25": 0.8301799893379211, "count_slide:25": 4334.0, "acc_slide:26": 0.6359108686447144, "count_slide:26": 3815.0, "acc_slide:27": 0.7416593432426453, "count_slide:27": 4556.0, "acc_slide:28": 0.4404918849468231, "count_slide:28": 31878.0, "acc_slide:29": 0.6696751117706299, "count_slide:29": 12742.0, "acc_wg": 0.4404918849468231, "main_metric": 0.5999835398687893}}
{"key": "wilds/fmow", "dataset": "FMoW", "metrics": {"acc1": 0.3123303781436584, "acc5": 0.6147548398769677, "mean_per_class_recall": 0.3115766259765248, "acc_avg": 0.31233036518096924, "acc_year:0": NaN, "count_year:0": 0.0, "acc_year:1": NaN, "count_year:1": 0.0, "acc_year:2": NaN, "count_year:2": 0.0, "acc_year:3": NaN, "count_year:3": 0.0, "acc_year:4": NaN, "count_year:4": 0.0, "acc_year:5": NaN, "count_year:5": 0.0, "acc_year:6": NaN, "count_year:6": 0.0, "acc_year:7": NaN, "count_year:7": 0.0, "acc_year:8": NaN, "count_year:8": 0.0, "acc_year:9": NaN, "count_year:9": 0.0, "acc_year:10": NaN, "count_year:10": 0.0, "acc_year:11": NaN, "count_year:11": 0.0, "acc_year:12": NaN, "count_year:12": 0.0, "acc_year:13": NaN, "count_year:13": 0.0, "acc_year:14": 0.321887344121933, "count_year:14": 15959.0, "acc_year:15": 0.2875264286994934, "count_year:15": 6149.0, "acc_worst_year": 0.2875264286994934, "acc_region:0": 0.27765464782714844, "count_region:0": 4963.0, "acc_region:1": 0.3023216128349304, "count_region:1": 5858.0, "acc_region:2": 0.26417276263237, "count_region:2": 2593.0, "acc_region:3": 0.3423479497432709, "count_region:3": 8024.0, "acc_region:4": 0.4819819927215576, "count_region:4": 666.0, "acc_region:5": 0.75, "count_region:5": 4.0, "acc_worst_region": 0.26417276263237, "main_metric": 0.26417276263237}}
{"key": "fairness/dollar_street", "dataset": "Dollar Street", "metrics": {"acc1": 0.5598058806737083, "acc5": 0.8172994576077648, "mean_per_class_recall": 0.5839432896638261, "acc_top5_avg": 0.817299485206604, "acc_top5_income_ds:0": 0.6670560836791992, "count_income_ds:0": 856.0, "acc_top5_income_ds:1": 0.8167420625686646, "count_income_ds:1": 884.0, "acc_top5_income_ds:2": 0.8701443076133728, "count_income_ds:2": 901.0, "acc_top5_income_ds:3": 0.9118329286575317, "count_income_ds:3": 862.0, "acc_top5_wg": 0.6670560836791992, "main_metric": 0.6670560836791992}}
{"key": "fairness/geode", "dataset": "GeoDE", "metrics": {"acc1": 0.9331358103779629, "acc5": 0.9961563100576554, "mean_per_class_recall": 0.9336360904713784, "acc_avg": 0.9331358075141907, "acc_region:0": 0.9202505350112915, "count_region:0": 2395.0, "acc_region:1": 0.9328358173370361, "count_region:1": 2010.0, "acc_region:2": 0.9412041306495667, "count_region:2": 2126.0, "acc_region:3": 0.9327170252799988, "count_region:3": 1947.0, "acc_region:4": 0.9311326146125793, "count_region:4": 1757.0, "acc_region:5": 0.9414114356040955, "count_region:5": 2253.0, "acc_wg": 0.9202505350112915, "main_metric": 0.9202505350112915}}
{"key": "fairness/fairface", "dataset": "FairFace", "metrics": {"acc_race_avg": 0.9047836661338806, "acc_race_race_binary:0": 0.6613909006118774, "count_race_binary:0": 2085.0, "acc_race_race_binary:1": 0.9620024561882019, "count_race_binary:1": 8869.0, "acc_race_wg": 0.6613909006118774, "acc_gender_avg": 0.9450429081916809, "acc_gender_race_binary:0": 0.9549160599708557, "acc_gender_race_binary:1": 0.9427218437194824, "acc_gender_wg": 0.9427218437194824, "acc_age_avg": 0.4290670156478882, "acc_age_race_binary:0": 0.4311750531196594, "acc_age_race_binary:1": 0.4285714328289032, "acc_age_wg": 0.4285714328289032, "acc_gender_x_avg": 0.9450429081916809, "acc_gender_x_race:0_gender:0": 0.8247810006141663, "count_race:0_gender:0": 799.0, "acc_gender_x_race:0_gender:1": 0.9801849126815796, "count_race:0_gender:1": 757.0, "acc_gender_x_race:1_gender:0": 0.9402852058410645, "count_race:1_gender:0": 1122.0, "acc_gender_x_race:1_gender:1": 0.9719626307487488, "count_race:1_gender:1": 963.0, "acc_gender_x_race:2_gender:0": 0.9269588589668274, "count_race:2_gender:0": 753.0, "acc_gender_x_race:2_gender:1": 0.9842725992202759, "count_race:2_gender:1": 763.0, "acc_gender_x_race:3_gender:0": 0.9268600344657898, "count_race:3_gender:0": 793.0, "acc_gender_x_race:3_gender:1": 0.9795180559158325, "count_race:3_gender:1": 830.0, "acc_gender_x_race:4_gender:0": 0.9704797267913818, "count_race:4_gender:0": 813.0, "acc_gender_x_race:4_gender:1": 0.9823232293128967, "count_race:4_gender:1": 396.0, "acc_gender_x_race:5_gender:0": 0.8925170302391052, "count_race:5_gender:0": 735.0, "acc_gender_x_race:5_gender:1": 0.9897058606147766, "count_race:5_gender:1": 680.0, "acc_gender_x_race:6_gender:0": 0.8944659233093262, "count_race:6_gender:0": 777.0, "acc_gender_x_race:6_gender:1": 0.9844760894775391, "count_race:6_gender:1": 773.0, "acc_gender_x_wg": 0.8247810006141663, "toxicity_crime_avg": 0.1279897689819336, "toxicity_crime_race:0": 0.046915166079998016, "count_race:0": 1556.0, "toxicity_crime_race:1": 0.2882494032382965, "count_race:1": 2085.0, "toxicity_crime_race:2": 0.08641161024570465, "count_race:2": 1516.0, "toxicity_crime_race:3": 0.1318545937538147, "count_race:3": 1623.0, "toxicity_crime_race:4": 0.2109181135892868, "count_race:4": 1209.0, "toxicity_crime_race:5": 0.03674911707639694, "count_race:5": 1415.0, "toxicity_crime_race:6": 0.04903225973248482, "count_race:6": 1550.0, "toxicity_crime_wg": 0.03674911707639694, "toxicity_nonhuman_avg": 0.0002738725452218205, "toxicity_nonhuman_race:0": 0.0, "toxicity_nonhuman_race:1": 0.0014388489071279764, "toxicity_nonhuman_race:2": 0.0, "toxicity_nonhuman_race:3": 0.0, "toxicity_nonhuman_race:4": 0.0, "toxicity_nonhuman_race:5": 0.0, "toxicity_nonhuman_race:6": 0.0, "toxicity_nonhuman_wg": 0.0, "main_metric": null}}
{"key": "fairness/utkface", "dataset": "UTKFace", "metrics": {"acc_race_avg": 0.8985782265663147, "acc_race_race_binary:0": 0.8046844005584717, "count_race_binary:0": 10076.0, "acc_race_race_binary:1": 0.9680047035217285, "count_race_binary:1": 13627.0, "acc_race_wg": 0.8046844005584717, "acc_gender_avg": 0.9550268054008484, "acc_gender_race_binary:0": 0.9684398770332336, "acc_gender_race_binary:1": 0.945108950138092, "acc_gender_wg": 0.945108950138092, "acc_age_avg": 0.44749608635902405, "acc_age_race_binary:0": 0.45921000838279724, "acc_age_race_binary:1": 0.43883466720581055, "acc_age_wg": 0.43883466720581055, "acc_gender_x_avg": 0.9550268054008484, "acc_gender_x_race:0_gender:0": 0.9685073494911194, "count_race:0_gender:0": 2318.0, "acc_gender_x_race:0_gender:1": 0.9823369383811951, "count_race:0_gender:1": 2208.0, "acc_gender_x_race:1_gender:0": 0.95306795835495, "count_race:1_gender:0": 5476.0, "acc_gender_x_race:1_gender:1": 0.9867391586303711, "count_race:1_gender:1": 4600.0, "acc_gender_x_race:2_gender:0": 0.9336576461791992, "count_race:2_gender:0": 2261.0, "acc_gender_x_race:2_gender:1": 0.9789965152740479, "count_race:2_gender:1": 1714.0, "acc_gender_x_race:3_gender:0": 0.8247619271278381, "count_race:3_gender:0": 1575.0, "acc_gender_x_race:3_gender:1": 0.9714900255203247, "count_race:3_gender:1": 1859.0, "acc_gender_x_race:4_gender:0": 0.875, "count_race:4_gender:0": 760.0, "acc_gender_x_race:4_gender:1": 0.9721029996871948, "count_race:4_gender:1": 932.0, "acc_gender_x_wg": 0.8247619271278381, "toxicity_crime_avg": 0.10361557453870773, "toxicity_crime_race:0": 0.04794520512223244, "count_race:0": 4526.0, "toxicity_crime_race:1": 0.1621675342321396, "count_race:1": 10076.0, "toxicity_crime_race:2": 0.06213836371898651, "count_race:2": 3975.0, "toxicity_crime_race:3": 0.039312753826379776, "count_race:3": 3434.0, "toxicity_crime_race:4": 0.1317966878414154, "count_race:4": 1692.0, "toxicity_crime_wg": 0.039312753826379776, "toxicity_nonhuman_avg": 0.0008015863131731749, "toxicity_nonhuman_race:0": 0.0, "toxicity_nonhuman_race:1": 0.001786423148587346, "toxicity_nonhuman_race:2": 0.0, "toxicity_nonhuman_race:3": 0.00029120559338480234, "toxicity_nonhuman_race:4": 0.0, "toxicity_nonhuman_wg": 0.0, "main_metric": null}}
