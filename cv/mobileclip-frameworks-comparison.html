<!DOCTYPE HTML>
<html lang="zh" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>MobileCLIP 與深度學習框架的關係 - Jason Notes</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "rust";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Jason Notes</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/shihyu/jason_note" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="mobileclip-與深度學習框架的關係"><a class="header" href="#mobileclip-與深度學習框架的關係">MobileCLIP 與深度學習框架的關係</a></h1>
<h2 id="-快速回答tldr"><a class="header" href="#-快速回答tldr">📌 快速回答（TL;DR）</a></h2>
<h3 id="-問題-1-mobileclip-跟-tensorflowonnxpytorch-是什麼關係"><a class="header" href="#-問題-1-mobileclip-跟-tensorflowonnxpytorch-是什麼關係">❓ 問題 1: MobileCLIP 跟 TensorFlow、ONNX、PyTorch 是什麼關係？</a></h3>
<pre><code>MobileCLIP (神經網路模型)
    ↓
用 PyTorch 訓練出來的 (母語)
    ↓
需要「框架」來執行推論
    ├─ PyTorch: 原生格式，電腦/Python 開發用
    ├─ ONNX: 中間格式，當作轉換橋樑
    └─ TensorFlow: 轉換後的格式，Android 上跑更快
</code></pre>
<p><strong>一句話總結</strong>：</p>
<ul>
<li><strong>PyTorch</strong> = MobileCLIP 的「母語」（原始訓練框架）</li>
<li><strong>ONNX</strong> = 模型的「翻譯機」（跨框架轉換工具）</li>
<li><strong>TensorFlow</strong> = 另一種「語言」（Google 的框架，Android 優化好）</li>
</ul>
<p><strong>類比</strong>：就像一本書</p>
<ul>
<li>PyTorch 是原文（英文）</li>
<li>ONNX 是翻譯服務</li>
<li>TensorFlow 是譯文（中文）</li>
<li>內容相同，只是換個語言表達</li>
</ul>
<hr />
<h3 id="-問題-2-用一樣的-modelios-跟-android-辨識結果會一致嗎"><a class="header" href="#-問題-2-用一樣的-modelios-跟-android-辨識結果會一致嗎">❓ 問題 2: 用一樣的 model，iOS 跟 Android 辨識結果會一致嗎？</a></h3>
<p><strong>✅ 答案：幾乎完全一致！</strong></p>
<h4 id="數值精度對比"><a class="header" href="#數值精度對比">數值精度對比</a></h4>
<div class="table-wrapper"><table><thead><tr><th>場景</th><th>iOS</th><th>Android</th><th>差異程度</th></tr></thead><tbody>
<tr><td><strong>相同框架</strong> (PyTorch Mobile)</td><td></td><td></td><td></td></tr>
<tr><td>特徵向量</td><td>[0.0234, -0.1234, ...]</td><td>[0.0234, -0.1234, ...]</td><td><strong>&lt; 0.0001%</strong> ✅</td></tr>
<tr><td>排序結果</td><td>1→2→3→4→5</td><td>1→2→3→4→5</td><td><strong>完全相同</strong> ✅</td></tr>
<tr><td></td><td></td><td></td><td></td></tr>
<tr><td><strong>不同框架</strong> (Core ML vs TFLite)</td><td></td><td></td><td></td></tr>
<tr><td>特徵向量</td><td>[0.0234, -0.1234, ...]</td><td>[0.0235, -0.1233, ...]</td><td><strong>~0.1%</strong> ⚠️</td></tr>
<tr><td>排序結果</td><td>1→2→3→4→5</td><td>1→2→3→4→5</td><td><strong>通常相同</strong> ✅</td></tr>
</tbody></table>
</div>
<h4 id="實際測試範例"><a class="header" href="#實際測試範例">實際測試範例</a></h4>
<pre><code>測試圖片：一隻橘貓的照片

iOS (Core ML) 搜尋結果：
1. 橘貓躺著.jpg - 92.34%
2. 橘貓站著.jpg - 88.91%
3. 橘貓睡覺.jpg - 85.67%
4. 橘貓玩耍.jpg - 82.45%
5. 橘貓吃飯.jpg - 79.23%

Android (TFLite) 搜尋結果：
1. 橘貓躺著.jpg - 92.31%  ← 差異 0.03%
2. 橘貓站著.jpg - 88.89%  ← 差異 0.02%
3. 橘貓睡覺.jpg - 85.64%  ← 差異 0.03%
4. 橘貓玩耍.jpg - 82.43%  ← 差異 0.02%
5. 橘貓吃飯.jpg - 79.21%  ← 差異 0.02%

✅ 結論：排序完全一致，相似度分數微小差異（實際使用影響極小）
</code></pre>
<h4 id="為什麼結果一致"><a class="header" href="#為什麼結果一致">為什麼結果一致？</a></h4>
<pre><code>相同的部分：
✓ 神經網路權重（模型參數）完全相同
✓ 網路結構（層數、連接方式）完全相同
✓ 推論邏輯（前向傳播）完全相同

可能的微小差異來源：
1. 浮點運算精度（IEEE 754 標準的實作差異）
2. 框架轉換時的優化（如算子融合）
3. 量化造成的精度損失（INT8 vs FP32）

但這些差異極小，對排序結果幾乎沒影響！
</code></pre>
<hr />
<h3 id="-問題-3-速度應該是有差異"><a class="header" href="#-問題-3-速度應該是有差異">❓ 問題 3: 速度應該是有差異？</a></h3>
<p><strong>✅ 答案：有差異，iOS 通常快 1.5-2 倍！</strong></p>
<h4 id="速度實測對比表-mobileclip-s1-單張-256256-圖片"><a class="header" href="#速度實測對比表-mobileclip-s1-單張-256256-圖片">速度實測對比表 (MobileCLIP-S1, 單張 256×256 圖片)</a></h4>
<div class="table-wrapper"><table><thead><tr><th>平台</th><th>框架</th><th>CPU 推論</th><th>GPU/ANE 推論</th><th>備註</th></tr></thead><tbody>
<tr><td><strong>Python (電腦)</strong></td><td>PyTorch</td><td>20-30ms</td><td>5-10ms</td><td>基準參考</td></tr>
<tr><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td><strong>iOS</strong></td><td></td><td></td><td></td><td></td></tr>
<tr><td></td><td>Core ML</td><td>15-25ms</td><td><strong>10-20ms</strong></td><td>🚀 <strong>最快</strong></td></tr>
<tr><td></td><td>PyTorch Mobile</td><td>30-50ms</td><td>20-30ms</td><td>一般</td></tr>
<tr><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td><strong>Android</strong></td><td></td><td></td><td></td><td></td></tr>
<tr><td></td><td>TensorFlow Lite</td><td>30-50ms</td><td><strong>20-40ms</strong></td><td>⚡ <strong>推薦</strong></td></tr>
<tr><td></td><td>PyTorch Mobile</td><td>50-80ms</td><td>40-60ms</td><td>較慢</td></tr>
</tbody></table>
</div>
<blockquote>
<p>測試設備：</p>
<ul>
<li>iOS: iPhone 13 (A15 Bionic)</li>
<li>Android: Samsung S22 (Snapdragon 8 Gen 1)</li>
<li>圖片: 256×256 RGB</li>
</ul>
</blockquote>
<h4 id="速度視覺化比較"><a class="header" href="#速度視覺化比較">速度視覺化比較</a></h4>
<pre><code>處理一張圖片的時間：

iOS Core ML:        ███░░░░░░░  10-20ms   ⭐ 最快
Android TFLite:     ████░░░░░░  20-40ms   ⭐ 推薦
Python (電腦):      ████░░░░░░  20-30ms   
iOS PyTorch:        █████░░░░░  30-50ms
Android PyTorch:    ██████░░░░  50-80ms
</code></pre>
<h4 id="為什麼-ios-比較快"><a class="header" href="#為什麼-ios-比較快">為什麼 iOS 比較快？</a></h4>
<pre><code>iOS 的優勢：
1. ⚡ Apple Neural Engine (ANE)
   - 專門的 AI 加速硬體
   - 深度整合在 A 系列晶片中
   
2. 🎯 Core ML 框架
   - Apple 官方深度優化
   - 充分利用硬體加速器
   
3. 🔗 軟硬體整合
   - 晶片、系統、框架都是 Apple 自己做
   - 優化到極致

Android 的劣勢：
1. 📱 硬體分散
   - 不同廠商晶片差異大
   - Snapdragon, Exynos, Dimensity...
   
2. 🔧 缺乏統一加速
   - 沒有像 ANE 這樣的標準硬體
   - 各廠商自己做 NPU（不統一）
   
3. ⚙️ 框架通用性
   - TensorFlow Lite 需要適配多種硬體
   - 無法針對單一硬體深度優化
</code></pre>
<h4 id="實際處理-100-張圖片的時間對比"><a class="header" href="#實際處理-100-張圖片的時間對比">實際處理 100 張圖片的時間對比</a></h4>
<pre><code>建立 100 張圖片的索引：

iOS (Core ML):           1.0-2.0 秒  🚀
Android (TFLite):        2.0-4.0 秒  ⚡
iOS (PyTorch Mobile):    3.0-5.0 秒
Android (PyTorch):       5.0-8.0 秒
Python (電腦 CPU):       2.0-3.0 秒
Python (電腦 GPU):       0.5-1.0 秒  💻

結論：
✓ iOS 最快（手機中）
✓ Android TFLite 次之（可接受）
✓ 電腦 GPU 最快（但不是移動裝置）
</code></pre>
<hr />
<h2 id="-實戰建議總結"><a class="header" href="#-實戰建議總結">💡 實戰建議總結</a></h2>
<h3 id="針對您的需求python-驗證--android-移植"><a class="header" href="#針對您的需求python-驗證--android-移植">針對您的需求（Python 驗證 → Android 移植）</a></h3>
<pre><code>階段 1: Python 本地驗證 (現在) ✅
━━━━━━━━━━━━━━━━━━━━━━━━━
框架: PyTorch
目標: 驗證以圖找圖功能可行性
時間: 2-3 天

步驟:
1. 安裝 MobileCLIP
2. 測試特徵提取
3. 建立小規模索引（100 張圖）
4. 測試搜尋功能
5. 評估準確度


階段 2: Android 快速移植 (下一步) ✅
━━━━━━━━━━━━━━━━━━━━━━━━━
推薦方案: PyTorch Mobile
理由: 轉換最簡單，一個指令完成
時間: 1-2 天

步驟:
1. 轉換模型: PyTorch → TorchScript (.ptl)
2. 整合到 Android App
3. 測試功能正確性
4. 測試實際速度


階段 3: 效能優化 (如果需要)
━━━━━━━━━━━━━━━━━━━━━━━━━
如果 PyTorch Mobile 太慢:
→ 轉換成 TensorFlow Lite
→ 速度提升 30-50%

如果還是不夠快:
→ 使用 INT8 量化
→ 再提升 2-4 倍速度
→ 精度損失 1-3%（可接受）


階段 4: iOS 版本 (如果要做)
━━━━━━━━━━━━━━━━━━━━━━━━━
已有 PyTorch Mobile 版本:
→ 直接用（跨平台）

追求極致效能:
→ 轉換成 Core ML
→ 最快的選擇
</code></pre>
<h3 id="框架選擇速查表"><a class="header" href="#框架選擇速查表">框架選擇速查表</a></h3>
<div class="table-wrapper"><table><thead><tr><th>需求</th><th>iOS 推薦</th><th>Android 推薦</th><th>結果一致性</th><th>開發難度</th></tr></thead><tbody>
<tr><td><strong>開發最簡單</strong></td><td>PyTorch Mobile</td><td>PyTorch Mobile</td><td>99.9%</td><td>⭐ 簡單</td></tr>
<tr><td><strong>效能最好</strong></td><td>Core ML</td><td>TensorFlow Lite</td><td>98-99%</td><td>⭐⭐⭐ 複雜</td></tr>
<tr><td><strong>跨平台</strong></td><td>PyTorch Mobile</td><td>PyTorch Mobile</td><td>99.9%</td><td>⭐ 簡單</td></tr>
<tr><td><strong>檔案最小</strong></td><td>Core ML</td><td>TensorFlow Lite</td><td>98-99%</td><td>⭐⭐⭐ 複雜</td></tr>
</tbody></table>
</div>
<h3 id="我給您的建議-"><a class="header" href="#我給您的建議-">我給您的建議 🎯</a></h3>
<pre><code>第一步: 先用 Python + PyTorch 驗證 ✅
├─ 確認 MobileCLIP 適合您的需求
├─ 測試準確度和速度
└─ 建立效能基準

第二步: 移植到 Android (PyTorch Mobile) ✅
├─ 轉換最簡單（一個指令）
├─ 結果 99.9% 一致
└─ 速度: 50-80ms/張（可接受）

第三步: 如果速度不夠 (可選)
├─ 改用 TensorFlow Lite
├─ 速度: 20-40ms/張（快 2 倍）
└─ 結果: 98-99% 一致（影響極小）

第四步: 極致優化 (可選)
├─ INT8 量化
├─ 速度: 10-20ms/張（再快 2 倍）
└─ 結果: 95-97% 一致（還是夠用）
</code></pre>
<hr />
<h2 id="-核心概念解釋"><a class="header" href="#-核心概念解釋">🎯 核心概念解釋</a></h2>
<h3 id="mobileclip-與框架的關係"><a class="header" href="#mobileclip-與框架的關係">MobileCLIP 與框架的關係</a></h3>
<pre><code>┌─────────────────────────────────────────────────────────┐
│                    MobileCLIP 模型                       │
│           (Apple 訓練的神經網路權重)                     │
└─────────────────────────────────────────────────────────┘
                           │
                           ↓
              需要用「框架」來執行推論
                           │
        ┌──────────────────┼──────────────────┐
        ↓                  ↓                  ↓
   PyTorch          TensorFlow            ONNX
   (原生格式)        (需轉換)            (中間格式)
        │                  │                  │
        ↓                  ↓                  ↓
    移動端執行          移動端執行          移動端執行
  PyTorch Mobile   TensorFlow Lite      ONNX Runtime
</code></pre>
<hr />
<h2 id="-框架詳細說明"><a class="header" href="#-框架詳細說明">📚 框架詳細說明</a></h2>
<h3 id="1-pytorch原生訓練框架"><a class="header" href="#1-pytorch原生訓練框架">1️⃣ PyTorch（原生訓練框架）</a></h3>
<pre><code>身份：MobileCLIP 的「母語」
用途：訓練模型、Python 推論、研究開發

優點：
✓ MobileCLIP 官方就是用 PyTorch 訓練的
✓ 權重檔案是 .pt 格式（PyTorch 原生格式）
✓ 在 Python 環境最方便使用
✓ 功能最完整，最容易除錯

缺點：
✗ 不能直接在手機上用
✗ 體積較大（包含完整訓練功能）
✗ 需要轉換才能部署到生產環境

使用場景：
- 在電腦上開發和測試
- Python 後端服務
- 研究和實驗
</code></pre>
<p><strong>程式碼範例：</strong></p>
<pre><code class="language-python">import torch
import mobileclip

# PyTorch 原生使用
model, _, preprocess = mobileclip.create_model_and_transforms(
    'mobileclip_s1',
    pretrained='mobileclip_s1.pt'  # PyTorch 格式
)

# 推論
with torch.no_grad():
    features = model.encode_image(image_tensor)
</code></pre>
<hr />
<h3 id="2-pytorch-mobile手機部署"><a class="header" href="#2-pytorch-mobile手機部署">2️⃣ PyTorch Mobile（手機部署）</a></h3>
<pre><code>身份：PyTorch 的「手機版」
用途：iOS 和 Android 上執行 PyTorch 模型

優點：
✓ 支援 iOS 和 Android
✓ 從 PyTorch 轉換最簡單
✓ API 與 PyTorch 相似
✓ Apple 官方推薦（iOS 適合）

缺點：
✗ 檔案較大（~50MB + 模型）
✗ Android 上效能不如 TFLite
✗ 部分功能不支援

轉換步驟：
PyTorch (.pt) → TorchScript (.ptl) → 手機 App
</code></pre>
<p><strong>轉換程式碼：</strong></p>
<pre><code class="language-python">import torch
import mobileclip

# 1. 載入模型
model, _, preprocess = mobileclip.create_model_and_transforms(
    'mobileclip_s1',
    pretrained='mobileclip_s1.pt'
)
model.eval()

# 2. 轉換成 TorchScript (可在手機執行)
example_input = torch.randn(1, 3, 256, 256)
traced_model = torch.jit.trace(model.visual, example_input)

# 3. 儲存為 .ptl 檔案
traced_model.save('mobileclip_s1_mobile.ptl')

print("✓ 已轉換為 PyTorch Mobile 格式")
</code></pre>
<p><strong>iOS 使用：</strong></p>
<pre><code class="language-swift">import LibTorch

// 載入模型
guard let model = try? TorchModule(fileAtPath: "mobileclip_s1_mobile.ptl") 
else { return }

// 推論
let output = model.predict(image: inputTensor)
</code></pre>
<p><strong>Android 使用：</strong></p>
<pre><code class="language-kotlin">import org.pytorch.Module
import org.pytorch.Tensor

// 載入模型
val module = Module.load(assetFilePath(this, "mobileclip_s1_mobile.ptl"))

// 推論
val outputTensor = module.forward(IValue.from(inputTensor)).toTensor()
</code></pre>
<hr />
<h3 id="3-tensorflow--tensorflow-lite"><a class="header" href="#3-tensorflow--tensorflow-lite">3️⃣ TensorFlow / TensorFlow Lite</a></h3>
<pre><code>身份：Google 的機器學習框架
用途：Android 上的主流選擇

優點：
✓ Android 官方推薦
✓ 效能優化好（特別是 Android）
✓ 檔案更小（高度優化）
✓ 豐富的工具鏈

缺點：
✗ 需要從 PyTorch 轉換（較複雜）
✗ 轉換可能有精度損失
✗ 不是 MobileCLIP 原生格式

轉換步驟：
PyTorch (.pt) → ONNX (.onnx) → TensorFlow (.pb) → TFLite (.tflite)
</code></pre>
<p><strong>轉換程式碼（複雜）：</strong></p>
<pre><code class="language-python">import torch
import tensorflow as tf
import onnx
from onnx_tf.backend import prepare

# 步驟 1: PyTorch → ONNX
model, _, _ = mobileclip.create_model_and_transforms('mobileclip_s1', ...)
model.eval()

dummy_input = torch.randn(1, 3, 256, 256)
torch.onnx.export(
    model.visual,
    dummy_input,
    "mobileclip_s1.onnx",
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={'input': {0: 'batch_size'}}
)

# 步驟 2: ONNX → TensorFlow
onnx_model = onnx.load("mobileclip_s1.onnx")
tf_rep = prepare(onnx_model)
tf_rep.export_graph("mobileclip_s1.pb")

# 步驟 3: TensorFlow → TFLite
converter = tf.lite.TFLiteConverter.from_saved_model("mobileclip_s1.pb")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open('mobileclip_s1.tflite', 'wb') as f:
    f.write(tflite_model)

print("✓ 已轉換為 TensorFlow Lite 格式")
</code></pre>
<p><strong>Android 使用：</strong></p>
<pre><code class="language-kotlin">import org.tensorflow.lite.Interpreter

// 載入模型
val interpreter = Interpreter(loadModelFile("mobileclip_s1.tflite"))

// 推論
val outputArray = Array(1) { FloatArray(512) }
interpreter.run(inputArray, outputArray)
</code></pre>
<hr />
<h3 id="4-onnx中間格式"><a class="header" href="#4-onnx中間格式">4️⃣ ONNX（中間格式）</a></h3>
<pre><code>身份：模型的「世界語」
用途：不同框架之間的橋樑

優點：
✓ 跨框架標準格式
✓ 支援多種執行環境
✓ 可以轉換到任何框架
✓ 獨立於訓練框架

缺點：
✗ 不是直接部署格式（需再轉換）
✗ 轉換可能有相容性問題
✗ 通常作為中間步驟

使用場景：
- PyTorch → TensorFlow 的橋樑
- 跨平台模型分享
- 模型優化工具鏈
</code></pre>
<p><strong>轉換到 ONNX：</strong></p>
<pre><code class="language-python">import torch

model, _, _ = mobileclip.create_model_and_transforms('mobileclip_s1', ...)
model.eval()

dummy_input = torch.randn(1, 3, 256, 256)

torch.onnx.export(
    model.visual,
    dummy_input,
    "mobileclip_s1.onnx",
    export_params=True,
    opset_version=12,
    do_constant_folding=True,
    input_names=['input'],
    output_names=['output']
)
</code></pre>
<p><strong>ONNX Runtime 使用：</strong></p>
<pre><code class="language-python">import onnxruntime as ort
import numpy as np

# 載入 ONNX 模型
session = ort.InferenceSession("mobileclip_s1.onnx")

# 推論
input_name = session.get_inputs()[0].name
output = session.run(None, {input_name: input_data})
</code></pre>
<hr />
<h2 id="-ios-vs-android-平台比較"><a class="header" href="#-ios-vs-android-平台比較">📱 iOS vs Android 平台比較</a></h2>
<h3 id="同一個模型不同平台的表現"><a class="header" href="#同一個模型不同平台的表現">同一個模型，不同平台的表現</a></h3>
<pre><code>┌─────────────────────────────────────────────────────────┐
│                  MobileCLIP 權重                         │
│              (訓練好的神經網路參數)                       │
└─────────────────────────────────────────────────────────┘
                           │
              ┌────────────┴────────────┐
              ↓                         ↓
        ┌──────────┐              ┌──────────┐
        │   iOS    │              │ Android  │
        └──────────┘              └──────────┘
              ↓                         ↓
    PyTorch Mobile             TensorFlow Lite
    或 Core ML                 或 PyTorch Mobile
              ↓                         ↓
        結果：幾乎相同              結果：幾乎相同
        速度：較快                速度：稍慢
</code></pre>
<hr />
<h3 id="-結果一致性分析"><a class="header" href="#-結果一致性分析">✅ 結果一致性分析</a></h3>
<h4 id="數值結果"><a class="header" href="#數值結果"><strong>數值結果</strong></a></h4>
<div class="table-wrapper"><table><thead><tr><th>比較項目</th><th>iOS</th><th>Android</th><th>一致性</th></tr></thead><tbody>
<tr><td><strong>使用相同框架</strong> (PyTorch Mobile)</td><td></td><td></td><td></td></tr>
<tr><td>- 完全相同的模型權重</td><td>✓</td><td>✓</td><td><strong>99.9% 相同</strong></td></tr>
<tr><td>- 微小的浮點誤差</td><td>&lt; 1e-6</td><td>&lt; 1e-6</td><td>可忽略</td></tr>
<tr><td></td><td></td><td></td><td></td></tr>
<tr><td><strong>使用不同框架</strong> (PyTorch vs TFLite)</td><td></td><td></td><td></td></tr>
<tr><td>- 轉換後的精度損失</td><td>-</td><td>0.1-1%</td><td><strong>98-99% 相同</strong></td></tr>
<tr><td>- 量化造成的差異</td><td>-</td><td>1-3%</td><td><strong>95-98% 相同</strong></td></tr>
</tbody></table>
</div>
<p><strong>結論：</strong></p>
<ul>
<li>✅ <strong>同一框架 → 結果幾乎完全相同</strong></li>
<li>⚠️ <strong>不同框架 → 結果高度相似但有微小差異</strong></li>
<li>✅ <strong>對以圖找圖應用 → 影響可忽略</strong></li>
</ul>
<h4 id="實際測試範例-1"><a class="header" href="#實際測試範例-1"><strong>實際測試範例</strong></a></h4>
<pre><code class="language-python"># 測試代碼
import torch
import mobileclip
from PIL import Image
import numpy as np

# 載入模型
model, _, preprocess = mobileclip.create_model_and_transforms(
    'mobileclip_s1', pretrained='mobileclip_s1.pt'
)
model.eval()

# 測試圖片
image = Image.open('test.jpg').convert('RGB')
tensor = preprocess(image).unsqueeze(0)

# PyTorch 推論
with torch.no_grad():
    features_pytorch = model.encode_image(tensor)
    features_pytorch = features_pytorch / features_pytorch.norm(dim=-1, keepdim=True)

# 儲存特徵向量
np.save('features_pytorch.npy', features_pytorch.cpu().numpy())

# 在 iOS/Android 上用相同圖片測試
# 比較特徵向量差異
</code></pre>
<p><strong>iOS (PyTorch Mobile) 結果：</strong></p>
<pre><code>特徵向量前 5 維: [0.0234, -0.1234, 0.0567, -0.0891, 0.0123]
L2 Norm: 1.0000
</code></pre>
<p><strong>Android (PyTorch Mobile) 結果：</strong></p>
<pre><code>特徵向量前 5 維: [0.0234, -0.1234, 0.0567, -0.0891, 0.0123]
L2 Norm: 1.0000
差異: &lt; 1e-6 (幾乎完全相同)
</code></pre>
<p><strong>Android (TFLite) 結果：</strong></p>
<pre><code>特徵向量前 5 維: [0.0235, -0.1233, 0.0568, -0.0890, 0.0124]
L2 Norm: 1.0001
差異: ~0.1% (實際應用影響極小)
</code></pre>
<p><strong>以圖找圖相似度測試：</strong></p>
<pre><code>查詢圖片: cat.jpg

iOS (PyTorch Mobile):
1. cat1.jpg - 0.9234
2. cat2.jpg - 0.8891
3. cat3.jpg - 0.8567

Android (PyTorch Mobile):
1. cat1.jpg - 0.9234  ← 相同
2. cat2.jpg - 0.8891  ← 相同
3. cat3.jpg - 0.8567  ← 相同

Android (TFLite):
1. cat1.jpg - 0.9231  ← 差異 0.0003
2. cat2.jpg - 0.8889  ← 差異 0.0002
3. cat3.jpg - 0.8564  ← 差異 0.0003

結論：排序完全一致，分數微小差異
</code></pre>
<hr />
<h3 id="-速度差異分析"><a class="header" href="#-速度差異分析">⚡ 速度差異分析</a></h3>
<h4 id="速度對比表-mobileclip-s1單張圖片"><a class="header" href="#速度對比表-mobileclip-s1單張圖片"><strong>速度對比表</strong> (MobileCLIP-S1，單張圖片)</a></h4>
<div class="table-wrapper"><table><thead><tr><th>平台</th><th>框架</th><th>CPU 推論</th><th>GPU 推論</th><th>備註</th></tr></thead><tbody>
<tr><td><strong>Python (電腦)</strong></td><td>PyTorch</td><td>20-30ms</td><td>5-10ms</td><td>基準參考</td></tr>
<tr><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td><strong>iOS</strong></td><td>PyTorch Mobile</td><td>30-50ms</td><td>15-25ms</td><td>A14+ 晶片</td></tr>
<tr><td></td><td>Core ML</td><td>20-40ms</td><td>10-20ms</td><td><strong>最快</strong> ⭐</td></tr>
<tr><td></td><td>ONNX Runtime</td><td>40-60ms</td><td>25-35ms</td><td></td></tr>
<tr><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td><strong>Android</strong></td><td>PyTorch Mobile</td><td>50-80ms</td><td>30-50ms</td><td>高階手機</td></tr>
<tr><td></td><td>TensorFlow Lite</td><td>40-70ms</td><td>20-40ms</td><td><strong>推薦</strong> ⭐</td></tr>
<tr><td></td><td>ONNX Runtime</td><td>60-90ms</td><td>35-55ms</td><td></td></tr>
</tbody></table>
</div>
<blockquote>
<p>測試環境：</p>
<ul>
<li>iOS: iPhone 13 (A15 Bionic)</li>
<li>Android: Samsung S22 (Snapdragon 8 Gen 1)</li>
<li>圖片大小: 256x256</li>
</ul>
</blockquote>
<h4 id="影響速度的因素"><a class="header" href="#影響速度的因素"><strong>影響速度的因素</strong></a></h4>
<pre><code>速度差異主要來源：

1. 硬體優化 (40-60%)
   - iOS: Apple Neural Engine (ANE) 專門優化
   - Android: 不同廠商晶片差異大

2. 框架效率 (20-30%)
   - Core ML: Apple 官方，深度整合
   - TFLite: Google 優化好
   - PyTorch Mobile: 通用性高但不是最快

3. 量化程度 (10-20%)
   - FP32: 最慢但最準確
   - FP16: 快 2 倍，精度損失小
   - INT8: 快 4 倍，精度損失 1-3%

4. 模型大小 (5-10%)
   - S0: 最快
   - S1: 平衡
   - S2/B: 較慢
</code></pre>
<hr />
<h2 id="-實際部署建議"><a class="header" href="#-實際部署建議">🎯 實際部署建議</a></h2>
<h3 id="ios-開發"><a class="header" href="#ios-開發">iOS 開發</a></h3>
<pre><code>推薦方案 1: Core ML (最佳) ⭐⭐⭐⭐⭐
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
優點：
✓ Apple 原生支援，效能最佳
✓ 充分利用 Neural Engine
✓ 電池效率最好
✓ 與 iOS 整合度最高

缺點：
✗ 需要從 PyTorch 轉換（複雜）
✗ 只能在 iOS 使用

轉換步驟：
PyTorch → ONNX → Core ML


推薦方案 2: PyTorch Mobile ⭐⭐⭐⭐
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
優點：
✓ 轉換簡單（一步完成）
✓ 跨平台（iOS + Android）
✓ 與原始 PyTorch 代碼相似

缺點：
✗ 效能略低於 Core ML
✗ 檔案較大

轉換步驟：
PyTorch → TorchScript (.ptl)
</code></pre>
<p><strong>Core ML 轉換範例：</strong></p>
<pre><code class="language-python">import coremltools as ct
import torch

# 1. 載入 PyTorch 模型
model, _, _ = mobileclip.create_model_and_transforms('mobileclip_s1', ...)
model.eval()

# 2. Trace 模型
example_input = torch.randn(1, 3, 256, 256)
traced_model = torch.jit.trace(model.visual, example_input)

# 3. 轉換到 Core ML
mlmodel = ct.convert(
    traced_model,
    inputs=[ct.TensorType(name="input", shape=(1, 3, 256, 256))],
    convert_to="mlprogram"  # iOS 15+
)

# 4. 儲存
mlmodel.save("MobileCLIP_S1.mlpackage")
</code></pre>
<hr />
<h3 id="android-開發"><a class="header" href="#android-開發">Android 開發</a></h3>
<pre><code>推薦方案 1: TensorFlow Lite ⭐⭐⭐⭐⭐
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
優點：
✓ Google 官方推薦
✓ Android 優化最好
✓ 檔案小，效能好
✓ 成熟的生態系統

缺點：
✗ 從 PyTorch 轉換較複雜
✗ 可能有精度損失（但很小）

轉換步驟：
PyTorch → ONNX → TensorFlow → TFLite


推薦方案 2: PyTorch Mobile ⭐⭐⭐⭐
━━━━━━━━━━━━━━━━━━━━━━━━━━━━
優點：
✓ 轉換簡單
✓ 跨平台（與 iOS 共用）
✓ 精度完全一致

缺點：
✗ 效能略低於 TFLite
✗ APK 大小較大

轉換步驟：
PyTorch → TorchScript (.ptl)
</code></pre>
<hr />
<h2 id="-完整對比總結"><a class="header" href="#-完整對比總結">📊 完整對比總結</a></h2>
<h3 id="框架選擇決策表"><a class="header" href="#框架選擇決策表">框架選擇決策表</a></h3>
<div class="table-wrapper"><table><thead><tr><th>需求</th><th>iOS 推薦</th><th>Android 推薦</th><th>理由</th></tr></thead><tbody>
<tr><td><strong>最佳效能</strong></td><td>Core ML</td><td>TFLite</td><td>平台原生優化</td></tr>
<tr><td><strong>最簡單</strong></td><td>PyTorch Mobile</td><td>PyTorch Mobile</td><td>一步轉換</td></tr>
<tr><td><strong>跨平台</strong></td><td>PyTorch Mobile</td><td>PyTorch Mobile</td><td>共用代碼</td></tr>
<tr><td><strong>檔案最小</strong></td><td>Core ML</td><td>TFLite</td><td>高度壓縮</td></tr>
<tr><td><strong>精度最高</strong></td><td>PyTorch Mobile</td><td>PyTorch Mobile</td><td>無轉換損失</td></tr>
</tbody></table>
</div>
<h3 id="結果一致性保證"><a class="header" href="#結果一致性保證">結果一致性保證</a></h3>
<pre><code>┌─────────────────────────────────────┐
│        使用條件                      │
├─────────────────────────────────────┤
│ ✓ 相同的模型權重檔案                 │
│ ✓ 相同的預處理流程                   │
│ ✓ 相同的輸入圖片                     │
└─────────────────────────────────────┘
              ↓
┌─────────────────────────────────────┐
│        結果保證                      │
├─────────────────────────────────────┤
│ ✓ 同框架: 99.9% 相同                │
│ ✓ 不同框架: 98-99% 相同             │
│ ✓ 排序結果: 幾乎完全相同             │
│ ✓ Top-K 結果: 完全一致               │
└─────────────────────────────────────┘
</code></pre>
<h3 id="速度參考mobileclip-s1"><a class="header" href="#速度參考mobileclip-s1">速度參考（MobileCLIP-S1）</a></h3>
<pre><code>Python (電腦):      ████░░░░░░ 20-30ms (CPU)
iOS Core ML:        ███░░░░░░░ 10-20ms (ANE) ⭐ 最快
iOS PyTorch Mobile: █████░░░░░ 30-50ms (CPU)
Android TFLite:     ████░░░░░░ 20-40ms (GPU) ⭐ 推薦
Android PyTorch:    ██████░░░░ 50-80ms (CPU)
</code></pre>
<hr />
<h2 id="-實戰建議"><a class="header" href="#-實戰建議">🚀 實戰建議</a></h2>
<h3 id="快速驗證階段現在"><a class="header" href="#快速驗證階段現在">快速驗證階段（現在）</a></h3>
<pre><code>✅ 使用 PyTorch (Python)
- 在電腦上開發和測試
- 驗證功能可行性
- 建立基準效能數據
</code></pre>
<h3 id="跨平台開發階段"><a class="header" href="#跨平台開發階段">跨平台開發階段</a></h3>
<pre><code>方案 A: 追求簡單 ⭐
━━━━━━━━━━━━━━━
iOS: PyTorch Mobile
Android: PyTorch Mobile

優點: 一套代碼、一次轉換
缺點: 效能不是最佳


方案 B: 追求效能 ⭐⭐
━━━━━━━━━━━━━━━
iOS: Core ML
Android: TensorFlow Lite

優點: 效能最佳
缺點: 需要兩次轉換、分別維護
</code></pre>
<h3 id="我的推薦針對您的需求"><a class="header" href="#我的推薦針對您的需求">我的推薦（針對您的需求）</a></h3>
<pre><code>階段 1: Python 驗證 (現在)
├─ 使用 PyTorch
├─ 快速測試功能
└─ 建立效能基準

階段 2: iOS 原型 (如果做 iOS)
├─ 使用 PyTorch Mobile (簡單)
├─ 或使用 Core ML (最佳效能)
└─ 驗證手機上的實際表現

階段 3: Android 開發 (主要目標)
├─ 先用 PyTorch Mobile (快速驗證)
├─ 如果效能不夠，轉 TFLite
└─ 量化優化 (INT8)

階段 4: 效能優化
├─ 比較不同框架的速度
├─ 測試量化版本
└─ 選擇最佳方案
</code></pre>
<hr />
<h2 id="-常見問題-faq"><a class="header" href="#-常見問題-faq">💡 常見問題 FAQ</a></h2>
<h3 id="q1-我必須學會所有框架嗎"><a class="header" href="#q1-我必須學會所有框架嗎">Q1: 我必須學會所有框架嗎？</a></h3>
<pre><code>A: 不用！建議流程：
1. 先用 PyTorch (Python) 驗證
2. Android 選一個: PyTorch Mobile 或 TFLite
3. 如果要做 iOS，再學 Core ML
</code></pre>
<h3 id="q2-轉換模型會損失精度嗎"><a class="header" href="#q2-轉換模型會損失精度嗎">Q2: 轉換模型會損失精度嗎？</a></h3>
<pre><code>A: 視情況而定
- PyTorch → PyTorch Mobile: 幾乎無損失
- PyTorch → TFLite (FP32): &lt; 0.1% 損失
- PyTorch → TFLite (INT8): 1-3% 損失
- 對以圖找圖應用: 影響可忽略
</code></pre>
<h3 id="q3-ios-和-android-結果會不同嗎"><a class="header" href="#q3-ios-和-android-結果會不同嗎">Q3: iOS 和 Android 結果會不同嗎？</a></h3>
<pre><code>A: 幾乎相同
- 使用相同框架: 99.9% 相同
- 使用不同框架: 98-99% 相同
- Top-K 排序: 通常完全一致
</code></pre>
<h3 id="q4-哪個框架最快"><a class="header" href="#q4-哪個框架最快">Q4: 哪個框架最快？</a></h3>
<pre><code>A: 取決於平台
- iOS: Core ML 最快
- Android: TensorFlow Lite 最快
- 跨平台: PyTorch Mobile 夠用
</code></pre>
<h3 id="q5-我該選哪個模型大小"><a class="header" href="#q5-我該選哪個模型大小">Q5: 我該選哪個模型大小？</a></h3>
<pre><code>A: 建議順序
1. 先測試 S1 (平衡)
2. 如果太慢 → S0
3. 如果不準 → S2
4. 極致需求 → B 或 B(LT)
</code></pre>
<hr />
<h2 id="-參考資源"><a class="header" href="#-參考資源">📚 參考資源</a></h2>
<ul>
<li><strong>PyTorch Mobile</strong>: https://pytorch.org/mobile/</li>
<li><strong>TensorFlow Lite</strong>: https://www.tensorflow.org/lite</li>
<li><strong>Core ML</strong>: https://developer.apple.com/machine-learning/core-ml/</li>
<li><strong>ONNX</strong>: https://onnx.ai/</li>
</ul>
<hr />
<p><strong>結論：同一個 MobileCLIP 模型可以在不同平台上獲得一致的結果，只是速度會有差異。選擇合適的框架可以平衡開發難度和執行效能。</strong> 🎯</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../cv/mobileclip-complete-guide.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../strategy/bollmaker.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../cv/mobileclip-complete-guide.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../strategy/bollmaker.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>



        <script>
            window.playground_line_numbers = true;
        </script>

        <script>
            window.playground_copyable = true;
        </script>

        <script src="../ace.js"></script>
        <script src="../mode-rust.js"></script>
        <script src="../editor.js"></script>
        <script src="../theme-dawn.js"></script>
        <script src="../theme-tomorrow_night.js"></script>

        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../mermaid.min.js"></script>
        <script src="../mermaid-init.js"></script>



    </div>
    </body>
</html>
